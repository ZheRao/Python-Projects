{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fbdd09",
   "metadata": {},
   "source": [
    "Note: the dataset contains possible value of 2 if the original piece's left hand and right hand hit that key simultenuously, made adjustment in the train phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336a8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from torch import optim\n",
    "import math\n",
    "import pypianoroll\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e3569",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d1a05",
   "metadata": {},
   "source": [
    "note: we compare the loss the final 10 predictions, but I can't, so output seq_len-1 predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33606074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class customDataset(data.Dataset):\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        fnames = os.listdir(path)\n",
    "        fnames_ful = map(lambda fname: os.path.join(path, fname), fnames)\n",
    "        # hold a list of full file paths\n",
    "        self.fnames_ful = list(fnames_ful)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fnames_ful)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fnames_ful = self.fnames_ful[index]\n",
    "        roll = pd.read_csv(fnames_ful,header=None)\n",
    "        roll = np.array(roll)\n",
    "        # input sequence is from first element til the second last so that\n",
    "        #  the model could predict from the second element til the last one\n",
    "        input_seq = roll[:-1,:]\n",
    "        # we expect the model to predict the final 10 elements\n",
    "        output_seq = roll[-500:,:]\n",
    "        #output_seq = roll[1:,:]\n",
    "        return (input_seq,output_seq)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32e1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class customDataset2(data.Dataset):\n",
    "    def __init__(self,folder,subfolders,trainingtype):\n",
    "        self.folder = folder # this contains subfolders such as mozart\n",
    "        self.subfolders = subfolders\n",
    "        self.trainingtype = trainingtype # this is either Train, Val, or Test\n",
    "        \n",
    "        subfoldername = self.subfolders # get all the subfoler names such as chopin\n",
    "        \n",
    "        # extract desired datasets from each of the subfolders\n",
    "        all_songs = []\n",
    "        for foldername in  subfoldername:\n",
    "            # this gives the path of desired folder: e.g..../Chopin/Train\n",
    "            dataset_path_in_subfolder = os.path.join(folder,foldername,trainingtype)\n",
    "            #print(\"desired folder \",dataset_path_in_subfolder)\n",
    "            \n",
    "            # this gives the song names in the desired folder: e.g. k21_op3.mid\n",
    "            songs_in_dataset = os.listdir(dataset_path_in_subfolder)\n",
    "            #print(\"songs: \", songs_in_dataset[:3])\n",
    "            \n",
    "            # combine the desired path with the song names: e.g. .../Chopin/Train/k21_op3.mid\n",
    "            songs = map(lambda fname: os.path.join(dataset_path_in_subfolder,fname),\n",
    "                                                    songs_in_dataset)\n",
    "            songs = list(songs)\n",
    "            #print(\"songs full: \",songs[:3])\n",
    "            \n",
    "            # append the songs to all_songs\n",
    "            all_songs.extend(songs)\n",
    "            #print(\"all songs: \", all_songs[:3])\n",
    "        \n",
    "        # hold a list of full file paths\n",
    "        self.fnames_ful = all_songs\n",
    "        print(\"Total samples: \",len(all_songs))\n",
    "        #print(all_songs[:10])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fnames_ful)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fnames_ful = self.fnames_ful[index]\n",
    "        roll = pd.read_csv(fnames_ful,header=None)\n",
    "        roll = np.array(roll)\n",
    "        # input sequence is from first element til the second last so that\n",
    "        #  the model could predict from the second element til the last one\n",
    "        input_seq = roll[:599,:]\n",
    "        # we expect the model to predict the final 10 elements\n",
    "        output_seq = roll[1:600,:]\n",
    "        #output_seq = roll[1:,:]\n",
    "        return (input_seq,output_seq)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc92f9f",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef08c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"Handcrafted Dataset - One Hot\"\n",
    "subfolders = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffda1a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  29431\n"
     ]
    }
   ],
   "source": [
    "# test new dataset class: takes folder, subfolders, trainingtype\n",
    "\n",
    "trainingtype = \"Train\"\n",
    "\n",
    "train_dataset = customDataset2(folder,subfolders,trainingtype)\n",
    "train_dataloader = data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5a5125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 599, 88])\n",
      "torch.Size([64, 599, 88])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "X_train=next(iter(train_dataloader))\n",
    "print(X_train[0].shape) # input seq\n",
    "print(X_train[1].shape) # output seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f233862",
   "metadata": {},
   "source": [
    "input shape: (batch_size,seq_len=219, num_pitch=88)\n",
    "output shape: (batch_size,seq_len=200,num_pitch=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e38e963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  5211\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "path = \"waldstein_1/Val\"\n",
    "\n",
    "trainingtype=\"Val\"\n",
    "#val_dataset = customDataset(path)\n",
    "val_dataset = customDataset2(folder,subfolders,trainingtype)\n",
    "# seperate val set into 5 sets because validate 40,000 every time is too much\n",
    "#  now it would only validate on 8,000\n",
    "set1 = list(range(0,len(val_dataset),3))\n",
    "set2 = list(range(1,len(val_dataset),3))\n",
    "set3 = list(range(2,len(val_dataset),3))\n",
    "#set4 = list(range(3,len(val_dataset),5))\n",
    "#set5 = list(range(4,len(val_dataset),5))\n",
    "\n",
    "val1 = data.Subset(val_dataset,set1)\n",
    "val2 = data.Subset(val_dataset,set2)\n",
    "val3 = data.Subset(val_dataset,set3)\n",
    "#val4 = data.Subset(val_dataset,set4)\n",
    "#val5 = data.Subset(val_dataset,set5)\"\"\n",
    "\n",
    "size = 64\n",
    "val_dataloader1 = data.DataLoader(val1,batch_size=size,shuffle=True)\n",
    "val_dataloader2 = data.DataLoader(val2,batch_size=size,shuffle=True)\n",
    "val_dataloader3 = data.DataLoader(val3,batch_size=size,shuffle=True)\n",
    "#val_dataloader4 = data.DataLoader(val4,batch_size=size,shuffle=True)\n",
    "#val_dataloader5 = data.DataLoader(val5,batch_size=size,shuffle=True)\n",
    "\n",
    "val_dataloaders = [val_dataloader1,\n",
    "               val_dataloader2,\n",
    "               val_dataloader3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58af8b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 599, 88])\n",
      "torch.Size([64, 599, 88])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "X_val = next(iter(val_dataloader1))\n",
    "print(X_val[0].shape) # input seq\n",
    "print(X_val[1].shape) # output seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5282abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  3367\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "trainingtype=\"Test\"\n",
    "test_dataset = customDataset2(folder,subfolders,trainingtype)\n",
    "test_dataloader = data.DataLoader(test_dataset,batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f83472",
   "metadata": {},
   "source": [
    "# plot some composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd405e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1cfd72460>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Matrix representation of a classical composition\")\n",
    "plt.imshow(X_train[0][0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db061d9c",
   "metadata": {},
   "source": [
    "# Training and Validation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6844bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,val_loader,device,loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    steps = 0\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        steps += 1\n",
    "        input_seq, output_seq = batch\n",
    "        input_seq, output_seq = input_seq.to(device), output_seq.to(device)\n",
    "        # try to fix error :\"addmm_cuda\" not implemented for 'Long'\n",
    "        input_seq = input_seq.float()\n",
    "        \n",
    "        output_seq = output_seq.transpose(0,1).contiguous()\n",
    "        output_seq = output_seq.contiguous().view(-1)\n",
    "        \n",
    "        final,_ = model(input_seq)\n",
    "        # try to fix:\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'\n",
    "        #final, output_seq = final.double(),output_seq.double()\n",
    "        loss = loss_fn(final,output_seq)\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    print(\"The mean validation loss is %.4f\" % (val_loss/steps))\n",
    "    print()\n",
    "    return val_loss/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c5f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainloader,valloaders,ep,print_freq,loss_fun,\n",
    "          optimizer,device,run,grad_clip=1.0,mname=\"LSTM\"):\n",
    "    val_loss_best = float(\"inf\")\n",
    "    \n",
    "    # total number of training steps\n",
    "    num_steps = ep * (len(trainloader))\n",
    "    progress_bar = tqdm(range(num_steps))\n",
    "    \n",
    "    # calculate how often print the result\n",
    "    #  if num_step = 12, and print_freq = 3, then print every 4 steps\n",
    "    print_every = math.floor(num_steps/print_freq)\n",
    "    \n",
    "    # initialize\n",
    "    steps = 0\n",
    "    #model.to(device) ## error when run this twice\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    which_val = 0\n",
    "    \n",
    "    for e in range(ep):\n",
    "        current_loss = 0\n",
    "        for batch in trainloader:\n",
    "            input_s, output_s = batch\n",
    "            steps += 1\n",
    "            input_seq, output_seq = input_s.to(device), output_s.to(device)\n",
    "            # try to fix error :\"addmm_cuda\" not implemented for 'Long'\n",
    "            #  note: output_seq should stay long (int)\n",
    "            input_seq = input_seq.float()\n",
    "            #print(\"input shape: \",input_seq.shape)\n",
    "            \n",
    "            output_seq = output_seq.transpose(0,1).contiguous()\n",
    "            #print(\"output shape: \", output_seq.shape)\n",
    "            output_seq = output_seq.contiguous().view(-1)\n",
    "            \n",
    "            #print(\"output shape: \", output_seq.shape)\n",
    "            #print(\"largest output: \", torch.max(output_seq))\n",
    "            \n",
    "            # calculate grad and update\n",
    "            optimizer.zero_grad()\n",
    "            final,_ = model(input_seq)\n",
    "            #print(\"prediction shape: \", final.shape)\n",
    "            #print(\"largest prediction: \", torch.max(final.permute(1,0)[0]))\n",
    "            # calculate loss and record loss\n",
    "            # try to fix:\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'\n",
    "            #final, output_seq = final.double(),output_seq.double()\n",
    "            loss = loss_fun(final, output_seq)\n",
    "            #print(\"loss: \", loss)\n",
    "            train_losses.append(loss.item())\n",
    "            current_loss += loss.item()\n",
    "            # update parameter\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),grad_clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update progress bar\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            # print if reach the threshold we want\n",
    "            if steps % print_every == 0:\n",
    "                # training loss: divided by the number of steps taken during training\n",
    "                #  from last print to current print\n",
    "                if steps > 90:\n",
    "                    print('EPOCHS : {}/{} - step - {}'.format(e+1,ep,steps),\n",
    "                          'Loss : {:.6f}'.format(current_loss/print_every))\n",
    "                else:\n",
    "                    print('EPOCHS : {}/{} - step - {}'.format(e+1,ep,steps),\n",
    "                          'Loss : {:.6f}'.format(current_loss/10))\n",
    "                current_loss = 0\n",
    "                #which_val = random.randint(0,4)\n",
    "                which_val = random.randint(0,2) # now I only have 3 val sets\n",
    "                # val loss: divided by the number of steps taken when validate\n",
    "                val_loss = evaluate(model,valloaders[which_val],device,loss_fun)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                # add call back\n",
    "                if val_loss < val_loss_best:\n",
    "                    val_loss_best = val_loss\n",
    "                    torch.save(model.state_dict(),\n",
    "                     \"Handcrafted Dataset - One Hot Weights/\"+mname+\"-run-{}-val_loss-BEST.pth\".format(run))\n",
    "            model.train()\n",
    "    torch.save(model.state_dict(),\n",
    "         \"Handcrafted Dataset - One Hot Weights/ComplexLSTM_3composer-run-{}-val_loss-LAST.pth\".format(run))\n",
    "    return train_losses, val_losses\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c450f332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,1,1,0,4])\n",
    "b = [i if i<=1 else 1 for i in a]\n",
    "b = torch.tensor(b,dtype=torch.long)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e310f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325a9cc",
   "metadata": {},
   "source": [
    "# Model: Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317778e",
   "metadata": {},
   "source": [
    "\n",
    "###  embedding dimension: 512\n",
    "###  hidden dimension: 512\n",
    "###  LSTM layers: 2\n",
    "###  batchnorm after embedding&LSTM\n",
    "###  dropout_embed: 0.2\n",
    "###  dropout_lstm: 0.2\n",
    "###  grad clip: 1\n",
    "### Train loss: \n",
    "###  Val loss:\n",
    "###  Test loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4b87e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, input_size = 88, embed_size = 512, hidden_size = 512, \n",
    "                  num_class = 88, layers = 2):\n",
    "        super(MusicLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_class = num_class\n",
    "        self.layers = layers\n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=embed_size)\n",
    "        self.layernorm_encoder = nn.LayerNorm(embed_size)\n",
    "        self.layernorm_lstm = nn.LayerNorm(hidden_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,layers)\n",
    "        self.final = nn.Linear(hidden_size,num_class)\n",
    "        ###\n",
    "        #self.final = nn.Linear(hidden_size,128)\n",
    "        #self.final2 = nn.Linear(128,num_class)\n",
    "        #self.relu = nn.ReLU()\n",
    "        ###\n",
    "        \n",
    "    def forward(self,sequences,hidden=None):\n",
    "        # seq shape (batch,seq_len,88)\n",
    "        notes_encoded = self.notes_encoder(sequences) # shape (batch,seq_len,embed_size)\n",
    "        #notes_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
    "                                                      # shape (seq_len,embed_size,batch)\n",
    "        notes_rolled = notes_encoded\n",
    "        notes_lnormed = self.layernorm_encoder(notes_rolled)\n",
    "        notes_lnormed = nn.Dropout(0.2)(notes_lnormed)\n",
    "        #notes = notes_lnormed.permute(2,0,1)          # shape (batch,seq_len,embed_size)\n",
    "        notes = notes_lnormed\n",
    "        \n",
    "        # output shape (batch,seq_len,hidden_size)\n",
    "        output, hidden = self.lstm(notes,hidden)\n",
    "        \n",
    "        #output_lnormed = self.layernorm_lstm(output.permute(1,2,0).contiguous())\n",
    "        output_lnormed = self.layernorm_lstm(output)\n",
    "        output_lnormed = nn.Dropout(0.2)(output_lnormed)\n",
    "        \n",
    "\n",
    "        \n",
    "        # only take the final 200\n",
    "        output_lnormed = output_lnormed[:,-500:,:] \n",
    "        \n",
    "        # final shape (batch,200,num_class)\n",
    "        #final = self.final(output_lnormed.permute(2,0,1))\n",
    "        final = self.final(output_lnormed) # final (batch,200,hidden_size) --> \n",
    "                                            #                 (batch,200,88)\n",
    "        \n",
    "        ###\n",
    "        #final = self.relu(final)\n",
    "        #final = nn.Dropout(0.5)(final)\n",
    "        #final = self.final2(final)\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        \n",
    "        # final shape (200,batch,88)\n",
    "        final = final.transpose(0,1).contiguous()\n",
    "        #print(\"final shape: \", final.shape)\n",
    "        \n",
    "        # create a second measure for prediction per class, shape(seq_len,batch,num_class)\n",
    "        neg_final = 1 - final\n",
    "        \n",
    "        # two \"predictions\" for each node\n",
    "        zero_one_final = torch.stack((final,neg_final),dim=3).contiguous()\n",
    "        \n",
    "        # flatten everything except for the two predictions dimension\n",
    "        flatten_final = zero_one_final.view(-1,2)\n",
    "        \n",
    "        return flatten_final, hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeca1d5",
   "metadata": {},
   "source": [
    "### run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e1c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_base = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_base.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b537c4f6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8995988154f6e9d6fc4044c7eeed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/1 - step - 10 Loss : 1.289201\n",
      "The mean validation loss is 1.2395\n",
      "EPOCHS : 1/1 - step - 20 Loss : 1.154012\n",
      "The mean validation loss is 1.1400\n",
      "EPOCHS : 1/1 - step - 30 Loss : 0.948867\n",
      "The mean validation loss is 0.8806\n",
      "EPOCHS : 1/1 - step - 40 Loss : 0.689564\n",
      "The mean validation loss is 0.4864\n",
      "EPOCHS : 1/1 - step - 50 Loss : 0.428878\n",
      "The mean validation loss is 0.2484\n",
      "EPOCHS : 1/1 - step - 60 Loss : 0.242519\n",
      "The mean validation loss is 0.1285\n",
      "EPOCHS : 1/1 - step - 70 Loss : 0.141892\n",
      "The mean validation loss is 0.0786\n",
      "EPOCHS : 1/1 - step - 80 Loss : 0.094775\n",
      "The mean validation loss is 0.0609\n",
      "EPOCHS : 1/1 - step - 90 Loss : 0.068720\n",
      "The mean validation loss is 0.0572\n",
      "EPOCHS : 1/1 - step - 95 Loss : 0.003011\n",
      "The mean validation loss is 0.0489\n",
      "EPOCHS : 1/1 - step - 190 Loss : 0.039445\n",
      "The mean validation loss is 0.0328\n",
      "EPOCHS : 1/1 - step - 285 Loss : 0.033110\n",
      "The mean validation loss is 0.0321\n",
      "EPOCHS : 1/1 - step - 380 Loss : 0.031146\n",
      "The mean validation loss is 0.0304\n",
      "EPOCHS : 1/1 - step - 475 Loss : 0.030811\n",
      "The mean validation loss is 0.0424\n",
      "EPOCHS : 1/1 - step - 570 Loss : 0.029856\n",
      "The mean validation loss is 0.0294\n",
      "EPOCHS : 1/1 - step - 665 Loss : 0.031960\n",
      "The mean validation loss is 0.0329\n",
      "EPOCHS : 1/1 - step - 760 Loss : 0.030239\n",
      "The mean validation loss is 0.0288\n",
      "EPOCHS : 1/1 - step - 855 Loss : 0.028687\n",
      "The mean validation loss is 0.0283\n",
      "EPOCHS : 1/1 - step - 950 Loss : 0.028373\n",
      "The mean validation loss is 0.0280\n",
      "EPOCHS : 1/1 - step - 1045 Loss : 0.028270\n",
      "The mean validation loss is 0.0277\n",
      "EPOCHS : 1/1 - step - 1140 Loss : 0.027855\n",
      "The mean validation loss is 0.0276\n",
      "EPOCHS : 1/1 - step - 1235 Loss : 0.027622\n",
      "The mean validation loss is 0.0275\n",
      "EPOCHS : 1/1 - step - 1330 Loss : 0.027639\n",
      "The mean validation loss is 0.0273\n",
      "EPOCHS : 1/1 - step - 1425 Loss : 0.027615\n",
      "The mean validation loss is 0.0272\n",
      "EPOCHS : 1/1 - step - 1520 Loss : 0.027424\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/1 - step - 1615 Loss : 0.027197\n",
      "The mean validation loss is 0.0269\n",
      "EPOCHS : 1/1 - step - 1710 Loss : 0.027400\n",
      "The mean validation loss is 0.0269\n",
      "EPOCHS : 1/1 - step - 1805 Loss : 0.027017\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/1 - step - 1900 Loss : 0.027078\n",
      "The mean validation loss is 0.0268\n"
     ]
    }
   ],
   "source": [
    "# num_step = 1907 * ep, feq = 8, print every 190 batches\n",
    "train_loss, val_loss = train(LSTM_base,train_dataloader,val_dataloaders,1,20,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9d5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a952e12a",
   "metadata": {},
   "source": [
    "### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72bceeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_base = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "\n",
    "weights_folder = \"Handcrafted Dataset - One Hot Weights/\"\n",
    "model = \"0.027\"\n",
    "weights = weights_folder+\"LSTM_base-run-1-val_loss-\"+model+ \".pth\"\n",
    "LSTM_base.load_state_dict(torch.load(weights))\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_base.parameters(),lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef957b41",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381b72336b3e4a7bbec7294c064dc400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/2 - step - 190 Loss : 0.027261\n",
      "The mean validation loss is 0.0271\n",
      "EPOCHS : 1/2 - step - 380 Loss : 0.027293\n",
      "The mean validation loss is 0.0271\n",
      "EPOCHS : 1/2 - step - 570 Loss : 0.027260\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 760 Loss : 0.027347\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 950 Loss : 0.027211\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 1140 Loss : 0.027324\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 1330 Loss : 0.027202\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 1520 Loss : 0.027235\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 1/2 - step - 1710 Loss : 0.027222\n",
      "The mean validation loss is 0.0271\n",
      "EPOCHS : 1/2 - step - 1900 Loss : 0.027250\n",
      "The mean validation loss is 0.0269\n",
      "EPOCHS : 2/2 - step - 2090 Loss : 0.026198\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 2280 Loss : 0.027183\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 2470 Loss : 0.027269\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 2660 Loss : 0.027311\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 2850 Loss : 0.027236\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 3040 Loss : 0.027208\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 3230 Loss : 0.027196\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 3420 Loss : 0.027232\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 3610 Loss : 0.027170\n",
      "The mean validation loss is 0.0270\n",
      "EPOCHS : 2/2 - step - 3800 Loss : 0.027324\n",
      "The mean validation loss is 0.0269\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_base,train_dataloader,val_dataloaders,2,20,\n",
    "      loss_fun,optimizer,'cuda',2,grad_clip=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6265200",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_base.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_base-run-2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7caa2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f98ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7513a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8217a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4c018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90371415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d755c6d",
   "metadata": {},
   "source": [
    "# Chopin - 400 predict 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b519848",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Chopin = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_Chopin.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c184d912",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e723d93bedd42468d3f84cc6802618d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/10 - step - 49 Loss : 0.764307\n",
      "The mean validation loss is 0.0773\n",
      "\n",
      "EPOCHS : 1/10 - step - 98 Loss : 0.044465\n",
      "The mean validation loss is 0.0319\n",
      "\n",
      "EPOCHS : 2/10 - step - 147 Loss : 0.027584\n",
      "The mean validation loss is 0.0263\n",
      "\n",
      "EPOCHS : 2/10 - step - 196 Loss : 0.026742\n",
      "The mean validation loss is 0.0268\n",
      "\n",
      "EPOCHS : 3/10 - step - 245 Loss : 0.024985\n",
      "The mean validation loss is 0.0257\n",
      "\n",
      "EPOCHS : 3/10 - step - 294 Loss : 0.025467\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 4/10 - step - 343 Loss : 0.023836\n",
      "The mean validation loss is 0.0248\n",
      "\n",
      "EPOCHS : 4/10 - step - 392 Loss : 0.025040\n",
      "The mean validation loss is 0.0258\n",
      "\n",
      "EPOCHS : 5/10 - step - 441 Loss : 0.022941\n",
      "The mean validation loss is 0.0254\n",
      "\n",
      "EPOCHS : 5/10 - step - 490 Loss : 0.024680\n",
      "The mean validation loss is 0.0254\n",
      "\n",
      "EPOCHS : 6/10 - step - 539 Loss : 0.022104\n",
      "The mean validation loss is 0.0254\n",
      "\n",
      "EPOCHS : 6/10 - step - 588 Loss : 0.024408\n",
      "The mean validation loss is 0.0248\n",
      "\n",
      "EPOCHS : 7/10 - step - 637 Loss : 0.021499\n",
      "The mean validation loss is 0.0248\n",
      "\n",
      "EPOCHS : 7/10 - step - 686 Loss : 0.024236\n",
      "The mean validation loss is 0.0254\n",
      "\n",
      "EPOCHS : 8/10 - step - 735 Loss : 0.020634\n",
      "The mean validation loss is 0.0244\n",
      "\n",
      "EPOCHS : 8/10 - step - 784 Loss : 0.024203\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 9/10 - step - 833 Loss : 0.020201\n",
      "The mean validation loss is 0.0244\n",
      "\n",
      "EPOCHS : 9/10 - step - 882 Loss : 0.023734\n",
      "The mean validation loss is 0.0250\n",
      "\n",
      "EPOCHS : 10/10 - step - 931 Loss : 0.019492\n",
      "The mean validation loss is 0.0234\n",
      "\n",
      "EPOCHS : 10/10 - step - 980 Loss : 0.023838\n",
      "The mean validation loss is 0.0237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin,train_dataloader,val_dataloaders,10,20,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=1.0,mname=\"LSTM_Chopin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4255d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin-run-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07411d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49019a1e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca240bc1884470bb183d47f1e20f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 5/100 - step - 495 Loss : 0.004701\n",
      "The mean validation loss is 0.0238\n",
      "\n",
      "EPOCHS : 10/100 - step - 990 Loss : 0.004657\n",
      "The mean validation loss is 0.0238\n",
      "\n",
      "EPOCHS : 15/100 - step - 1485 Loss : 0.004598\n",
      "The mean validation loss is 0.0243\n",
      "\n",
      "EPOCHS : 20/100 - step - 1980 Loss : 0.004568\n",
      "The mean validation loss is 0.0231\n",
      "\n",
      "EPOCHS : 25/100 - step - 2475 Loss : 0.004547\n",
      "The mean validation loss is 0.0241\n",
      "\n",
      "EPOCHS : 30/100 - step - 2970 Loss : 0.004515\n",
      "The mean validation loss is 0.0232\n",
      "\n",
      "EPOCHS : 35/100 - step - 3465 Loss : 0.004484\n",
      "The mean validation loss is 0.0234\n",
      "\n",
      "EPOCHS : 40/100 - step - 3960 Loss : 0.004458\n",
      "The mean validation loss is 0.0236\n",
      "\n",
      "EPOCHS : 45/100 - step - 4455 Loss : 0.004445\n",
      "The mean validation loss is 0.0237\n",
      "\n",
      "EPOCHS : 50/100 - step - 4950 Loss : 0.004418\n",
      "The mean validation loss is 0.0234\n",
      "\n",
      "EPOCHS : 55/100 - step - 5445 Loss : 0.004396\n",
      "The mean validation loss is 0.0234\n",
      "\n",
      "EPOCHS : 60/100 - step - 5940 Loss : 0.004378\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 65/100 - step - 6435 Loss : 0.004369\n",
      "The mean validation loss is 0.0238\n",
      "\n",
      "EPOCHS : 70/100 - step - 6930 Loss : 0.004348\n",
      "The mean validation loss is 0.0233\n",
      "\n",
      "EPOCHS : 75/100 - step - 7425 Loss : 0.004338\n",
      "The mean validation loss is 0.0241\n",
      "\n",
      "EPOCHS : 80/100 - step - 7920 Loss : 0.004312\n",
      "The mean validation loss is 0.0233\n",
      "\n",
      "EPOCHS : 85/100 - step - 8415 Loss : 0.004318\n",
      "The mean validation loss is 0.0237\n",
      "\n",
      "EPOCHS : 90/100 - step - 8910 Loss : 0.004300\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 95/100 - step - 9405 Loss : 0.004286\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 100/100 - step - 9900 Loss : 0.004282\n",
      "The mean validation loss is 0.0232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin,train_dataloader,val_dataloaders,100,20,\n",
    "      loss_fun,optimizer,'cuda',2,grad_clip=2.0,mname=\"LSTM_Chopin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8ccba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin-run-2-val_loss_LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f1dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab410613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e226a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39702f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38990a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a5929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c3d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85c5f1f",
   "metadata": {},
   "source": [
    "# Chopin predict whole song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "196aade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Chopin = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_Chopin.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40d7ea7c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d017c52eda0449f894da1fb05d5a5091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/10 - step - 24 Loss : 0.487422\n",
      "The mean validation loss is 0.1303\n",
      "\n",
      "EPOCHS : 1/10 - step - 48 Loss : 0.294884\n",
      "The mean validation loss is 0.1060\n",
      "\n",
      "EPOCHS : 1/10 - step - 72 Loss : 0.196855\n",
      "The mean validation loss is 0.0548\n",
      "\n",
      "EPOCHS : 1/10 - step - 96 Loss : 0.043571\n",
      "The mean validation loss is 0.0354\n",
      "\n",
      "EPOCHS : 2/10 - step - 120 Loss : 0.028337\n",
      "The mean validation loss is 0.0296\n",
      "\n",
      "EPOCHS : 2/10 - step - 144 Loss : 0.029392\n",
      "The mean validation loss is 0.0275\n",
      "\n",
      "EPOCHS : 2/10 - step - 168 Loss : 0.027438\n",
      "The mean validation loss is 0.0274\n",
      "\n",
      "EPOCHS : 2/10 - step - 192 Loss : 0.026904\n",
      "The mean validation loss is 0.0273\n",
      "\n",
      "EPOCHS : 3/10 - step - 216 Loss : 0.019861\n",
      "The mean validation loss is 0.0267\n",
      "\n",
      "EPOCHS : 3/10 - step - 240 Loss : 0.026696\n",
      "The mean validation loss is 0.0263\n",
      "\n",
      "EPOCHS : 3/10 - step - 264 Loss : 0.025958\n",
      "The mean validation loss is 0.0264\n",
      "\n",
      "EPOCHS : 3/10 - step - 288 Loss : 0.026071\n",
      "The mean validation loss is 0.0263\n",
      "\n",
      "EPOCHS : 4/10 - step - 312 Loss : 0.016045\n",
      "The mean validation loss is 0.0259\n",
      "\n",
      "EPOCHS : 4/10 - step - 336 Loss : 0.025629\n",
      "The mean validation loss is 0.0252\n",
      "\n",
      "EPOCHS : 4/10 - step - 360 Loss : 0.025518\n",
      "The mean validation loss is 0.0251\n",
      "\n",
      "EPOCHS : 4/10 - step - 384 Loss : 0.025371\n",
      "The mean validation loss is 0.0256\n",
      "\n",
      "EPOCHS : 5/10 - step - 408 Loss : 0.012525\n",
      "The mean validation loss is 0.0252\n",
      "\n",
      "EPOCHS : 5/10 - step - 432 Loss : 0.025422\n",
      "The mean validation loss is 0.0255\n",
      "\n",
      "EPOCHS : 5/10 - step - 456 Loss : 0.024966\n",
      "The mean validation loss is 0.0250\n",
      "\n",
      "EPOCHS : 5/10 - step - 480 Loss : 0.025164\n",
      "The mean validation loss is 0.0251\n",
      "\n",
      "EPOCHS : 6/10 - step - 504 Loss : 0.009379\n",
      "The mean validation loss is 0.0249\n",
      "\n",
      "EPOCHS : 6/10 - step - 528 Loss : 0.024934\n",
      "The mean validation loss is 0.0249\n",
      "\n",
      "EPOCHS : 6/10 - step - 552 Loss : 0.024257\n",
      "The mean validation loss is 0.0250\n",
      "\n",
      "EPOCHS : 6/10 - step - 576 Loss : 0.024823\n",
      "The mean validation loss is 0.0241\n",
      "\n",
      "EPOCHS : 7/10 - step - 600 Loss : 0.006317\n",
      "The mean validation loss is 0.0247\n",
      "\n",
      "EPOCHS : 7/10 - step - 624 Loss : 0.024244\n",
      "The mean validation loss is 0.0250\n",
      "\n",
      "EPOCHS : 7/10 - step - 648 Loss : 0.024827\n",
      "The mean validation loss is 0.0249\n",
      "\n",
      "EPOCHS : 7/10 - step - 672 Loss : 0.024366\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 8/10 - step - 696 Loss : 0.003078\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 8/10 - step - 720 Loss : 0.024074\n",
      "The mean validation loss is 0.0244\n",
      "\n",
      "EPOCHS : 8/10 - step - 744 Loss : 0.024435\n",
      "The mean validation loss is 0.0248\n",
      "\n",
      "EPOCHS : 8/10 - step - 768 Loss : 0.024285\n",
      "The mean validation loss is 0.0241\n",
      "\n",
      "EPOCHS : 8/10 - step - 792 Loss : 0.024554\n",
      "The mean validation loss is 0.0238\n",
      "\n",
      "EPOCHS : 9/10 - step - 816 Loss : 0.024091\n",
      "The mean validation loss is 0.0237\n",
      "\n",
      "EPOCHS : 9/10 - step - 840 Loss : 0.024535\n",
      "The mean validation loss is 0.0244\n",
      "\n",
      "EPOCHS : 9/10 - step - 864 Loss : 0.024122\n",
      "The mean validation loss is 0.0242\n",
      "\n",
      "EPOCHS : 9/10 - step - 888 Loss : 0.024126\n",
      "The mean validation loss is 0.0243\n",
      "\n",
      "EPOCHS : 10/10 - step - 912 Loss : 0.020825\n",
      "The mean validation loss is 0.0240\n",
      "\n",
      "EPOCHS : 10/10 - step - 936 Loss : 0.024123\n",
      "The mean validation loss is 0.0238\n",
      "\n",
      "EPOCHS : 10/10 - step - 960 Loss : 0.024075\n",
      "The mean validation loss is 0.0243\n",
      "\n",
      "EPOCHS : 10/10 - step - 984 Loss : 0.024221\n",
      "The mean validation loss is 0.0245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin,train_dataloader,val_dataloaders,10,40,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=2.0,mname=\"LSTM_Chopin2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fffbb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin2-run-1-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bf06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e567f9cd",
   "metadata": {},
   "source": [
    "# Chopin3 loss: final 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bec3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Chopin3 = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_Chopin3.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d62b8305",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f332bd66b6a49bca657ef4119270bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/50 - step - 89 Loss : 1.105215\n",
      "The mean validation loss is 0.0429\n",
      "\n",
      "EPOCHS : 2/50 - step - 178 Loss : 0.011125\n",
      "The mean validation loss is 0.0277\n",
      "\n",
      "EPOCHS : 2/50 - step - 267 Loss : 0.027000\n",
      "The mean validation loss is 0.0272\n",
      "\n",
      "EPOCHS : 3/50 - step - 356 Loss : 0.020514\n",
      "The mean validation loss is 0.0259\n",
      "\n",
      "EPOCHS : 4/50 - step - 445 Loss : 0.004637\n",
      "The mean validation loss is 0.0263\n",
      "\n",
      "EPOCHS : 4/50 - step - 534 Loss : 0.025554\n",
      "The mean validation loss is 0.0252\n",
      "\n",
      "EPOCHS : 5/50 - step - 623 Loss : 0.014485\n",
      "The mean validation loss is 0.0254\n",
      "\n",
      "EPOCHS : 5/50 - step - 712 Loss : 0.024900\n",
      "The mean validation loss is 0.0248\n",
      "\n",
      "EPOCHS : 6/50 - step - 801 Loss : 0.023782\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 7/50 - step - 890 Loss : 0.008840\n",
      "The mean validation loss is 0.0244\n",
      "\n",
      "EPOCHS : 7/50 - step - 979 Loss : 0.024549\n",
      "The mean validation loss is 0.0242\n",
      "\n",
      "EPOCHS : 8/50 - step - 1068 Loss : 0.018224\n",
      "The mean validation loss is 0.0242\n",
      "\n",
      "EPOCHS : 9/50 - step - 1157 Loss : 0.003505\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 9/50 - step - 1246 Loss : 0.024315\n",
      "The mean validation loss is 0.0240\n",
      "\n",
      "EPOCHS : 10/50 - step - 1335 Loss : 0.013099\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 10/50 - step - 1424 Loss : 0.024012\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 11/50 - step - 1513 Loss : 0.022310\n",
      "The mean validation loss is 0.0245\n",
      "\n",
      "EPOCHS : 12/50 - step - 1602 Loss : 0.007732\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 12/50 - step - 1691 Loss : 0.023911\n",
      "The mean validation loss is 0.0242\n",
      "\n",
      "EPOCHS : 13/50 - step - 1780 Loss : 0.017175\n",
      "The mean validation loss is 0.0237\n",
      "\n",
      "EPOCHS : 14/50 - step - 1869 Loss : 0.002639\n",
      "The mean validation loss is 0.0246\n",
      "\n",
      "EPOCHS : 14/50 - step - 1958 Loss : 0.023863\n",
      "The mean validation loss is 0.0242\n",
      "\n",
      "EPOCHS : 15/50 - step - 2047 Loss : 0.012126\n",
      "The mean validation loss is 0.0235\n",
      "\n",
      "EPOCHS : 15/50 - step - 2136 Loss : 0.023507\n",
      "The mean validation loss is 0.0235\n",
      "\n",
      "EPOCHS : 16/50 - step - 2225 Loss : 0.021181\n",
      "The mean validation loss is 0.0240\n",
      "\n",
      "EPOCHS : 17/50 - step - 2314 Loss : 0.007020\n",
      "The mean validation loss is 0.0236\n",
      "\n",
      "EPOCHS : 17/50 - step - 2403 Loss : 0.023451\n",
      "The mean validation loss is 0.0240\n",
      "\n",
      "EPOCHS : 18/50 - step - 2492 Loss : 0.016121\n",
      "The mean validation loss is 0.0235\n",
      "\n",
      "EPOCHS : 19/50 - step - 2581 Loss : 0.001844\n",
      "The mean validation loss is 0.0240\n",
      "\n",
      "EPOCHS : 19/50 - step - 2670 Loss : 0.023297\n",
      "The mean validation loss is 0.0239\n",
      "\n",
      "EPOCHS : 20/50 - step - 2759 Loss : 0.010808\n",
      "The mean validation loss is 0.0235\n",
      "\n",
      "EPOCHS : 20/50 - step - 2848 Loss : 0.023443\n",
      "The mean validation loss is 0.0239\n",
      "\n",
      "EPOCHS : 21/50 - step - 2937 Loss : 0.019939\n",
      "The mean validation loss is 0.0233\n",
      "\n",
      "EPOCHS : 22/50 - step - 3026 Loss : 0.005982\n",
      "The mean validation loss is 0.0233\n",
      "\n",
      "EPOCHS : 22/50 - step - 3115 Loss : 0.023155\n",
      "The mean validation loss is 0.0236\n",
      "\n",
      "EPOCHS : 23/50 - step - 3204 Loss : 0.015220\n",
      "The mean validation loss is 0.0231\n",
      "\n",
      "EPOCHS : 24/50 - step - 3293 Loss : 0.001041\n",
      "The mean validation loss is 0.0237\n",
      "\n",
      "EPOCHS : 24/50 - step - 3382 Loss : 0.023108\n",
      "The mean validation loss is 0.0236\n",
      "\n",
      "EPOCHS : 25/50 - step - 3471 Loss : 0.010026\n",
      "The mean validation loss is 0.0231\n",
      "\n",
      "EPOCHS : 25/50 - step - 3560 Loss : 0.023019\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 26/50 - step - 3649 Loss : 0.019138\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 27/50 - step - 3738 Loss : 0.005187\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 27/50 - step - 3827 Loss : 0.022853\n",
      "The mean validation loss is 0.0235\n",
      "\n",
      "EPOCHS : 28/50 - step - 3916 Loss : 0.014271\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 29/50 - step - 4005 Loss : 0.000266\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 29/50 - step - 4094 Loss : 0.022798\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 30/50 - step - 4183 Loss : 0.009096\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 30/50 - step - 4272 Loss : 0.022736\n",
      "The mean validation loss is 0.0233\n",
      "\n",
      "EPOCHS : 31/50 - step - 4361 Loss : 0.018109\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 32/50 - step - 4450 Loss : 0.004302\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 32/50 - step - 4539 Loss : 0.022721\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 33/50 - step - 4628 Loss : 0.013250\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 33/50 - step - 4717 Loss : 0.022432\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 34/50 - step - 4806 Loss : 0.022096\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 35/50 - step - 4895 Loss : 0.008200\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 35/50 - step - 4984 Loss : 0.022721\n",
      "The mean validation loss is 0.0231\n",
      "\n",
      "EPOCHS : 36/50 - step - 5073 Loss : 0.017276\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 37/50 - step - 5162 Loss : 0.003517\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 37/50 - step - 5251 Loss : 0.022568\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 38/50 - step - 5340 Loss : 0.012305\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 38/50 - step - 5429 Loss : 0.022406\n",
      "The mean validation loss is 0.0225\n",
      "\n",
      "EPOCHS : 39/50 - step - 5518 Loss : 0.021087\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 40/50 - step - 5607 Loss : 0.007494\n",
      "The mean validation loss is 0.0225\n",
      "\n",
      "EPOCHS : 40/50 - step - 5696 Loss : 0.022270\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 41/50 - step - 5785 Loss : 0.016303\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 42/50 - step - 5874 Loss : 0.002722\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 42/50 - step - 5963 Loss : 0.022184\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 43/50 - step - 6052 Loss : 0.011406\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 43/50 - step - 6141 Loss : 0.022224\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 44/50 - step - 6230 Loss : 0.020312\n",
      "The mean validation loss is 0.0230\n",
      "\n",
      "EPOCHS : 45/50 - step - 6319 Loss : 0.006608\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 45/50 - step - 6408 Loss : 0.022233\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 46/50 - step - 6497 Loss : 0.015352\n",
      "The mean validation loss is 0.0224\n",
      "\n",
      "EPOCHS : 47/50 - step - 6586 Loss : 0.002015\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 47/50 - step - 6675 Loss : 0.022044\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 48/50 - step - 6764 Loss : 0.010792\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 48/50 - step - 6853 Loss : 0.021968\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 49/50 - step - 6942 Loss : 0.019203\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 50/50 - step - 7031 Loss : 0.005878\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 50/50 - step - 7120 Loss : 0.022044\n",
      "The mean validation loss is 0.0221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin3,train_dataloader,val_dataloaders,50,80,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=2.0,mname=\"LSTM_Chopin3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f736c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin3.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin3-run-1-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d1e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f5045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4964f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Chopin3 = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "LSTM_Chopin3.load_state_dict(torch.load(\"Handcrafted Dataset - One Hot Weights/LSTM_Chopin3-run-1-val_loss-LAST.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6074a81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b584225e63034e5e85787267c657d5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/50 - step - 89 Loss : 0.193799\n",
      "The mean validation loss is 0.0224\n",
      "\n",
      "EPOCHS : 2/50 - step - 178 Loss : 0.008614\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 2/50 - step - 267 Loss : 0.021991\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 3/50 - step - 356 Loss : 0.017111\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 4/50 - step - 445 Loss : 0.003999\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 4/50 - step - 534 Loss : 0.021925\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 5/50 - step - 623 Loss : 0.012526\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 5/50 - step - 712 Loss : 0.021938\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 6/50 - step - 801 Loss : 0.021075\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 7/50 - step - 890 Loss : 0.008070\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 7/50 - step - 979 Loss : 0.021909\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 8/50 - step - 1068 Loss : 0.016500\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 9/50 - step - 1157 Loss : 0.003137\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 9/50 - step - 1246 Loss : 0.021970\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 10/50 - step - 1335 Loss : 0.011713\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 10/50 - step - 1424 Loss : 0.022034\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 11/50 - step - 1513 Loss : 0.020444\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 12/50 - step - 1602 Loss : 0.007133\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 12/50 - step - 1691 Loss : 0.021938\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 13/50 - step - 1780 Loss : 0.015663\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 14/50 - step - 1869 Loss : 0.002455\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 14/50 - step - 1958 Loss : 0.021970\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 15/50 - step - 2047 Loss : 0.011200\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 15/50 - step - 2136 Loss : 0.021840\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 16/50 - step - 2225 Loss : 0.019636\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 17/50 - step - 2314 Loss : 0.006359\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 17/50 - step - 2403 Loss : 0.021864\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 18/50 - step - 2492 Loss : 0.015015\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 19/50 - step - 2581 Loss : 0.001679\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 19/50 - step - 2670 Loss : 0.021887\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 20/50 - step - 2759 Loss : 0.010266\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 20/50 - step - 2848 Loss : 0.021943\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 21/50 - step - 2937 Loss : 0.018998\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 22/50 - step - 3026 Loss : 0.005717\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 22/50 - step - 3115 Loss : 0.021855\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 23/50 - step - 3204 Loss : 0.014265\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 24/50 - step - 3293 Loss : 0.001019\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 24/50 - step - 3382 Loss : 0.022019\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 25/50 - step - 3471 Loss : 0.009548\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 25/50 - step - 3560 Loss : 0.022020\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 26/50 - step - 3649 Loss : 0.018243\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 27/50 - step - 3738 Loss : 0.004888\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 27/50 - step - 3827 Loss : 0.022023\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 28/50 - step - 3916 Loss : 0.013477\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 29/50 - step - 4005 Loss : 0.000268\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 29/50 - step - 4094 Loss : 0.021829\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 30/50 - step - 4183 Loss : 0.008847\n",
      "The mean validation loss is 0.0224\n",
      "\n",
      "EPOCHS : 30/50 - step - 4272 Loss : 0.021911\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 31/50 - step - 4361 Loss : 0.017462\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 32/50 - step - 4450 Loss : 0.004186\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 32/50 - step - 4539 Loss : 0.021883\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 33/50 - step - 4628 Loss : 0.012866\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 33/50 - step - 4717 Loss : 0.021866\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 34/50 - step - 4806 Loss : 0.021516\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 35/50 - step - 4895 Loss : 0.008068\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 35/50 - step - 4984 Loss : 0.021994\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 36/50 - step - 5073 Loss : 0.016663\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 37/50 - step - 5162 Loss : 0.003457\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 37/50 - step - 5251 Loss : 0.022037\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 38/50 - step - 5340 Loss : 0.012021\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 38/50 - step - 5429 Loss : 0.021990\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 39/50 - step - 5518 Loss : 0.020699\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 40/50 - step - 5607 Loss : 0.007523\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 40/50 - step - 5696 Loss : 0.021809\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 41/50 - step - 5785 Loss : 0.016007\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 42/50 - step - 5874 Loss : 0.002724\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 42/50 - step - 5963 Loss : 0.021871\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 43/50 - step - 6052 Loss : 0.011203\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 43/50 - step - 6141 Loss : 0.022013\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 44/50 - step - 6230 Loss : 0.020095\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 45/50 - step - 6319 Loss : 0.006641\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 45/50 - step - 6408 Loss : 0.021875\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 46/50 - step - 6497 Loss : 0.015451\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 47/50 - step - 6586 Loss : 0.001956\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 47/50 - step - 6675 Loss : 0.021846\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 48/50 - step - 6764 Loss : 0.010525\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 48/50 - step - 6853 Loss : 0.022056\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 49/50 - step - 6942 Loss : 0.019164\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 50/50 - step - 7031 Loss : 0.005968\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 50/50 - step - 7120 Loss : 0.021868\n",
      "The mean validation loss is 0.0223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin3,train_dataloader,val_dataloaders,50,80,\n",
    "      loss_fun,optimizer,'cuda',2,grad_clip=3.0,mname=\"LSTM_Chopin3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "668df6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin3.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin3-run-2-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465dd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fa05bfa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e05f57f2c9e4cac91d6874ef5151cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/50 - step - 143 Loss : 0.021927\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 2/50 - step - 286 Loss : 0.021906\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 3/50 - step - 429 Loss : 0.021935\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 4/50 - step - 572 Loss : 0.021942\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 5/50 - step - 715 Loss : 0.021931\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 6/50 - step - 858 Loss : 0.021949\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 7/50 - step - 1001 Loss : 0.021966\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 8/50 - step - 1144 Loss : 0.021923\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 9/50 - step - 1287 Loss : 0.021910\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 10/50 - step - 1430 Loss : 0.021955\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 11/50 - step - 1573 Loss : 0.021911\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 12/50 - step - 1716 Loss : 0.021946\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 13/50 - step - 1859 Loss : 0.021957\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 14/50 - step - 2002 Loss : 0.021939\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 15/50 - step - 2145 Loss : 0.021937\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 16/50 - step - 2288 Loss : 0.021960\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 17/50 - step - 2431 Loss : 0.021968\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 18/50 - step - 2574 Loss : 0.021907\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 19/50 - step - 2717 Loss : 0.021935\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 20/50 - step - 2860 Loss : 0.021920\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 21/50 - step - 3003 Loss : 0.021934\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 22/50 - step - 3146 Loss : 0.021928\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 23/50 - step - 3289 Loss : 0.021978\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 24/50 - step - 3432 Loss : 0.021907\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 25/50 - step - 3575 Loss : 0.021935\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 26/50 - step - 3718 Loss : 0.021923\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 27/50 - step - 3861 Loss : 0.021940\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 28/50 - step - 4004 Loss : 0.021913\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 29/50 - step - 4147 Loss : 0.021915\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 30/50 - step - 4290 Loss : 0.021927\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 31/50 - step - 4433 Loss : 0.021944\n",
      "The mean validation loss is 0.0229\n",
      "\n",
      "EPOCHS : 32/50 - step - 4576 Loss : 0.021918\n",
      "The mean validation loss is 0.0226\n",
      "\n",
      "EPOCHS : 33/50 - step - 4719 Loss : 0.021932\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 34/50 - step - 4862 Loss : 0.021879\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 35/50 - step - 5005 Loss : 0.021938\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 36/50 - step - 5148 Loss : 0.021987\n",
      "The mean validation loss is 0.0228\n",
      "\n",
      "EPOCHS : 37/50 - step - 5291 Loss : 0.021941\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 38/50 - step - 5434 Loss : 0.021981\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 39/50 - step - 5577 Loss : 0.021930\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 40/50 - step - 5720 Loss : 0.021916\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 41/50 - step - 5863 Loss : 0.021956\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 42/50 - step - 6006 Loss : 0.021922\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 43/50 - step - 6149 Loss : 0.021906\n",
      "The mean validation loss is 0.0223\n",
      "\n",
      "EPOCHS : 44/50 - step - 6292 Loss : 0.021932\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 45/50 - step - 6435 Loss : 0.021906\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 46/50 - step - 6578 Loss : 0.021983\n",
      "The mean validation loss is 0.0227\n",
      "\n",
      "EPOCHS : 47/50 - step - 6721 Loss : 0.021970\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 48/50 - step - 6864 Loss : 0.021946\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 49/50 - step - 7007 Loss : 0.021938\n",
      "The mean validation loss is 0.0221\n",
      "\n",
      "EPOCHS : 50/50 - step - 7150 Loss : 0.021930\n",
      "The mean validation loss is 0.0227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin3,train_dataloader,val_dataloaders,50,50,\n",
    "      loss_fun,optimizer,'cuda',3,grad_clip=3.0,mname=\"LSTM_Chopin3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "570042ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Chopin3.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Chopin3-run-3-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbcbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824f313c",
   "metadata": {},
   "source": [
    "# chopin3 with 3 composers - base model - 0.213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea382b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Chopin3 = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "LSTM_Chopin3.load_state_dict(torch.load(\"Handcrafted Dataset - One Hot Weights/LSTM_Chopin3-run-2-val_loss-LAST.pth\"))\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(LSTM_Chopin3.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286068b5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6169ed2e55e84ca383c9f01d3a6605cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/15 - step - 335 Loss : 0.022518\n",
      "The mean validation loss is 0.0222\n",
      "\n",
      "EPOCHS : 1/15 - step - 670 Loss : 0.022031\n",
      "The mean validation loss is 0.0220\n",
      "\n",
      "EPOCHS : 2/15 - step - 1005 Loss : 0.021838\n",
      "The mean validation loss is 0.0219\n",
      "\n",
      "EPOCHS : 2/15 - step - 1340 Loss : 0.021896\n",
      "The mean validation loss is 0.0219\n",
      "\n",
      "EPOCHS : 3/15 - step - 1675 Loss : 0.021590\n",
      "The mean validation loss is 0.0217\n",
      "\n",
      "EPOCHS : 3/15 - step - 2010 Loss : 0.021816\n",
      "The mean validation loss is 0.0217\n",
      "\n",
      "EPOCHS : 4/15 - step - 2345 Loss : 0.021542\n",
      "The mean validation loss is 0.0216\n",
      "\n",
      "EPOCHS : 4/15 - step - 2680 Loss : 0.021635\n",
      "The mean validation loss is 0.0216\n",
      "\n",
      "EPOCHS : 5/15 - step - 3015 Loss : 0.021382\n",
      "The mean validation loss is 0.0216\n",
      "\n",
      "EPOCHS : 5/15 - step - 3350 Loss : 0.021601\n",
      "The mean validation loss is 0.0217\n",
      "\n",
      "EPOCHS : 6/15 - step - 3685 Loss : 0.021267\n",
      "The mean validation loss is 0.0216\n",
      "\n",
      "EPOCHS : 6/15 - step - 4020 Loss : 0.021549\n",
      "The mean validation loss is 0.0216\n",
      "\n",
      "EPOCHS : 7/15 - step - 4355 Loss : 0.021174\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 7/15 - step - 4690 Loss : 0.021528\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 8/15 - step - 5025 Loss : 0.021072\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 8/15 - step - 5360 Loss : 0.021483\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 9/15 - step - 5695 Loss : 0.020919\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 9/15 - step - 6030 Loss : 0.021502\n",
      "The mean validation loss is 0.0215\n",
      "\n",
      "EPOCHS : 10/15 - step - 6365 Loss : 0.020834\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 10/15 - step - 6700 Loss : 0.021491\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 11/15 - step - 7035 Loss : 0.020765\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 11/15 - step - 7370 Loss : 0.021417\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 12/15 - step - 7705 Loss : 0.020653\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 12/15 - step - 8040 Loss : 0.021440\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 13/15 - step - 8375 Loss : 0.020575\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 13/15 - step - 8710 Loss : 0.021431\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 14/15 - step - 9045 Loss : 0.020492\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 14/15 - step - 9380 Loss : 0.021416\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 15/15 - step - 9715 Loss : 0.020421\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 15/15 - step - 10050 Loss : 0.021377\n",
      "The mean validation loss is 0.0213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Chopin3,train_dataloader,val_dataloaders,15,30,\n",
    "      loss_fun,optimizer,'cuda',4,grad_clip=1.0,mname=\"LSTM_Chopin3composer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bae953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51ec350",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc8f2fe23ed489fb7210244c12073ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/10 - step - 335 Loss : 0.021371\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 1/10 - step - 670 Loss : 0.021312\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 2/10 - step - 1005 Loss : 0.021289\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 2/10 - step - 1340 Loss : 0.021320\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 3/10 - step - 1675 Loss : 0.021185\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 3/10 - step - 2010 Loss : 0.021350\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 4/10 - step - 2345 Loss : 0.021202\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 4/10 - step - 2680 Loss : 0.021282\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 5/10 - step - 3015 Loss : 0.021047\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 5/10 - step - 3350 Loss : 0.021359\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 6/10 - step - 3685 Loss : 0.021146\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 6/10 - step - 4020 Loss : 0.021196\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 7/10 - step - 4355 Loss : 0.020883\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 7/10 - step - 4690 Loss : 0.021411\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 8/10 - step - 5025 Loss : 0.020974\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 8/10 - step - 5360 Loss : 0.021230\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 9/10 - step - 5695 Loss : 0.020820\n",
      "The mean validation loss is 0.0214\n",
      "\n",
      "EPOCHS : 9/10 - step - 6030 Loss : 0.021347\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 10/10 - step - 6365 Loss : 0.020783\n",
      "The mean validation loss is 0.0213\n",
      "\n",
      "EPOCHS : 10/10 - step - 6700 Loss : 0.021287\n",
      "The mean validation loss is 0.0213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(LSTM_Chopin3.parameters(),lr=1e-6)\n",
    "train_loss, val_loss = train(LSTM_Chopin3,train_dataloader,val_dataloaders,10,20,\n",
    "      loss_fun,optimizer,'cuda',5,grad_clip=1.0,mname=\"LSTM_Chopin3composer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead322f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3fdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ce64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a4daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f1d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eaa13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd4025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd08666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "316646f4",
   "metadata": {},
   "source": [
    "# Mozart "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cff0d9",
   "metadata": {},
   "source": [
    "## base - run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d59d417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Mozart = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "weights = torch.cuda.FloatTensor([1.0,3.0])\n",
    "loss_fun = nn.CrossEntropyLoss(weights)\n",
    "optimizer = optim.AdamW(LSTM_Mozart.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f421616",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfcf011a888464fa28f6a99469501bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/20 - step - 42 Loss : 0.883349\n",
      "The mean validation loss is 0.0983\n",
      "\n",
      "EPOCHS : 1/20 - step - 84 Loss : 0.247877\n",
      "The mean validation loss is 0.0442\n",
      "\n",
      "EPOCHS : 1/20 - step - 126 Loss : 0.042777\n",
      "The mean validation loss is 0.0415\n",
      "\n",
      "EPOCHS : 2/20 - step - 168 Loss : 0.041500\n",
      "The mean validation loss is 0.0401\n",
      "\n",
      "EPOCHS : 2/20 - step - 210 Loss : 0.040480\n",
      "The mean validation loss is 0.0395\n",
      "\n",
      "EPOCHS : 2/20 - step - 252 Loss : 0.039783\n",
      "The mean validation loss is 0.0390\n",
      "\n",
      "EPOCHS : 3/20 - step - 294 Loss : 0.039540\n",
      "The mean validation loss is 0.0396\n",
      "\n",
      "EPOCHS : 3/20 - step - 336 Loss : 0.039631\n",
      "The mean validation loss is 0.0394\n",
      "\n",
      "EPOCHS : 3/20 - step - 378 Loss : 0.038877\n",
      "The mean validation loss is 0.0383\n",
      "\n",
      "EPOCHS : 4/20 - step - 420 Loss : 0.039232\n",
      "The mean validation loss is 0.0384\n",
      "\n",
      "EPOCHS : 4/20 - step - 462 Loss : 0.038302\n",
      "The mean validation loss is 0.0381\n",
      "\n",
      "EPOCHS : 4/20 - step - 504 Loss : 0.038274\n",
      "The mean validation loss is 0.0384\n",
      "\n",
      "EPOCHS : 5/20 - step - 546 Loss : 0.038339\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 5/20 - step - 588 Loss : 0.038022\n",
      "The mean validation loss is 0.0375\n",
      "\n",
      "EPOCHS : 5/20 - step - 630 Loss : 0.038383\n",
      "The mean validation loss is 0.0385\n",
      "\n",
      "EPOCHS : 6/20 - step - 672 Loss : 0.037918\n",
      "The mean validation loss is 0.0371\n",
      "\n",
      "EPOCHS : 6/20 - step - 714 Loss : 0.037712\n",
      "The mean validation loss is 0.0372\n",
      "\n",
      "EPOCHS : 6/20 - step - 756 Loss : 0.037923\n",
      "The mean validation loss is 0.0372\n",
      "\n",
      "EPOCHS : 7/20 - step - 798 Loss : 0.037772\n",
      "The mean validation loss is 0.0368\n",
      "\n",
      "EPOCHS : 7/20 - step - 840 Loss : 0.037739\n",
      "The mean validation loss is 0.0373\n",
      "\n",
      "EPOCHS : 7/20 - step - 882 Loss : 0.037575\n",
      "The mean validation loss is 0.0375\n",
      "\n",
      "EPOCHS : 8/20 - step - 924 Loss : 0.037681\n",
      "The mean validation loss is 0.0370\n",
      "\n",
      "EPOCHS : 8/20 - step - 966 Loss : 0.037073\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 8/20 - step - 1008 Loss : 0.037399\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 9/20 - step - 1050 Loss : 0.037606\n",
      "The mean validation loss is 0.0382\n",
      "\n",
      "EPOCHS : 9/20 - step - 1092 Loss : 0.036839\n",
      "The mean validation loss is 0.0370\n",
      "\n",
      "EPOCHS : 9/20 - step - 1134 Loss : 0.037314\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 10/20 - step - 1176 Loss : 0.037624\n",
      "The mean validation loss is 0.0370\n",
      "\n",
      "EPOCHS : 10/20 - step - 1218 Loss : 0.037018\n",
      "The mean validation loss is 0.0369\n",
      "\n",
      "EPOCHS : 10/20 - step - 1260 Loss : 0.036975\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 11/20 - step - 1302 Loss : 0.037093\n",
      "The mean validation loss is 0.0365\n",
      "\n",
      "EPOCHS : 11/20 - step - 1344 Loss : 0.037044\n",
      "The mean validation loss is 0.0363\n",
      "\n",
      "EPOCHS : 11/20 - step - 1386 Loss : 0.036859\n",
      "The mean validation loss is 0.0366\n",
      "\n",
      "EPOCHS : 12/20 - step - 1428 Loss : 0.036868\n",
      "The mean validation loss is 0.0366\n",
      "\n",
      "EPOCHS : 12/20 - step - 1470 Loss : 0.037101\n",
      "The mean validation loss is 0.0367\n",
      "\n",
      "EPOCHS : 12/20 - step - 1512 Loss : 0.036844\n",
      "The mean validation loss is 0.0369\n",
      "\n",
      "EPOCHS : 13/20 - step - 1554 Loss : 0.037107\n",
      "The mean validation loss is 0.0374\n",
      "\n",
      "EPOCHS : 13/20 - step - 1596 Loss : 0.036556\n",
      "The mean validation loss is 0.0366\n",
      "\n",
      "EPOCHS : 13/20 - step - 1638 Loss : 0.036821\n",
      "The mean validation loss is 0.0367\n",
      "\n",
      "EPOCHS : 14/20 - step - 1680 Loss : 0.036618\n",
      "The mean validation loss is 0.0360\n",
      "\n",
      "EPOCHS : 14/20 - step - 1722 Loss : 0.036672\n",
      "The mean validation loss is 0.0364\n",
      "\n",
      "EPOCHS : 14/20 - step - 1764 Loss : 0.036711\n",
      "The mean validation loss is 0.0362\n",
      "\n",
      "EPOCHS : 15/20 - step - 1806 Loss : 0.036368\n",
      "The mean validation loss is 0.0366\n",
      "\n",
      "EPOCHS : 15/20 - step - 1848 Loss : 0.036666\n",
      "The mean validation loss is 0.0364\n",
      "\n",
      "EPOCHS : 15/20 - step - 1890 Loss : 0.036846\n",
      "The mean validation loss is 0.0371\n",
      "\n",
      "EPOCHS : 16/20 - step - 1932 Loss : 0.036327\n",
      "The mean validation loss is 0.0363\n",
      "\n",
      "EPOCHS : 16/20 - step - 1974 Loss : 0.036670\n",
      "The mean validation loss is 0.0370\n",
      "\n",
      "EPOCHS : 16/20 - step - 2016 Loss : 0.036573\n",
      "The mean validation loss is 0.0370\n",
      "\n",
      "EPOCHS : 17/20 - step - 2058 Loss : 0.036301\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 17/20 - step - 2100 Loss : 0.036485\n",
      "The mean validation loss is 0.0361\n",
      "\n",
      "EPOCHS : 17/20 - step - 2142 Loss : 0.036290\n",
      "The mean validation loss is 0.0365\n",
      "\n",
      "EPOCHS : 18/20 - step - 2184 Loss : 0.036480\n",
      "The mean validation loss is 0.0362\n",
      "\n",
      "EPOCHS : 18/20 - step - 2226 Loss : 0.036466\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 18/20 - step - 2268 Loss : 0.036452\n",
      "The mean validation loss is 0.0368\n",
      "\n",
      "EPOCHS : 19/20 - step - 2310 Loss : 0.036090\n",
      "The mean validation loss is 0.0364\n",
      "\n",
      "EPOCHS : 19/20 - step - 2352 Loss : 0.036349\n",
      "The mean validation loss is 0.0366\n",
      "\n",
      "EPOCHS : 19/20 - step - 2394 Loss : 0.036596\n",
      "The mean validation loss is 0.0368\n",
      "\n",
      "EPOCHS : 20/20 - step - 2436 Loss : 0.036481\n",
      "The mean validation loss is 0.0359\n",
      "\n",
      "EPOCHS : 20/20 - step - 2478 Loss : 0.036146\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 20/20 - step - 2520 Loss : 0.036169\n",
      "The mean validation loss is 0.0364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Mozart,train_dataloader,val_dataloaders,20,60,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=2.0,mname=\"LSTM_Mozart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46dd6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Mozart.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Mozart-run-1-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7601e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16af58b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7af3f09cfab459fb6809a18b6b9dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/20 - step - 42 Loss : 0.152289\n",
      "The mean validation loss is 0.0361\n",
      "\n",
      "EPOCHS : 1/20 - step - 84 Loss : 0.151962\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 1/20 - step - 126 Loss : 0.036097\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 2/20 - step - 168 Loss : 0.036163\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 2/20 - step - 210 Loss : 0.035818\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 2/20 - step - 252 Loss : 0.036171\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 3/20 - step - 294 Loss : 0.036019\n",
      "The mean validation loss is 0.0364\n",
      "\n",
      "EPOCHS : 3/20 - step - 336 Loss : 0.035975\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 3/20 - step - 378 Loss : 0.035936\n",
      "The mean validation loss is 0.0354\n",
      "\n",
      "EPOCHS : 4/20 - step - 420 Loss : 0.036149\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 4/20 - step - 462 Loss : 0.035953\n",
      "The mean validation loss is 0.0361\n",
      "\n",
      "EPOCHS : 4/20 - step - 504 Loss : 0.035743\n",
      "The mean validation loss is 0.0364\n",
      "\n",
      "EPOCHS : 5/20 - step - 546 Loss : 0.035736\n",
      "The mean validation loss is 0.0355\n",
      "\n",
      "EPOCHS : 5/20 - step - 588 Loss : 0.035726\n",
      "The mean validation loss is 0.0368\n",
      "\n",
      "EPOCHS : 5/20 - step - 630 Loss : 0.036192\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 6/20 - step - 672 Loss : 0.035746\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 6/20 - step - 714 Loss : 0.035686\n",
      "The mean validation loss is 0.0359\n",
      "\n",
      "EPOCHS : 6/20 - step - 756 Loss : 0.036010\n",
      "The mean validation loss is 0.0360\n",
      "\n",
      "EPOCHS : 7/20 - step - 798 Loss : 0.035697\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 7/20 - step - 840 Loss : 0.035924\n",
      "The mean validation loss is 0.0353\n",
      "\n",
      "EPOCHS : 7/20 - step - 882 Loss : 0.035877\n",
      "The mean validation loss is 0.0355\n",
      "\n",
      "EPOCHS : 8/20 - step - 924 Loss : 0.035380\n",
      "The mean validation loss is 0.0352\n",
      "\n",
      "EPOCHS : 8/20 - step - 966 Loss : 0.035957\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 8/20 - step - 1008 Loss : 0.035773\n",
      "The mean validation loss is 0.0353\n",
      "\n",
      "EPOCHS : 9/20 - step - 1050 Loss : 0.035732\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 9/20 - step - 1092 Loss : 0.035608\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 9/20 - step - 1134 Loss : 0.035574\n",
      "The mean validation loss is 0.0351\n",
      "\n",
      "EPOCHS : 10/20 - step - 1176 Loss : 0.035325\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 10/20 - step - 1218 Loss : 0.035592\n",
      "The mean validation loss is 0.0353\n",
      "\n",
      "EPOCHS : 10/20 - step - 1260 Loss : 0.035798\n",
      "The mean validation loss is 0.0354\n",
      "\n",
      "EPOCHS : 11/20 - step - 1302 Loss : 0.035592\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 11/20 - step - 1344 Loss : 0.035827\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 11/20 - step - 1386 Loss : 0.035530\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 12/20 - step - 1428 Loss : 0.035279\n",
      "The mean validation loss is 0.0352\n",
      "\n",
      "EPOCHS : 12/20 - step - 1470 Loss : 0.036060\n",
      "The mean validation loss is 0.0361\n",
      "\n",
      "EPOCHS : 12/20 - step - 1512 Loss : 0.035670\n",
      "The mean validation loss is 0.0355\n",
      "\n",
      "EPOCHS : 13/20 - step - 1554 Loss : 0.035704\n",
      "The mean validation loss is 0.0351\n",
      "\n",
      "EPOCHS : 13/20 - step - 1596 Loss : 0.035237\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 13/20 - step - 1638 Loss : 0.035659\n",
      "The mean validation loss is 0.0348\n",
      "\n",
      "EPOCHS : 14/20 - step - 1680 Loss : 0.035274\n",
      "The mean validation loss is 0.0355\n",
      "\n",
      "EPOCHS : 14/20 - step - 1722 Loss : 0.035625\n",
      "The mean validation loss is 0.0353\n",
      "\n",
      "EPOCHS : 14/20 - step - 1764 Loss : 0.035666\n",
      "The mean validation loss is 0.0359\n",
      "\n",
      "EPOCHS : 15/20 - step - 1806 Loss : 0.035466\n",
      "The mean validation loss is 0.0354\n",
      "\n",
      "EPOCHS : 15/20 - step - 1848 Loss : 0.035194\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 15/20 - step - 1890 Loss : 0.035579\n",
      "The mean validation loss is 0.0357\n",
      "\n",
      "EPOCHS : 16/20 - step - 1932 Loss : 0.035100\n",
      "The mean validation loss is 0.0350\n",
      "\n",
      "EPOCHS : 16/20 - step - 1974 Loss : 0.035460\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 16/20 - step - 2016 Loss : 0.035528\n",
      "The mean validation loss is 0.0355\n",
      "\n",
      "EPOCHS : 17/20 - step - 2058 Loss : 0.035456\n",
      "The mean validation loss is 0.0352\n",
      "\n",
      "EPOCHS : 17/20 - step - 2100 Loss : 0.035447\n",
      "The mean validation loss is 0.0346\n",
      "\n",
      "EPOCHS : 17/20 - step - 2142 Loss : 0.035201\n",
      "The mean validation loss is 0.0354\n",
      "\n",
      "EPOCHS : 18/20 - step - 2184 Loss : 0.035560\n",
      "The mean validation loss is 0.0358\n",
      "\n",
      "EPOCHS : 18/20 - step - 2226 Loss : 0.035299\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 18/20 - step - 2268 Loss : 0.035083\n",
      "The mean validation loss is 0.0350\n",
      "\n",
      "EPOCHS : 19/20 - step - 2310 Loss : 0.035211\n",
      "The mean validation loss is 0.0348\n",
      "\n",
      "EPOCHS : 19/20 - step - 2352 Loss : 0.035507\n",
      "The mean validation loss is 0.0352\n",
      "\n",
      "EPOCHS : 19/20 - step - 2394 Loss : 0.035155\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 20/20 - step - 2436 Loss : 0.035232\n",
      "The mean validation loss is 0.0351\n",
      "\n",
      "EPOCHS : 20/20 - step - 2478 Loss : 0.035536\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 20/20 - step - 2520 Loss : 0.035154\n",
      "The mean validation loss is 0.0349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_Mozart,train_dataloader,val_dataloaders,20,60,\n",
    "      loss_fun,optimizer,'cuda',2,grad_clip=2.0,mname=\"LSTM_Mozart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64a2f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Mozart.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_Mozart-run-2-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8936631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36548b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab79b87",
   "metadata": {},
   "source": [
    "# one song - waldstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce13c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_wald = MusicLSTM(input_size=88,embed_size=512,hidden_size=512,num_class=88).cuda()\n",
    "weights = torch.cuda.FloatTensor([1.0,3.0])\n",
    "loss_fun = nn.CrossEntropyLoss(weights)\n",
    "optimizer = optim.AdamW(LSTM_wald.parameters(),lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2177494a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37957dbbbb0f4ea9a35a2b8ae9defd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/10 - step - 129 Loss : 0.193240\n",
      "The mean validation loss is 0.1020\n",
      "\n",
      "EPOCHS : 1/10 - step - 258 Loss : 0.071592\n",
      "The mean validation loss is 0.0548\n",
      "\n",
      "EPOCHS : 2/10 - step - 387 Loss : 0.048751\n",
      "The mean validation loss is 0.0449\n",
      "\n",
      "EPOCHS : 2/10 - step - 516 Loss : 0.042844\n",
      "The mean validation loss is 0.0417\n",
      "\n",
      "EPOCHS : 3/10 - step - 645 Loss : 0.040303\n",
      "The mean validation loss is 0.0396\n",
      "\n",
      "EPOCHS : 3/10 - step - 774 Loss : 0.038814\n",
      "The mean validation loss is 0.0387\n",
      "\n",
      "EPOCHS : 4/10 - step - 903 Loss : 0.037712\n",
      "The mean validation loss is 0.0372\n",
      "\n",
      "EPOCHS : 4/10 - step - 1032 Loss : 0.036958\n",
      "The mean validation loss is 0.0372\n",
      "\n",
      "EPOCHS : 5/10 - step - 1161 Loss : 0.036394\n",
      "The mean validation loss is 0.0361\n",
      "\n",
      "EPOCHS : 5/10 - step - 1290 Loss : 0.035648\n",
      "The mean validation loss is 0.0356\n",
      "\n",
      "EPOCHS : 6/10 - step - 1419 Loss : 0.035330\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 6/10 - step - 1548 Loss : 0.034907\n",
      "The mean validation loss is 0.0349\n",
      "\n",
      "EPOCHS : 7/10 - step - 1677 Loss : 0.034596\n",
      "The mean validation loss is 0.0345\n",
      "\n",
      "EPOCHS : 7/10 - step - 1806 Loss : 0.034239\n",
      "The mean validation loss is 0.0341\n",
      "\n",
      "EPOCHS : 8/10 - step - 1935 Loss : 0.033935\n",
      "The mean validation loss is 0.0337\n",
      "\n",
      "EPOCHS : 8/10 - step - 2064 Loss : 0.033856\n",
      "The mean validation loss is 0.0336\n",
      "\n",
      "EPOCHS : 9/10 - step - 2193 Loss : 0.033648\n",
      "The mean validation loss is 0.0332\n",
      "\n",
      "EPOCHS : 9/10 - step - 2322 Loss : 0.033124\n",
      "The mean validation loss is 0.0333\n",
      "\n",
      "EPOCHS : 10/10 - step - 2451 Loss : 0.033089\n",
      "The mean validation loss is 0.0330\n",
      "\n",
      "EPOCHS : 10/10 - step - 2580 Loss : 0.033020\n",
      "The mean validation loss is 0.0331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_wald,train_dataloader,val_dataloaders,10,20,\n",
    "      loss_fun,optimizer,'cuda',1,grad_clip=2.0,mname=\"LSTM_wald\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef94759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_wald.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_wald-run-1-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dbcd94b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3500fe0e02f844719d9dcc60d1a90ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/10 - step - 129 Loss : 0.032910\n",
      "The mean validation loss is 0.0327\n",
      "\n",
      "EPOCHS : 1/10 - step - 258 Loss : 0.032703\n",
      "The mean validation loss is 0.0327\n",
      "\n",
      "EPOCHS : 2/10 - step - 387 Loss : 0.032636\n",
      "The mean validation loss is 0.0325\n",
      "\n",
      "EPOCHS : 2/10 - step - 516 Loss : 0.032496\n",
      "The mean validation loss is 0.0325\n",
      "\n",
      "EPOCHS : 3/10 - step - 645 Loss : 0.032548\n",
      "The mean validation loss is 0.0323\n",
      "\n",
      "EPOCHS : 3/10 - step - 774 Loss : 0.032261\n",
      "The mean validation loss is 0.0328\n",
      "\n",
      "EPOCHS : 4/10 - step - 903 Loss : 0.032323\n",
      "The mean validation loss is 0.0322\n",
      "\n",
      "EPOCHS : 4/10 - step - 1032 Loss : 0.032283\n",
      "The mean validation loss is 0.0324\n",
      "\n",
      "EPOCHS : 5/10 - step - 1161 Loss : 0.032238\n",
      "The mean validation loss is 0.0326\n",
      "\n",
      "EPOCHS : 5/10 - step - 1290 Loss : 0.032218\n",
      "The mean validation loss is 0.0326\n",
      "\n",
      "EPOCHS : 6/10 - step - 1419 Loss : 0.032175\n",
      "The mean validation loss is 0.0322\n",
      "\n",
      "EPOCHS : 6/10 - step - 1548 Loss : 0.032094\n",
      "The mean validation loss is 0.0322\n",
      "\n",
      "EPOCHS : 7/10 - step - 1677 Loss : 0.032058\n",
      "The mean validation loss is 0.0319\n",
      "\n",
      "EPOCHS : 7/10 - step - 1806 Loss : 0.032091\n",
      "The mean validation loss is 0.0321\n",
      "\n",
      "EPOCHS : 8/10 - step - 1935 Loss : 0.031992\n",
      "The mean validation loss is 0.0322\n",
      "\n",
      "EPOCHS : 8/10 - step - 2064 Loss : 0.031986\n",
      "The mean validation loss is 0.0321\n",
      "\n",
      "EPOCHS : 9/10 - step - 2193 Loss : 0.031944\n",
      "The mean validation loss is 0.0320\n",
      "\n",
      "EPOCHS : 9/10 - step - 2322 Loss : 0.031943\n",
      "The mean validation loss is 0.0318\n",
      "\n",
      "EPOCHS : 10/10 - step - 2451 Loss : 0.031917\n",
      "The mean validation loss is 0.0318\n",
      "\n",
      "EPOCHS : 10/10 - step - 2580 Loss : 0.031842\n",
      "The mean validation loss is 0.0323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(LSTM_wald,train_dataloader,val_dataloaders,10,20,\n",
    "      loss_fun,optimizer,'cuda',2,grad_clip=2.0,mname=\"LSTM_wald\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35ef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_wald.state_dict(),\n",
    " \"Handcrafted Dataset - One Hot Weights/LSTM_wald-run-2-val_loss-LAST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92710d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ddd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312a69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233cfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd28947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cea84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6767182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db8d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449155f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e950c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ed665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c97747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf54334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9ca92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8a4724",
   "metadata": {},
   "source": [
    "# Generate Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a3e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract hidden state given the beginning of a piece of music\n",
    "#  it should start from time step 0, extract the piano roll, take the first portion \n",
    "#   to generate hidden space and last prediction from the model\n",
    "def get_hidden(model, path,len_input_seq=200,ln=200,tmp=1,start_position=0):\n",
    "    # extract piano roll from the music and form one hot encoding\n",
    "    multitrack = pypianoroll.read(path)\n",
    "    multitrack.binarize()\n",
    "    combined_track = multitrack.blend()\n",
    "    # shrink the pitches and extract the part that we need\n",
    "    track_len = len(combined_track[:,0]) \n",
    "    # if track_len is less than the track they want\n",
    "    if (track_len < len_input_seq + start_position):\n",
    "        if (track_len < len_input_seq):\n",
    "            input_seq = combined_track[:,21:109] # take the entire trach\n",
    "        else:\n",
    "            input_seq = combined_track[start_position:,21:109] \n",
    "    else:\n",
    "        end_position = start_position + len_input_seq - 1\n",
    "        input_seq = combined_track[start_position:end_position,21:109]\n",
    "    \n",
    "    # input sequence must be a tensor\n",
    "    input_seq = torch.tensor(input_seq,dtype=torch.float)\n",
    "    \n",
    "    # model is in GPU\n",
    "    \n",
    "    # add batch dimension\n",
    "    input_seq = torch.unsqueeze(input_seq,0)\n",
    "    \n",
    "    op, hidden = model(input_seq) # note hidden state don't stack\n",
    "    \n",
    "    # only take the last observations of each\n",
    "    output = op[-88:]\n",
    "    probs = nn.functional.softmax(output.div(tmp), dim=1)\n",
    "    output = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "    output = output.float()\n",
    "    \n",
    "    #print(type(hidden))\n",
    "    #print(type(hidden[0]))\n",
    "    #print(type(hidden[0][0]))\n",
    "    #print(type(hidden[0][0][0]))\n",
    "    #print()\n",
    "\n",
    "    \n",
    "    # hidden size (2,2,200,512), should go with (2,2,1,512)\n",
    "    h,c = hidden\n",
    "    h = h[:,-1:,:]\n",
    "    c = c[:,-1:,:]\n",
    "    #print(h.shape)\n",
    "    \n",
    "    hidden = (h,c)\n",
    "    \n",
    "\n",
    "    return generate_music(model,output,hidden,ln,tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03cdfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract hidden state given the beginning of a piece of music\n",
    "#  it should start from time step 0, extract the piano roll, take the first portion \n",
    "#   to generate hidden space and last prediction from the model\n",
    "def get_hidden2(model, path,len_input_seq=200,ln=200,tmp=1):\n",
    "    # extract piano roll from the music and form one hot encoding\n",
    "    multitrack = pypianoroll.read(path)\n",
    "    multitrack.binarize()\n",
    "    combined_track = multitrack.blend()\n",
    "    # shrink the pitches and extract the part that we need\n",
    "    input_seq = combined_track[:len_input_seq,21:109]\n",
    "    \n",
    "    # input sequence must be a tensor\n",
    "    input_seq = torch.tensor(input_seq,dtype=torch.float)\n",
    "    \n",
    "    # model is in GPU\n",
    "    \n",
    "    # add batch dimension\n",
    "    input_seq = torch.unsqueeze(input_seq,0)\n",
    "    \n",
    "    #encode\n",
    "    input_seq_encode = model.notes_encoder(input_seq)\n",
    "    \n",
    "    op, hidden = model.lstm(input_seq_encode) # op(1,input_seq_len,hidden_size)\n",
    "    \n",
    "    # apply final dense layer\n",
    "    op = model.final(op) # op (1, input_seq_len, 88)\n",
    "    \n",
    "    final = op.transpose(0,1).contiguous()\n",
    "    \n",
    "    # create a second measure for prediction per class, shape(seq_len,batch,num_class)\n",
    "    neg_final = 1 - final\n",
    "    \n",
    "    # two \"predictions\" for each node\n",
    "    zero_one_final = torch.stack((final,neg_final),dim=3).contiguous()\n",
    "    \n",
    "    # flatten everything except for the two predictions dimension\n",
    "    flatten_final = zero_one_final.view(-1,2) \n",
    "    \n",
    "    # only take the last observations of each\n",
    "    output = flatten_final[-88:]\n",
    "    probs = nn.functional.softmax(output.div(tmp), dim=1)\n",
    "    output = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "    output = output.float()\n",
    "    \n",
    "    #print(type(hidden))\n",
    "    #print(type(hidden[0]))\n",
    "    #print(type(hidden[0][0]))\n",
    "    #print(type(hidden[0][0][0]))\n",
    "    #print()\n",
    "\n",
    "    \n",
    "    # hidden size (2,2,200,512), should go with (2,2,1,512)\n",
    "    h,c = hidden\n",
    "    h = h[:,-1:,:]\n",
    "    c = c[:,-1:,:]\n",
    "    #print(h.shape)\n",
    "    \n",
    "    hidden = (h,c)\n",
    "    \n",
    "\n",
    "    return generate_music(model,output,hidden,ln,tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7809665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate music based on the hidden state of the music\n",
    "def generate_music(model, start, hidden, ln=200, tmp=1):\n",
    "    seq_ip_cur = start\n",
    "        \n",
    "    op_seq = [seq_ip_cur.data.squeeze(1)]\n",
    "    hd = hidden\n",
    "\n",
    "    for i in range(ln):\n",
    "\n",
    "        # input sequence is predicted outputs\n",
    "        op, hd = model(seq_ip_cur, hd) # output is a vector of 88\n",
    "        \n",
    "        probs = nn.functional.softmax(op.div(tmp), dim=1)\n",
    "        \n",
    "        # update current sequence to the previous prediction\n",
    "        seq_ip_cur = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # the model accept input as tensor of floats\n",
    "        seq_ip_cur = seq_ip_cur.float()\n",
    "\n",
    "        # append outputs\n",
    "        op_seq.append(seq_ip_cur.data.squeeze(1))\n",
    "\n",
    "    gen_seq = torch.cat(op_seq, dim=0).cpu().numpy()\n",
    "    \n",
    "    return gen_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc69e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate music based on the hidden state of the music\n",
    "def generate_music2(model, start, hidden, ln=200, tmp=1):\n",
    "    seq_ip_cur = start\n",
    "        \n",
    "    op_seq = [seq_ip_cur.data.squeeze(1)]\n",
    "    hd = hidden\n",
    "\n",
    "    for i in range(ln):\n",
    "\n",
    "        # input sequence is predicted outputs\n",
    "        #encode\n",
    "        input_seq_encode = model.notes_encoder(seq_ip_cur)\n",
    "    \n",
    "        op, hd = model.lstm(input_seq_encode,hidden) # op(1,input_seq_len,hidden_size)\n",
    "    \n",
    "        # apply final dense layer\n",
    "        op = model.final(op) # op (1, input_seq_len, 88)\n",
    "        \n",
    "        final = op.transpose(0,1).contiguous()\n",
    "        # create a second measure for prediction per class, shape(seq_len,batch,num_class)\n",
    "        neg_final = 1 - final\n",
    "        # two \"predictions\" for each node\n",
    "        zero_one_final = torch.stack((final,neg_final),dim=3).contiguous()\n",
    "        # flatten everything except for the two predictions dimension\n",
    "        flatten_final = zero_one_final.view(-1,2) \n",
    "        \n",
    "        probs = nn.functional.softmax(flatten_final.div(tmp), dim=1)\n",
    "        \n",
    "        # update current sequence to the previous prediction\n",
    "        seq_ip_cur = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # the model accept input as tensor of floats\n",
    "        seq_ip_cur = seq_ip_cur.float()\n",
    "\n",
    "        # append outputs\n",
    "        op_seq.append(seq_ip_cur.data.squeeze(1))\n",
    "\n",
    "    gen_seq = torch.cat(op_seq, dim=0).cpu().numpy()\n",
    "    \n",
    "    return gen_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4be5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model,model_val,run,musicname=\"mz_330_1.mid\",len_input_seq=200,\n",
    "                    ln=200,tmp=1,model_name=\"LSTM_Chopin\",start_position=0):\n",
    "    weights_folder = \"Handcrafted Dataset - One Hot Weights/old weights\"\n",
    "    \n",
    "    # this is for simple version\n",
    "    #LSTM = model(input_size=88,embed_size=512,hidden_size=512,num_class=88).cpu() \n",
    "    \n",
    "    LSTM = model(88,512,512,88,2).cpu() \n",
    "    weights = model_name+\"-run-\"+str(run)+\"-val_loss-\"+model_val+ \".pth\"\n",
    "    weights_path = os.path.join(weights_folder,weights)\n",
    "    LSTM.load_state_dict(torch.load(weights_path))\n",
    "    \n",
    "\n",
    "    musicpath = \"Handcrafted Dataset - Generated Music/input/Classical/\" + musicname\n",
    "    LSTM.eval()\n",
    "    seq = get_hidden(LSTM,musicpath,len_input_seq,ln,tmp,start_position)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(seq.T)\n",
    "    \n",
    "    outputpath = 'Handcrafted Dataset - Generated Music/'+model_name+'/run'+str(run)+'-'+model_val+'-'+musicname\n",
    "    return seq, outputpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8885b",
   "metadata": {},
   "source": [
    "# Experiment - LSTM_Chopin3composer - Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8417a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MusicLSTM\n",
    "model_val = \"BEST\"\n",
    "run = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "685263e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handcrafted Dataset - Generated Music/LSTM_Chopin3composer/run4-BEST-mz_330_1.mid\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq,path=generate_sample(model,model_val,run,musicname=\"mz_330_1.mid\",len_input_seq=2000,\n",
    "                    ln=1000,tmp=1.,model_name=\"LSTM_Chopin3composer\",start_position=0)\n",
    "print(path)\n",
    "F.midiwrite(path, seq, dtm=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed149b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.midiwrite(path, seq, dtm=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chpn_op25_e1.mid\n",
    "liz_et3.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b4ee873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handcrafted Dataset - Generated Music/LSTM_Chopin3composer/run4-BEST-liz_et3.mid\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25969a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54133db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21baf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71783c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5969e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
