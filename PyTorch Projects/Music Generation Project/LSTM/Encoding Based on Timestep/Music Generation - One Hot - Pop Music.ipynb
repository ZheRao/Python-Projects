{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e040aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.autograd import Variable\n",
    "#import torch.utils.data as data\n",
    "#import os\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tqdm.auto import tqdm\n",
    "#import random\n",
    "#from torch import optim\n",
    "import math\n",
    "#import pypianoroll\n",
    "#import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15121072",
   "metadata": {},
   "source": [
    "# Customized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d1ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class customDataset(data.Dataset):\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        fnames = os.listdir(path)\n",
    "        fnames_ful = map(lambda fname: os.path.join(path, fname), fnames)\n",
    "        # hold a list of full file paths\n",
    "        self.fnames_ful = list(fnames_ful)\n",
    "        print(\"Total samples: \", len(self.fnames_ful))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fnames_ful)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fnames_ful = self.fnames_ful[index]\n",
    "        roll = pd.read_csv(fnames_ful,header=None)\n",
    "        roll = np.array(roll)\n",
    "        # input sequence is from first element til the second last so that\n",
    "        #  the model could predict from the second element til the last one\n",
    "        input_seq = roll[:-1,:]\n",
    "        # we expect the model to predict the final 10 elements\n",
    "        output_seq = roll[1:,:]\n",
    "        #output_seq = roll[1:,:]\n",
    "        return (input_seq,output_seq)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4ad6f",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fae955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  28375\n"
     ]
    }
   ],
   "source": [
    "path = \"Pop-music - One Hot/Train\"\n",
    "\n",
    "train_dataset = customDataset(path)\n",
    "train_dataloader = data.DataLoader(train_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518dc525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1999, 88])\n",
      "torch.Size([32, 1999, 88])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "X_train=next(iter(train_dataloader))\n",
    "print(X_train[0].shape) # input seq\n",
    "print(X_train[1].shape) # output seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593f05e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  4350\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "\n",
    "path = \"Pop-music - One Hot/Val\"\n",
    "#val_dataset = customDataset(path)\n",
    "val_dataset = customDataset(path)\n",
    "# seperate val set into 5 sets because validate 40,000 every time is too much\n",
    "#  now it would only validate on 8,000\n",
    "set1 = list(range(0,len(val_dataset),3))\n",
    "set2 = list(range(1,len(val_dataset),3))\n",
    "set3 = list(range(2,len(val_dataset),3))\n",
    "#set4 = list(range(3,len(val_dataset),5))\n",
    "#set5 = list(range(4,len(val_dataset),5))\n",
    "\n",
    "val1 = data.Subset(val_dataset,set1)\n",
    "val2 = data.Subset(val_dataset,set2)\n",
    "val3 = data.Subset(val_dataset,set3)\n",
    "#val4 = data.Subset(val_dataset,set4)\n",
    "#val5 = data.Subset(val_dataset,set5)\"\"\n",
    "\n",
    "size = 64\n",
    "val_dataloader1 = data.DataLoader(val1,batch_size=size,shuffle=True)\n",
    "val_dataloader2 = data.DataLoader(val2,batch_size=size,shuffle=True)\n",
    "val_dataloader3 = data.DataLoader(val3,batch_size=size,shuffle=True)\n",
    "#val_dataloader4 = data.DataLoader(val4,batch_size=size,shuffle=True)\n",
    "#val_dataloader5 = data.DataLoader(val5,batch_size=size,shuffle=True)\n",
    "\n",
    "val_dataloaders = [val_dataloader1,\n",
    "               val_dataloader2,\n",
    "                val_dataloader3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41bb28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1999, 88])\n",
      "torch.Size([64, 1999, 88])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "X_val = next(iter(val_dataloader1))\n",
    "print(X_val[0].shape) # input seq\n",
    "print(X_val[1].shape) # output seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877befb",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6800a347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5d0514b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Matrix representation of a pop music composition\")\n",
    "plt.imshow(X_train[0][4][:1000].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a52cfb",
   "metadata": {},
   "source": [
    "# Training and validation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4547161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,val_loader,device,loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    steps = 0\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        steps += 1\n",
    "        input_seq, output_seq = batch\n",
    "        input_seq, output_seq = input_seq.to(device), output_seq.to(device)\n",
    "        # try to fix error :\"addmm_cuda\" not implemented for 'Long'\n",
    "        input_seq = input_seq.float()\n",
    "        \n",
    "        output_seq = output_seq.transpose(0,1).contiguous()\n",
    "        output_seq = output_seq.contiguous().view(-1)\n",
    "        \n",
    "        final,_ = model(input_seq)\n",
    "        # try to fix:\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'\n",
    "        #final, output_seq = final.double(),output_seq.double()\n",
    "        loss = loss_fn(final,output_seq)\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    print(\"The mean validation loss is %.6f\" % (val_loss/steps))\n",
    "    print()\n",
    "    return val_loss/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6132b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainloader,valloaders,ep,print_freq,loss_fun,\n",
    "          optimizer,device,run,grad_clip=1.0,mname=\"LSTM\"):\n",
    "    val_loss_best = float(\"inf\")\n",
    "    \n",
    "    # total number of training steps\n",
    "    num_steps = ep * (len(trainloader))\n",
    "    progress_bar = tqdm(range(num_steps))\n",
    "    \n",
    "    # calculate how often print the result\n",
    "    #  if num_step = 12, and print_freq = 3, then print every 4 steps\n",
    "    print_every = math.floor(num_steps/print_freq)\n",
    "    \n",
    "    # initialize\n",
    "    steps = 0\n",
    "    #model.to(device) ## error when run this twice\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    which_val = 0\n",
    "    \n",
    "    for e in range(ep):\n",
    "        current_loss = 0\n",
    "        for batch in trainloader:\n",
    "            input_s, output_s = batch\n",
    "            steps += 1\n",
    "            input_seq, output_seq = input_s.to(device), output_s.to(device)\n",
    "            # try to fix error :\"addmm_cuda\" not implemented for 'Long'\n",
    "            #  note: output_seq should stay long (int)\n",
    "            input_seq = input_seq.float()\n",
    "            #print(\"input shape: \",input_seq.shape)\n",
    "            \n",
    "            output_seq = output_seq.transpose(0,1).contiguous()\n",
    "            #print(\"original output shape: \", output_seq.shape)\n",
    "            output_seq = output_seq.contiguous().view(-1)\n",
    "\n",
    "            \n",
    "            # calculate grad and update\n",
    "            optimizer.zero_grad()\n",
    "            final,_ = model(input_seq)\n",
    "            loss = loss_fun(final, output_seq)\n",
    "            #print(\"loss: \", loss)\n",
    "            train_losses.append(loss.item())\n",
    "            current_loss += loss.item()\n",
    "            #print(current_loss)\n",
    "            # update parameter\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),grad_clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update progress bar\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            # print if reach the threshold we want\n",
    "            if steps % print_every == 0:\n",
    "                # training loss: divided by the number of steps taken during training\n",
    "                #  from last print to current print\n",
    "                print('EPOCHS : {}/{}'.format(e+1,ep),\n",
    "                          'Loss : {:.6f}'.format(current_loss/print_every))\n",
    "\n",
    "                current_loss = 0\n",
    "                #which_val = random.randint(0,4)\n",
    "                which_val = random.randint(0,2) # now I only have 2 val sets\n",
    "                # val loss: divided by the number of steps taken when validate\n",
    "                val_loss = evaluate(model,valloaders[which_val],device,loss_fun)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                # add call back\n",
    "                if val_loss < val_loss_best:\n",
    "                    val_loss_best = val_loss\n",
    "                    torch.save(model.state_dict(),\n",
    "                     \"Handcrafted Dataset - One Hot Weights/\"+mname+\"-run-{}-val_loss-BEST.pth\".format(run))\n",
    "            model.train()\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0232b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50c673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopBaseLSTM(nn.Module):\n",
    "    def __init__(self, input_size = 88, embed_size = 256, hidden_size = 512, \n",
    "                  num_class = 88, layers = 1):\n",
    "        super(PopBaseLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_class = num_class\n",
    "        self.layers = layers\n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=embed_size)\n",
    "        self.layernorm_encoder = nn.LayerNorm(embed_size)\n",
    "        self.layernorm_lstm = nn.LayerNorm(hidden_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,layers)\n",
    "        self.final = nn.Linear(hidden_size,num_class)\n",
    "\n",
    "        \n",
    "    def forward(self,sequences,hidden=None):\n",
    "        # seq shape (batch,seq_len,88)\n",
    "        notes_encoded = self.notes_encoder(sequences) # shape (batch,seq_len,embed_size)\n",
    "        #notes_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
    "                                                      # shape (seq_len,embed_size,batch)\n",
    "        notes_rolled = notes_encoded\n",
    "        notes_lnormed = self.layernorm_encoder(notes_rolled)\n",
    "        notes_lnormed = nn.Dropout(0.1)(notes_lnormed)\n",
    "        #notes = notes_lnormed.permute(2,0,1)          # shape (batch,seq_len,embed_size)\n",
    "        notes = notes_lnormed\n",
    "        \n",
    "        # output shape (batch,seq_len,hidden_size)\n",
    "        output, hidden = self.lstm(notes,hidden)\n",
    "        \n",
    "        #output_lnormed = self.layernorm_lstm(output.permute(1,2,0).contiguous())\n",
    "        output_lnormed = self.layernorm_lstm(output)\n",
    "        output_lnormed = nn.Dropout(0.1)(output_lnormed)\n",
    "        \n",
    "\n",
    "        \n",
    "        # only take the final 1000\n",
    "        #output_lnormed = output_lnormed[:,-1000:,:] \n",
    "        \n",
    "        # final shape (batch,200,num_class)\n",
    "        #final = self.final(output_lnormed.permute(2,0,1))\n",
    "        final = self.final(output_lnormed) # final (batch,200,hidden_size) --> \n",
    "                                            #                 (batch,200,88)\n",
    "        \n",
    "        ###\n",
    "        #final = self.relu(final)\n",
    "        #final = nn.Dropout(0.5)(final)\n",
    "        #final = self.final2(final)\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        \n",
    "        # final shape (200,batch,88)\n",
    "        final = final.transpose(0,1).contiguous()\n",
    "        #print(\"original final shape: \", final.shape)\n",
    "        \n",
    "        # create a second measure for prediction per class, shape(seq_len,batch,num_class)\n",
    "        neg_final = 1 - final\n",
    "        \n",
    "        # two \"predictions\" for each node\n",
    "        zero_one_final = torch.stack((final,neg_final),dim=3).contiguous()\n",
    "        \n",
    "        # flatten everything except for the two predictions dimension\n",
    "        flatten_final = zero_one_final.view(-1,2)\n",
    "        \n",
    "        return flatten_final, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d33a8",
   "metadata": {},
   "source": [
    "# BaseLSTM1 - length 2000\n",
    "batchsize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4b053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PopBaseLSTM1 = PopBaseLSTM(input_size = 88, embed_size = 256, hidden_size = 512, \n",
    "                  num_class = 88, layers = 1).cuda()\n",
    "optimizer = optim.AdamW(PopBaseLSTM1.parameters(),lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773e6af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f51dc429aa4e0095b035f00398d910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/1 Loss : 0.421925\n",
      "The mean validation loss is 0.0654\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.155907\n",
      "The mean validation loss is 0.0340\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.103671\n",
      "The mean validation loss is 0.0172\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.072764\n",
      "The mean validation loss is 0.0098\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.055441\n",
      "The mean validation loss is 0.0061\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.045409\n",
      "The mean validation loss is 0.0041\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.038642\n",
      "The mean validation loss is 0.0030\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.034670\n",
      "The mean validation loss is 0.0023\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.031799\n",
      "The mean validation loss is 0.0018\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.029651\n",
      "The mean validation loss is 0.0015\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.027696\n",
      "The mean validation loss is 0.0013\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.027029\n",
      "The mean validation loss is 0.0011\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.026093\n",
      "The mean validation loss is 0.0011\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.025644\n",
      "The mean validation loss is 0.0010\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.024760\n",
      "The mean validation loss is 0.0009\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.024473\n",
      "The mean validation loss is 0.0009\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.024279\n",
      "The mean validation loss is 0.0009\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.024119\n",
      "The mean validation loss is 0.0009\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023530\n",
      "The mean validation loss is 0.0010\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023644\n",
      "The mean validation loss is 0.0010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(PopBaseLSTM1,train_dataloader,val_dataloaders,1,20,loss_fn,\n",
    "          optimizer,\"cuda\",1,grad_clip=1.0,mname=\"PopBaseLSTM1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7945f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b599f09ecd84f4bb2e30459e35a2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/1 Loss : 0.023773\n",
      "The mean validation loss is 0.000904\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023744\n",
      "The mean validation loss is 0.000903\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023781\n",
      "The mean validation loss is 0.000916\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023469\n",
      "The mean validation loss is 0.000937\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023208\n",
      "The mean validation loss is 0.000984\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.023055\n",
      "The mean validation loss is 0.001014\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.022995\n",
      "The mean validation loss is 0.001048\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.022740\n",
      "The mean validation loss is 0.001102\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.022962\n",
      "The mean validation loss is 0.001160\n",
      "\n",
      "EPOCHS : 1/1 Loss : 0.022977\n",
      "The mean validation loss is 0.001249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(PopBaseLSTM1.parameters(),lr=5e-6)\n",
    "PopBaseLSTM1.load_state_dict(torch.load(\"Handcrafted Dataset - One Hot Weights/PopBaseLSTM1-run-1-val_loss-BEST.pth\"))\n",
    "train_loss, val_loss = train(PopBaseLSTM1,train_dataloader,val_dataloaders,1,10,loss_fn,\n",
    "          optimizer,\"cuda\",2,grad_clip=1.0,mname=\"PopBaseLSTM1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5718378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612485aaf4c54cd5a8290a6037297abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/4 Loss : 0.022732\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.01 GiB (GPU 0; 6.00 GiB total capacity; 2.02 GiB already allocated; 623.38 MiB free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19488/2675052487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_loss, val_loss = train(PopBaseLSTM1,train_dataloader,val_dataloaders,4,20,loss_fn,\n\u001b[0m\u001b[0;32m      2\u001b[0m           optimizer,\"cuda\",3,grad_clip=1.0,mname=\"PopBaseLSTM1\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19488/3608770942.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, valloaders, ep, print_freq, loss_fun, optimizer, device, run, grad_clip, mname)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mwhich_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# now I only have 2 val sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;31m# val loss: divided by the number of steps taken when validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwhich_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[0mval_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19488/3302521162.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, val_loader, device, loss_fn)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moutput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mfinal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m# try to fix:\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#final, output_seq = final.double(),output_seq.double()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19488/2825187188.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sequences, hidden)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# output shape (batch,seq_len,hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m#output_lnormed = self.layernorm_lstm(output.permute(1,2,0).contiguous())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.01 GiB (GPU 0; 6.00 GiB total capacity; 2.02 GiB already allocated; 623.38 MiB free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(PopBaseLSTM1,train_dataloader,val_dataloaders,4,20,loss_fn,\n",
    "          optimizer,\"cuda\",3,grad_clip=1.0,mname=\"PopBaseLSTM1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de382fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59ea7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e130d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4039ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ec92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1da5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ceef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5fbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bb3695f",
   "metadata": {},
   "source": [
    "# Generate Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83aa554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract hidden state given the beginning of a piece of music\n",
    "#  it should start from time step 0, extract the piano roll, take the first portion \n",
    "#   to generate hidden space and last prediction from the model\n",
    "def get_hidden(model, path,len_input_seq=200,ln=200,tmp=1,start_position=0):\n",
    "    # extract piano roll from the music and form one hot encoding\n",
    "    multitrack = pypianoroll.read(path)\n",
    "    multitrack.binarize()\n",
    "    combined_track = multitrack.blend()\n",
    "    # shrink the pitches and extract the part that we need\n",
    "    track_len = len(combined_track[:,0]) \n",
    "    # if track_len is less than the track they want\n",
    "    if (track_len < len_input_seq + start_position):\n",
    "        if (track_len < len_input_seq):\n",
    "            input_seq = combined_track[:,21:109] # take the entire trach\n",
    "        else:\n",
    "            input_seq = combined_track[start_position:,21:109] \n",
    "    else:\n",
    "        end_position = start_position + len_input_seq - 1\n",
    "        input_seq = combined_track[start_position:end_position,21:109]\n",
    "    \n",
    "    # input sequence must be a tensor\n",
    "    input_seq = torch.tensor(input_seq,dtype=torch.float)\n",
    "    \n",
    "    # add batch dimension\n",
    "    input_seq = torch.unsqueeze(input_seq,0)\n",
    "    \n",
    "    op, hidden = model(input_seq) # note hidden state don't stack\n",
    "    \n",
    "    # only take the last observations of each\n",
    "    output = op[-88:]\n",
    "    probs = nn.functional.softmax(output.div(tmp), dim=1)\n",
    "    output = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "    output = output.float()\n",
    " \n",
    "    # hidden size (2,2,200,512), should go with (2,2,1,512)\n",
    "    h,c = hidden\n",
    "    h = h[:,-1:,:]\n",
    "    c = c[:,-1:,:]\n",
    "    hidden = (h,c)\n",
    "    \n",
    "    return generate_music(model,output,hidden,ln,tmp)\n",
    "\n",
    "# define a function to generate music based on the hidden state of the music\n",
    "def generate_music(model, start, hidden, ln=200, tmp=1):\n",
    "    seq_ip_cur = start\n",
    "        \n",
    "    op_seq = [seq_ip_cur.data.squeeze(1)]\n",
    "    hd = hidden\n",
    "\n",
    "    for i in range(ln):\n",
    "\n",
    "        # input sequence is predicted outputs\n",
    "        op, hd = model(seq_ip_cur, hd) # output is a vector of 88\n",
    "        #print(\"output: \",op)\n",
    "        \n",
    "        probs = nn.functional.softmax(op.div(tmp), dim=1)\n",
    "        #print(\"probabilities: \",probs)\n",
    "        \n",
    "        # update current sequence to the previous prediction\n",
    "        seq_ip_cur = torch.multinomial(probs.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # the model accept input as tensor of floats\n",
    "        seq_ip_cur = seq_ip_cur.float()\n",
    "        #print(\"updated sequence: \", seq_ip_cur.data.squeeze(1))\n",
    "\n",
    "        # append outputs\n",
    "        op_seq.append(seq_ip_cur.data.squeeze(1))\n",
    "\n",
    "    gen_seq = torch.cat(op_seq, dim=0).cpu().numpy()\n",
    "    \n",
    "    return gen_seq\n",
    "\n",
    "def generate_sample(model,model_val,run,musicname=\"mz_330_1.mid\",len_input_seq=200,\n",
    "                    ln=200,tmp=1,model_name=\"LSTM_Chopin\",start_position=0):\n",
    "    weights_folder = \"Handcrafted Dataset - One Hot Weights\"\n",
    "    \n",
    "    # this is for simple version\n",
    "    #LSTM = model(input_size=88,embed_size=512,hidden_size=512,num_class=88).cpu() \n",
    "    \n",
    "    LSTM = model(88,256,512,88,1).cpu() \n",
    "    weights = model_name+\"-run-\"+str(run)+\"-val_loss-\"+model_val+ \".pth\"\n",
    "    weights_path = os.path.join(weights_folder,weights)\n",
    "    LSTM.load_state_dict(torch.load(weights_path))\n",
    "    \n",
    "\n",
    "    musicpath = \"Handcrafted Dataset - Generated Music/input/Pop/\" + musicname\n",
    "    LSTM.eval()\n",
    "    seq = get_hidden(LSTM,musicpath,len_input_seq,ln,tmp,start_position)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(seq.T)\n",
    "    \n",
    "    outputpath = 'Handcrafted Dataset - Generated Music/'+model_name+'/run'+str(run)+'-'+model_val+'-'+musicname\n",
    "    return seq, outputpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc76b0f",
   "metadata": {},
   "source": [
    "### PopBaseLSTM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3ca0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handcrafted Dataset - Generated Music/PopBaseLSTM1/run1-BEST-Someone_you_loved.midi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PopBaseLSTM\n",
    "model_val = \"BEST\"\n",
    "run = 1\n",
    "seq,path=generate_sample(model,model_val,run,musicname=\"Someone_you_loved.midi\",\n",
    "            len_input_seq=20,ln=1000,tmp=1,model_name=\"PopBaseLSTM1\",start_position=0)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48a96387",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.midiwrite(path, seq, dtm=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0d24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213f692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714fcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8badf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9b736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61889078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
