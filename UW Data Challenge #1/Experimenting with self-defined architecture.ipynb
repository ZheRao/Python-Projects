{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c393f5c",
   "metadata": {},
   "source": [
    "# experiments on image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "4caa52de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=280x280 at 0x261AE970E20>"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import requierd libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Read the input image\n",
    "img = Image.open('train/113.jpg')\n",
    "transform = transforms.Resize(280)\n",
    "transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "3cc793b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x261AE9B78E0>"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define the transform to apply random affine\n",
    "transform = transforms.Compose([\n",
    "                          transforms.RandomResizedCrop(280,scale=(0.8,1.2)),\n",
    "                          transforms.CenterCrop(224),\n",
    "                          transforms.RandomHorizontalFlip()])\n",
    "\n",
    "# apply the above defined transform on the input image\n",
    "transform(img)\n",
    "\n",
    "# display the transformed image\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd36279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9cf41a2",
   "metadata": {},
   "source": [
    "# prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0303ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL\n",
    "import os\n",
    "from IPython.display import Image \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e823fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5ffeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data, test_size=0.2, random_state=1,stratify=data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d59a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38897</th>\n",
       "      <td>38897</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24035</th>\n",
       "      <td>24035</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27492</th>\n",
       "      <td>27492</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>5994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14389</th>\n",
       "      <td>14389</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46328</th>\n",
       "      <td>46328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14888</th>\n",
       "      <td>14888</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45597</th>\n",
       "      <td>45597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10841</th>\n",
       "      <td>10841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24161</th>\n",
       "      <td>24161</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "38897  38897      7\n",
       "24035  24035      2\n",
       "27492  27492      9\n",
       "5994    5994      4\n",
       "14389  14389      6\n",
       "...      ...    ...\n",
       "46328  46328      5\n",
       "14888  14888      9\n",
       "45597  45597      0\n",
       "10841  10841      1\n",
       "24161  24161      6\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f48f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bf7fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38897</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24035</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27492</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14389</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>46328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>14888</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>45597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>10841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>24161</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "0      38897      7\n",
       "1      24035      2\n",
       "2      27492      9\n",
       "3       5994      4\n",
       "4      14389      6\n",
       "...      ...    ...\n",
       "39995  46328      5\n",
       "39996  14888      9\n",
       "39997  45597      0\n",
       "39998  10841      1\n",
       "39999  24161      6\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae09a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformers = {\"train\": transforms.Compose([\n",
    "                                       transforms.RandomResizedCrop(64),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,0.456,0.406],\n",
    "                                             [0.229,0.224,0.225])]),\n",
    "            \"val\":transforms.Compose([transforms.Resize(68),\n",
    "                          transforms.CenterCrop(64),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize([0.485,0.456,0.406],\n",
    "                                     [0.229,0.224,0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cea185",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformers2 = {\"train\": transforms.Compose([transforms.RandomResizedCrop(280,scale=(0.8,1.2)),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,0.456,0.406],\n",
    "                                             [0.229,0.224,0.225])]),\n",
    "            \"val\":transforms.Compose([transforms.Resize(256),\n",
    "                          transforms.CenterCrop(224),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize([0.485,0.456,0.406],\n",
    "                                     [0.229,0.224,0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13539d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_df, images_folder, transform=None):\n",
    "        self.df = csv_df\n",
    "        self.image_folder = images_folder\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df[\"id\"][index]\n",
    "        label = self.df[\"label\"][index]\n",
    "        image = PIL.Image.open(self.image_folder+str(filename)+\".jpg\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a67a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_df, \"./train/\",transform=data_transformers[\"train\"])\n",
    "val_data = CustomDataset(val_df, \"./train/\", transform=data_transformers[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49ca655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128,shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size =128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c650461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(model,dataloader,epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.cuda() \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad(): \n",
    "        for data in dataloader:\n",
    "           \n",
    "            images,labels = data\n",
    "            images,labels = images.to('cuda'),labels.to('cuda')\n",
    "            \n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1) \n",
    "            loss = criterion(outputs,labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    print(\"The validation loss is %.4f\" % (total_loss/len(dataloader)))\n",
    "    print('The valudation accuracy is {:.4f}\\n'.format(correct/total))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "def train(model,trainloader,epochs,print_every,criterion,optimizer,device,name):\n",
    "    num_training_steps = epochs * (len(trainloader))\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    epochs = epochs \n",
    "    print_every = math.floor(num_training_steps/print_every)\n",
    "    steps = 0\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    name = name\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        #running_loss = 0\n",
    "        for ii , (inputs,labels) in enumerate(trainloader):\n",
    "            steps += 1\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            # 前馈及反馈\n",
    "            outputs = model(inputs) \n",
    "            \n",
    "            _, predicted = torch.max(outputs.data,1) \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            #print(labels.size(),outputs.size())\n",
    "            loss = criterion(outputs,labels) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            \n",
    "            running_loss += loss.item() # maybe accumulate loss for steps?\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            if steps % print_every == 0:\n",
    "                #test the accuracy\n",
    "                print('EPOCHS : {}/{}'.format(e+1,epochs),\n",
    "                      'Loss : {:.6f}'.format(running_loss/print_every)) # this is a simgle loss divided by print_every\n",
    "                print('The training accuracy is {:.4f}'.format(correct/total))\n",
    "                running_loss=0\n",
    "                accuracy_test(model,val_loader,e)\n",
    "                #print(\"training accuracy: \\n\")\n",
    "                #accuracy_test(model,trainloader)\n",
    "    torch.save(model.state_dict(), \"Weights/myCNN_experiment1_cont_{}.pkl\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2733675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ffab8",
   "metadata": {},
   "source": [
    "# Base model - train 60%/1.11 - val 68%/0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86aa6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "class CNN_base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_base,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e2fd6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a64ca785",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_base(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_base = CNN_base()\n",
    "myCNN_base.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "148380b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a9b8f4a29748769c5e006db67db91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.244158\n",
      "The training accuracy is 0.1578\n",
      "The validation loss is 2.0855\n",
      "The valudation accuracy is 0.2429\n",
      "\n",
      "EPOCHS : 1/12 Loss : 2.068363\n",
      "The training accuracy is 0.1972\n",
      "The validation loss is 1.9672\n",
      "The valudation accuracy is 0.2888\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.971949\n",
      "The training accuracy is 0.2278\n",
      "The validation loss is 1.8683\n",
      "The valudation accuracy is 0.3358\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.910037\n",
      "The training accuracy is 0.2472\n",
      "The validation loss is 1.8002\n",
      "The valudation accuracy is 0.3653\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.841797\n",
      "The training accuracy is 0.2636\n",
      "The validation loss is 1.7199\n",
      "The valudation accuracy is 0.3907\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.788809\n",
      "The training accuracy is 0.2781\n",
      "The validation loss is 1.6700\n",
      "The valudation accuracy is 0.3988\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.763290\n",
      "The training accuracy is 0.2898\n",
      "The validation loss is 1.6854\n",
      "The valudation accuracy is 0.3972\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.745563\n",
      "The training accuracy is 0.2997\n",
      "The validation loss is 1.6158\n",
      "The valudation accuracy is 0.4277\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.696932\n",
      "The training accuracy is 0.3095\n",
      "The validation loss is 1.6168\n",
      "The valudation accuracy is 0.4299\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.691732\n",
      "The training accuracy is 0.3169\n",
      "The validation loss is 1.6015\n",
      "The valudation accuracy is 0.4371\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.675417\n",
      "The training accuracy is 0.3244\n",
      "The validation loss is 1.5438\n",
      "The valudation accuracy is 0.4548\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.696058\n",
      "The training accuracy is 0.3298\n",
      "The validation loss is 1.5389\n",
      "The valudation accuracy is 0.4513\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.678027\n",
      "The training accuracy is 0.3353\n",
      "The validation loss is 1.5135\n",
      "The valudation accuracy is 0.4679\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.650155\n",
      "The training accuracy is 0.3410\n",
      "The validation loss is 1.5403\n",
      "The valudation accuracy is 0.4558\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.643132\n",
      "The training accuracy is 0.3459\n",
      "The validation loss is 1.5301\n",
      "The valudation accuracy is 0.4610\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.612494\n",
      "The training accuracy is 0.3505\n",
      "The validation loss is 1.5282\n",
      "The valudation accuracy is 0.4598\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.583916\n",
      "The training accuracy is 0.3551\n",
      "The validation loss is 1.4922\n",
      "The valudation accuracy is 0.4627\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.582983\n",
      "The training accuracy is 0.3594\n",
      "The validation loss is 1.4727\n",
      "The valudation accuracy is 0.4754\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.605515\n",
      "The training accuracy is 0.3630\n",
      "The validation loss is 1.4892\n",
      "The valudation accuracy is 0.4737\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.594175\n",
      "The training accuracy is 0.3664\n",
      "The validation loss is 1.4114\n",
      "The valudation accuracy is 0.5074\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.584720\n",
      "The training accuracy is 0.3698\n",
      "The validation loss is 1.4120\n",
      "The valudation accuracy is 0.5075\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.559049\n",
      "The training accuracy is 0.3731\n",
      "The validation loss is 1.3796\n",
      "The valudation accuracy is 0.5118\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.519893\n",
      "The training accuracy is 0.3771\n",
      "The validation loss is 1.3909\n",
      "The valudation accuracy is 0.5042\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.539674\n",
      "The training accuracy is 0.3800\n",
      "The validation loss is 1.3483\n",
      "The valudation accuracy is 0.5169\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.537271\n",
      "The training accuracy is 0.3829\n",
      "The validation loss is 1.3814\n",
      "The valudation accuracy is 0.5230\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.549832\n",
      "The training accuracy is 0.3853\n",
      "The validation loss is 1.3740\n",
      "The valudation accuracy is 0.5122\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.534462\n",
      "The training accuracy is 0.3879\n",
      "The validation loss is 1.3334\n",
      "The valudation accuracy is 0.5349\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.513166\n",
      "The training accuracy is 0.3906\n",
      "The validation loss is 1.3359\n",
      "The valudation accuracy is 0.5258\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.482187\n",
      "The training accuracy is 0.3936\n",
      "The validation loss is 1.2982\n",
      "The valudation accuracy is 0.5347\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.494727\n",
      "The training accuracy is 0.3962\n",
      "The validation loss is 1.2931\n",
      "The valudation accuracy is 0.5439\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.481229\n",
      "The training accuracy is 0.3988\n",
      "The validation loss is 1.3240\n",
      "The valudation accuracy is 0.5278\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.457679\n",
      "The training accuracy is 0.4015\n",
      "The validation loss is 1.3071\n",
      "The valudation accuracy is 0.5482\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.466126\n",
      "The training accuracy is 0.4037\n",
      "The validation loss is 1.2778\n",
      "The valudation accuracy is 0.5544\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.451240\n",
      "The training accuracy is 0.4059\n",
      "The validation loss is 1.2791\n",
      "The valudation accuracy is 0.5456\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.468303\n",
      "The training accuracy is 0.4078\n",
      "The validation loss is 1.2524\n",
      "The valudation accuracy is 0.5638\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.443145\n",
      "The training accuracy is 0.4099\n",
      "The validation loss is 1.2926\n",
      "The valudation accuracy is 0.5435\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.450271\n",
      "The training accuracy is 0.4119\n",
      "The validation loss is 1.2425\n",
      "The valudation accuracy is 0.5702\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.432357\n",
      "The training accuracy is 0.4140\n",
      "The validation loss is 1.2562\n",
      "The valudation accuracy is 0.5655\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.424625\n",
      "The training accuracy is 0.4163\n",
      "The validation loss is 1.2477\n",
      "The valudation accuracy is 0.5653\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.440812\n",
      "The training accuracy is 0.4181\n",
      "The validation loss is 1.2080\n",
      "The valudation accuracy is 0.5759\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.424932\n",
      "The training accuracy is 0.4200\n",
      "The validation loss is 1.2752\n",
      "The valudation accuracy is 0.5603\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.414687\n",
      "The training accuracy is 0.4219\n",
      "The validation loss is 1.2115\n",
      "The valudation accuracy is 0.5741\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.398787\n",
      "The training accuracy is 0.4238\n",
      "The validation loss is 1.2358\n",
      "The valudation accuracy is 0.5604\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.392326\n",
      "The training accuracy is 0.4259\n",
      "The validation loss is 1.2235\n",
      "The valudation accuracy is 0.5694\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.385872\n",
      "The training accuracy is 0.4278\n",
      "The validation loss is 1.1828\n",
      "The valudation accuracy is 0.5869\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.409074\n",
      "The training accuracy is 0.4294\n",
      "The validation loss is 1.2178\n",
      "The valudation accuracy is 0.5728\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.388027\n",
      "The training accuracy is 0.4311\n",
      "The validation loss is 1.2382\n",
      "The valudation accuracy is 0.5700\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.378268\n",
      "The training accuracy is 0.4329\n",
      "The validation loss is 1.1498\n",
      "The valudation accuracy is 0.6027\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.361605\n",
      "The training accuracy is 0.4348\n",
      "The validation loss is 1.2337\n",
      "The valudation accuracy is 0.5706\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.371770\n",
      "The training accuracy is 0.4365\n",
      "The validation loss is 1.2059\n",
      "The valudation accuracy is 0.5829\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.372314\n",
      "The training accuracy is 0.4380\n",
      "The validation loss is 1.1581\n",
      "The valudation accuracy is 0.5953\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.352135\n",
      "The training accuracy is 0.4395\n",
      "The validation loss is 1.1588\n",
      "The valudation accuracy is 0.5885\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.364444\n",
      "The training accuracy is 0.4410\n",
      "The validation loss is 1.1953\n",
      "The valudation accuracy is 0.5802\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.358357\n",
      "The training accuracy is 0.4426\n",
      "The validation loss is 1.1465\n",
      "The valudation accuracy is 0.5980\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.347992\n",
      "The training accuracy is 0.4441\n",
      "The validation loss is 1.1230\n",
      "The valudation accuracy is 0.6159\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.350476\n",
      "The training accuracy is 0.4457\n",
      "The validation loss is 1.1859\n",
      "The valudation accuracy is 0.5772\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.357720\n",
      "The training accuracy is 0.4473\n",
      "The validation loss is 1.1338\n",
      "The valudation accuracy is 0.6007\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.325342\n",
      "The training accuracy is 0.4486\n",
      "The validation loss is 1.1178\n",
      "The valudation accuracy is 0.6169\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.334525\n",
      "The training accuracy is 0.4499\n",
      "The validation loss is 1.1298\n",
      "The valudation accuracy is 0.6064\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.326873\n",
      "The training accuracy is 0.4513\n",
      "The validation loss is 1.1448\n",
      "The valudation accuracy is 0.5975\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.319456\n",
      "The training accuracy is 0.4527\n",
      "The validation loss is 1.0961\n",
      "The valudation accuracy is 0.6220\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.310515\n",
      "The training accuracy is 0.4540\n",
      "The validation loss is 1.0962\n",
      "The valudation accuracy is 0.6269\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.319330\n",
      "The training accuracy is 0.4554\n",
      "The validation loss is 1.1110\n",
      "The valudation accuracy is 0.6118\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.291378\n",
      "The training accuracy is 0.4569\n",
      "The validation loss is 1.1383\n",
      "The valudation accuracy is 0.6106\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.311714\n",
      "The training accuracy is 0.4581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is 1.1094\n",
      "The valudation accuracy is 0.6143\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.309981\n",
      "The training accuracy is 0.4594\n",
      "The validation loss is 1.0807\n",
      "The valudation accuracy is 0.6168\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.290448\n",
      "The training accuracy is 0.4607\n",
      "The validation loss is 1.0692\n",
      "The valudation accuracy is 0.6328\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.259260\n",
      "The training accuracy is 0.4621\n",
      "The validation loss is 1.0615\n",
      "The valudation accuracy is 0.6365\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.272270\n",
      "The training accuracy is 0.4634\n",
      "The validation loss is 1.1017\n",
      "The valudation accuracy is 0.6094\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.283450\n",
      "The training accuracy is 0.4648\n",
      "The validation loss is 1.0775\n",
      "The valudation accuracy is 0.6191\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.247590\n",
      "The training accuracy is 0.4661\n",
      "The validation loss is 1.0485\n",
      "The valudation accuracy is 0.6354\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.256484\n",
      "The training accuracy is 0.4674\n",
      "The validation loss is 1.0223\n",
      "The valudation accuracy is 0.6430\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.250369\n",
      "The training accuracy is 0.4687\n",
      "The validation loss is 1.0626\n",
      "The valudation accuracy is 0.6310\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.253811\n",
      "The training accuracy is 0.4700\n",
      "The validation loss is 1.0512\n",
      "The valudation accuracy is 0.6351\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.264551\n",
      "The training accuracy is 0.4711\n",
      "The validation loss is 1.0304\n",
      "The valudation accuracy is 0.6416\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.237584\n",
      "The training accuracy is 0.4723\n",
      "The validation loss is 0.9850\n",
      "The valudation accuracy is 0.6598\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.219596\n",
      "The training accuracy is 0.4735\n",
      "The validation loss is 1.0259\n",
      "The valudation accuracy is 0.6407\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.237728\n",
      "The training accuracy is 0.4746\n",
      "The validation loss is 1.0234\n",
      "The valudation accuracy is 0.6438\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.216317\n",
      "The training accuracy is 0.4759\n",
      "The validation loss is 1.0752\n",
      "The valudation accuracy is 0.6214\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.237669\n",
      "The training accuracy is 0.4770\n",
      "The validation loss is 1.0124\n",
      "The valudation accuracy is 0.6472\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.220692\n",
      "The training accuracy is 0.4782\n",
      "The validation loss is 0.9985\n",
      "The valudation accuracy is 0.6534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base.parameters(),lr=5e-5)\n",
    "train(myCNN_base,train_loader, 12,80 ,criterion,optimizer,'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30039cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e0d58c51844062991bb3ae471a904d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.166527\n",
      "The training accuracy is 0.5865\n",
      "The validation loss is 0.9480\n",
      "The valudation accuracy is 0.6719\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.161292\n",
      "The training accuracy is 0.5916\n",
      "The validation loss is 0.9354\n",
      "The valudation accuracy is 0.6726\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.171471\n",
      "The training accuracy is 0.5913\n",
      "The validation loss is 0.9313\n",
      "The valudation accuracy is 0.6756\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.154161\n",
      "The training accuracy is 0.5926\n",
      "The validation loss is 0.9294\n",
      "The valudation accuracy is 0.6742\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.160431\n",
      "The training accuracy is 0.5922\n",
      "The validation loss is 0.9284\n",
      "The valudation accuracy is 0.6748\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.159843\n",
      "The training accuracy is 0.5918\n",
      "The validation loss is 0.9301\n",
      "The valudation accuracy is 0.6758\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.144204\n",
      "The training accuracy is 0.5925\n",
      "The validation loss is 0.9292\n",
      "The valudation accuracy is 0.6754\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.152356\n",
      "The training accuracy is 0.5928\n",
      "The validation loss is 0.9245\n",
      "The valudation accuracy is 0.6790\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.152200\n",
      "The training accuracy is 0.5932\n",
      "The validation loss is 0.9305\n",
      "The valudation accuracy is 0.6776\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.143723\n",
      "The training accuracy is 0.5938\n",
      "The validation loss is 0.9204\n",
      "The valudation accuracy is 0.6810\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.157702\n",
      "The training accuracy is 0.5941\n",
      "The validation loss is 0.9231\n",
      "The valudation accuracy is 0.6808\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.143371\n",
      "The training accuracy is 0.5943\n",
      "The validation loss is 0.9164\n",
      "The valudation accuracy is 0.6805\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.138529\n",
      "The training accuracy is 0.5947\n",
      "The validation loss is 0.9175\n",
      "The valudation accuracy is 0.6825\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.145097\n",
      "The training accuracy is 0.5951\n",
      "The validation loss is 0.9257\n",
      "The valudation accuracy is 0.6831\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.151343\n",
      "The training accuracy is 0.5953\n",
      "The validation loss is 0.9188\n",
      "The valudation accuracy is 0.6828\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.144237\n",
      "The training accuracy is 0.5954\n",
      "The validation loss is 0.9129\n",
      "The valudation accuracy is 0.6838\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.127230\n",
      "The training accuracy is 0.5959\n",
      "The validation loss is 0.9143\n",
      "The valudation accuracy is 0.6842\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.135494\n",
      "The training accuracy is 0.5965\n",
      "The validation loss is 0.9147\n",
      "The valudation accuracy is 0.6830\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.137399\n",
      "The training accuracy is 0.5969\n",
      "The validation loss is 0.9123\n",
      "The valudation accuracy is 0.6837\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.148740\n",
      "The training accuracy is 0.5969\n",
      "The validation loss is 0.9165\n",
      "The valudation accuracy is 0.6840\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.136907\n",
      "The training accuracy is 0.5970\n",
      "The validation loss is 0.9145\n",
      "The valudation accuracy is 0.6825\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.140735\n",
      "The training accuracy is 0.5975\n",
      "The validation loss is 0.9094\n",
      "The valudation accuracy is 0.6832\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.132345\n",
      "The training accuracy is 0.5976\n",
      "The validation loss is 0.9070\n",
      "The valudation accuracy is 0.6841\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.126815\n",
      "The training accuracy is 0.5979\n",
      "The validation loss is 0.9137\n",
      "The valudation accuracy is 0.6834\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.143534\n",
      "The training accuracy is 0.5980\n",
      "The validation loss is 0.9123\n",
      "The valudation accuracy is 0.6878\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.117658\n",
      "The training accuracy is 0.5983\n",
      "The validation loss is 0.9105\n",
      "The valudation accuracy is 0.6846\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.131937\n",
      "The training accuracy is 0.5985\n",
      "The validation loss is 0.9147\n",
      "The valudation accuracy is 0.6862\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.136034\n",
      "The training accuracy is 0.5984\n",
      "The validation loss is 0.9109\n",
      "The valudation accuracy is 0.6857\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.138746\n",
      "The training accuracy is 0.5985\n",
      "The validation loss is 0.9039\n",
      "The valudation accuracy is 0.6872\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.137544\n",
      "The training accuracy is 0.5986\n",
      "The validation loss is 0.9089\n",
      "The valudation accuracy is 0.6847\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.140787\n",
      "The training accuracy is 0.5987\n",
      "The validation loss is 0.9055\n",
      "The valudation accuracy is 0.6834\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.120335\n",
      "The training accuracy is 0.5989\n",
      "The validation loss is 0.9036\n",
      "The valudation accuracy is 0.6847\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.132232\n",
      "The training accuracy is 0.5990\n",
      "The validation loss is 0.9017\n",
      "The valudation accuracy is 0.6866\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.125835\n",
      "The training accuracy is 0.5992\n",
      "The validation loss is 0.9073\n",
      "The valudation accuracy is 0.6838\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.130745\n",
      "The training accuracy is 0.5995\n",
      "The validation loss is 0.9019\n",
      "The valudation accuracy is 0.6850\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.124928\n",
      "The training accuracy is 0.5998\n",
      "The validation loss is 0.9035\n",
      "The valudation accuracy is 0.6866\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.136222\n",
      "The training accuracy is 0.5998\n",
      "The validation loss is 0.9043\n",
      "The valudation accuracy is 0.6888\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.127920\n",
      "The training accuracy is 0.5999\n",
      "The validation loss is 0.9051\n",
      "The valudation accuracy is 0.6862\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.130507\n",
      "The training accuracy is 0.5999\n",
      "The validation loss is 0.9060\n",
      "The valudation accuracy is 0.6864\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.113017\n",
      "The training accuracy is 0.6001\n",
      "The validation loss is 0.9016\n",
      "The valudation accuracy is 0.6859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base.parameters(),lr=1e-6)\n",
    "train(myCNN_base,train_loader, 12, 40 ,criterion,optimizer,'cuda',\"-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2ee7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "847653c1",
   "metadata": {},
   "source": [
    "## Base-model - add batchnorm #1 - traing 66%/0.92 - val 76%/0.66 \n",
    "Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f5d15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# add batchnorm after each conv layer for the first three layers\n",
    "class CNN_base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_base,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f338fa64",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_base(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_base1 = CNN_base()\n",
    "myCNN_base1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11a7ceaa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3be6b6f95d4be3960b3cada6015c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.987207\n",
      "The training accuracy is 0.2597\n",
      "The validation loss is 1.6839\n",
      "The valudation accuracy is 0.3803\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.738310\n",
      "The training accuracy is 0.3162\n",
      "The validation loss is 1.6305\n",
      "The valudation accuracy is 0.4136\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.680882\n",
      "The training accuracy is 0.3441\n",
      "The validation loss is 1.5351\n",
      "The valudation accuracy is 0.4606\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.615394\n",
      "The training accuracy is 0.3630\n",
      "The validation loss is 1.4689\n",
      "The valudation accuracy is 0.4681\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.588250\n",
      "The training accuracy is 0.3774\n",
      "The validation loss is 1.4589\n",
      "The valudation accuracy is 0.4724\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.558680\n",
      "The training accuracy is 0.3885\n",
      "The validation loss is 1.3964\n",
      "The valudation accuracy is 0.4936\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.531039\n",
      "The training accuracy is 0.3976\n",
      "The validation loss is 1.3892\n",
      "The valudation accuracy is 0.5107\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.498246\n",
      "The training accuracy is 0.4063\n",
      "The validation loss is 1.3095\n",
      "The valudation accuracy is 0.5410\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.465858\n",
      "The training accuracy is 0.4144\n",
      "The validation loss is 1.2829\n",
      "The valudation accuracy is 0.5499\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.460694\n",
      "The training accuracy is 0.4213\n",
      "The validation loss is 1.2943\n",
      "The valudation accuracy is 0.5482\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.411996\n",
      "The training accuracy is 0.4282\n",
      "The validation loss is 1.2053\n",
      "The valudation accuracy is 0.5645\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.420959\n",
      "The training accuracy is 0.4340\n",
      "The validation loss is 1.2495\n",
      "The valudation accuracy is 0.5516\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.368765\n",
      "The training accuracy is 0.4396\n",
      "The validation loss is 1.1455\n",
      "The valudation accuracy is 0.5991\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.364273\n",
      "The training accuracy is 0.4447\n",
      "The validation loss is 1.1958\n",
      "The valudation accuracy is 0.5723\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.334466\n",
      "The training accuracy is 0.4504\n",
      "The validation loss is 1.1415\n",
      "The valudation accuracy is 0.5923\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.344143\n",
      "The training accuracy is 0.4552\n",
      "The validation loss is 1.1411\n",
      "The valudation accuracy is 0.6005\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.297298\n",
      "The training accuracy is 0.4602\n",
      "The validation loss is 1.1077\n",
      "The valudation accuracy is 0.6040\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.270010\n",
      "The training accuracy is 0.4653\n",
      "The validation loss is 1.0276\n",
      "The valudation accuracy is 0.6309\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.261997\n",
      "The training accuracy is 0.4703\n",
      "The validation loss is 1.0366\n",
      "The valudation accuracy is 0.6391\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.255679\n",
      "The training accuracy is 0.4746\n",
      "The validation loss is 0.9956\n",
      "The valudation accuracy is 0.6421\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.237789\n",
      "The training accuracy is 0.4788\n",
      "The validation loss is 0.9768\n",
      "The valudation accuracy is 0.6586\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.227145\n",
      "The training accuracy is 0.4828\n",
      "The validation loss is 0.9593\n",
      "The valudation accuracy is 0.6665\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.215352\n",
      "The training accuracy is 0.4869\n",
      "The validation loss is 0.9662\n",
      "The valudation accuracy is 0.6569\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.217851\n",
      "The training accuracy is 0.4902\n",
      "The validation loss is 0.9854\n",
      "The valudation accuracy is 0.6493\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.183828\n",
      "The training accuracy is 0.4939\n",
      "The validation loss is 0.9395\n",
      "The valudation accuracy is 0.6572\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.171719\n",
      "The training accuracy is 0.4975\n",
      "The validation loss is 0.9535\n",
      "The valudation accuracy is 0.6574\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.163638\n",
      "The training accuracy is 0.5011\n",
      "The validation loss is 0.8971\n",
      "The valudation accuracy is 0.6770\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.123909\n",
      "The training accuracy is 0.5048\n",
      "The validation loss is 0.9415\n",
      "The valudation accuracy is 0.6593\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.145357\n",
      "The training accuracy is 0.5080\n",
      "The validation loss is 0.8951\n",
      "The valudation accuracy is 0.6894\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.114360\n",
      "The training accuracy is 0.5112\n",
      "The validation loss is 0.8718\n",
      "The valudation accuracy is 0.6938\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.097969\n",
      "The training accuracy is 0.5145\n",
      "The validation loss is 0.9481\n",
      "The valudation accuracy is 0.6595\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.096783\n",
      "The training accuracy is 0.5177\n",
      "The validation loss is 0.8326\n",
      "The valudation accuracy is 0.7035\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.110032\n",
      "The training accuracy is 0.5205\n",
      "The validation loss is 0.8811\n",
      "The valudation accuracy is 0.6899\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.069524\n",
      "The training accuracy is 0.5236\n",
      "The validation loss is 0.8696\n",
      "The valudation accuracy is 0.6999\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.055500\n",
      "The training accuracy is 0.5265\n",
      "The validation loss is 0.8144\n",
      "The valudation accuracy is 0.7149\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.058571\n",
      "The training accuracy is 0.5294\n",
      "The validation loss is 0.7696\n",
      "The valudation accuracy is 0.7272\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.030763\n",
      "The training accuracy is 0.5322\n",
      "The validation loss is 0.7582\n",
      "The valudation accuracy is 0.7311\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.036326\n",
      "The training accuracy is 0.5349\n",
      "The validation loss is 0.8120\n",
      "The valudation accuracy is 0.7125\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.011174\n",
      "The training accuracy is 0.5377\n",
      "The validation loss is 0.7795\n",
      "The valudation accuracy is 0.7296\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.015287\n",
      "The training accuracy is 0.5404\n",
      "The validation loss is 0.7680\n",
      "The valudation accuracy is 0.7288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base1.parameters(),lr=5e-5)\n",
    "train(myCNN_base1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e46bdec9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c0dfa6173143668a38a9d1f553f138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.253340\n",
      "The training accuracy is 0.5839\n",
      "The validation loss is 0.8251\n",
      "The valudation accuracy is 0.7117\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.083941\n",
      "The training accuracy is 0.6033\n",
      "The validation loss is 0.7802\n",
      "The valudation accuracy is 0.7277\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.047332\n",
      "The training accuracy is 0.6144\n",
      "The validation loss is 0.7548\n",
      "The valudation accuracy is 0.7364\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.029062\n",
      "The training accuracy is 0.6207\n",
      "The validation loss is 0.7419\n",
      "The valudation accuracy is 0.7391\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.013022\n",
      "The training accuracy is 0.6256\n",
      "The validation loss is 0.7345\n",
      "The valudation accuracy is 0.7434\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.988714\n",
      "The training accuracy is 0.6306\n",
      "The validation loss is 0.7258\n",
      "The valudation accuracy is 0.7483\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.995477\n",
      "The training accuracy is 0.6333\n",
      "The validation loss is 0.7194\n",
      "The valudation accuracy is 0.7487\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.987098\n",
      "The training accuracy is 0.6367\n",
      "The validation loss is 0.7110\n",
      "The valudation accuracy is 0.7511\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.987917\n",
      "The training accuracy is 0.6387\n",
      "The validation loss is 0.7096\n",
      "The valudation accuracy is 0.7538\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.971602\n",
      "The training accuracy is 0.6410\n",
      "The validation loss is 0.7044\n",
      "The valudation accuracy is 0.7552\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.963965\n",
      "The training accuracy is 0.6429\n",
      "The validation loss is 0.7012\n",
      "The valudation accuracy is 0.7571\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.986702\n",
      "The training accuracy is 0.6439\n",
      "The validation loss is 0.7068\n",
      "The valudation accuracy is 0.7556\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.949868\n",
      "The training accuracy is 0.6459\n",
      "The validation loss is 0.6912\n",
      "The valudation accuracy is 0.7583\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.974321\n",
      "The training accuracy is 0.6468\n",
      "The validation loss is 0.6942\n",
      "The valudation accuracy is 0.7578\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.957571\n",
      "The training accuracy is 0.6480\n",
      "The validation loss is 0.6929\n",
      "The valudation accuracy is 0.7597\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.957333\n",
      "The training accuracy is 0.6489\n",
      "The validation loss is 0.6909\n",
      "The valudation accuracy is 0.7601\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.952645\n",
      "The training accuracy is 0.6497\n",
      "The validation loss is 0.6910\n",
      "The valudation accuracy is 0.7591\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.965213\n",
      "The training accuracy is 0.6504\n",
      "The validation loss is 0.6823\n",
      "The valudation accuracy is 0.7614\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.955614\n",
      "The training accuracy is 0.6510\n",
      "The validation loss is 0.6830\n",
      "The valudation accuracy is 0.7613\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.943764\n",
      "The training accuracy is 0.6519\n",
      "The validation loss is 0.6845\n",
      "The valudation accuracy is 0.7618\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.960189\n",
      "The training accuracy is 0.6526\n",
      "The validation loss is 0.6860\n",
      "The valudation accuracy is 0.7611\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.952366\n",
      "The training accuracy is 0.6532\n",
      "The validation loss is 0.6764\n",
      "The valudation accuracy is 0.7619\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.946684\n",
      "The training accuracy is 0.6538\n",
      "The validation loss is 0.6779\n",
      "The valudation accuracy is 0.7631\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.947801\n",
      "The training accuracy is 0.6542\n",
      "The validation loss is 0.6827\n",
      "The valudation accuracy is 0.7630\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.946902\n",
      "The training accuracy is 0.6550\n",
      "The validation loss is 0.6777\n",
      "The valudation accuracy is 0.7640\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.918815\n",
      "The training accuracy is 0.6560\n",
      "The validation loss is 0.6787\n",
      "The valudation accuracy is 0.7638\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.945377\n",
      "The training accuracy is 0.6565\n",
      "The validation loss is 0.6775\n",
      "The valudation accuracy is 0.7633\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.937997\n",
      "The training accuracy is 0.6569\n",
      "The validation loss is 0.6811\n",
      "The valudation accuracy is 0.7647\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.947535\n",
      "The training accuracy is 0.6573\n",
      "The validation loss is 0.6711\n",
      "The valudation accuracy is 0.7641\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.927953\n",
      "The training accuracy is 0.6581\n",
      "The validation loss is 0.6774\n",
      "The valudation accuracy is 0.7641\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.942315\n",
      "The training accuracy is 0.6585\n",
      "The validation loss is 0.6755\n",
      "The valudation accuracy is 0.7642\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.942900\n",
      "The training accuracy is 0.6589\n",
      "The validation loss is 0.6730\n",
      "The valudation accuracy is 0.7651\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.929506\n",
      "The training accuracy is 0.6593\n",
      "The validation loss is 0.6716\n",
      "The valudation accuracy is 0.7657\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.935071\n",
      "The training accuracy is 0.6597\n",
      "The validation loss is 0.6772\n",
      "The valudation accuracy is 0.7632\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.929106\n",
      "The training accuracy is 0.6602\n",
      "The validation loss is 0.6721\n",
      "The valudation accuracy is 0.7661\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.928039\n",
      "The training accuracy is 0.6606\n",
      "The validation loss is 0.6644\n",
      "The valudation accuracy is 0.7670\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.923520\n",
      "The training accuracy is 0.6611\n",
      "The validation loss is 0.6664\n",
      "The valudation accuracy is 0.7669\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.924647\n",
      "The training accuracy is 0.6614\n",
      "The validation loss is 0.6674\n",
      "The valudation accuracy is 0.7657\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.921771\n",
      "The training accuracy is 0.6619\n",
      "The validation loss is 0.6620\n",
      "The valudation accuracy is 0.7674\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.922995\n",
      "The training accuracy is 0.6624\n",
      "The validation loss is 0.6687\n",
      "The valudation accuracy is 0.7647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base1.parameters(),lr=1e-6)\n",
    "train(myCNN_base1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "172cf6c8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84d2dd50aaa4ba58faf209dad4a9c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.049361\n",
      "The training accuracy is 0.6368\n",
      "The validation loss is 0.7043\n",
      "The valudation accuracy is 0.7479\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.976365\n",
      "The training accuracy is 0.6482\n",
      "The validation loss is 0.6954\n",
      "The valudation accuracy is 0.7511\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.969442\n",
      "The training accuracy is 0.6513\n",
      "The validation loss is 0.6849\n",
      "The valudation accuracy is 0.7552\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.943969\n",
      "The training accuracy is 0.6562\n",
      "The validation loss is 0.6847\n",
      "The valudation accuracy is 0.7572\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.962423\n",
      "The training accuracy is 0.6574\n",
      "The validation loss is 0.6832\n",
      "The valudation accuracy is 0.7579\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.942510\n",
      "The training accuracy is 0.6597\n",
      "The validation loss is 0.6776\n",
      "The valudation accuracy is 0.7607\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.955656\n",
      "The training accuracy is 0.6611\n",
      "The validation loss is 0.6751\n",
      "The valudation accuracy is 0.7612\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.956258\n",
      "The training accuracy is 0.6612\n",
      "The validation loss is 0.6752\n",
      "The valudation accuracy is 0.7611\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.941242\n",
      "The training accuracy is 0.6621\n",
      "The validation loss is 0.6763\n",
      "The valudation accuracy is 0.7623\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.944508\n",
      "The training accuracy is 0.6630\n",
      "The validation loss is 0.6716\n",
      "The valudation accuracy is 0.7623\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.938434\n",
      "The training accuracy is 0.6636\n",
      "The validation loss is 0.6705\n",
      "The valudation accuracy is 0.7647\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.935109\n",
      "The training accuracy is 0.6647\n",
      "The validation loss is 0.6687\n",
      "The valudation accuracy is 0.7631\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.937423\n",
      "The training accuracy is 0.6651\n",
      "The validation loss is 0.6753\n",
      "The valudation accuracy is 0.7626\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.932705\n",
      "The training accuracy is 0.6658\n",
      "The validation loss is 0.6740\n",
      "The valudation accuracy is 0.7644\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.944867\n",
      "The training accuracy is 0.6660\n",
      "The validation loss is 0.6719\n",
      "The valudation accuracy is 0.7623\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.930295\n",
      "The training accuracy is 0.6665\n",
      "The validation loss is 0.6640\n",
      "The valudation accuracy is 0.7648\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.927538\n",
      "The training accuracy is 0.6670\n",
      "The validation loss is 0.6667\n",
      "The valudation accuracy is 0.7652\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.916625\n",
      "The training accuracy is 0.6678\n",
      "The validation loss is 0.6674\n",
      "The valudation accuracy is 0.7652\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.933952\n",
      "The training accuracy is 0.6681\n",
      "The validation loss is 0.6685\n",
      "The valudation accuracy is 0.7658\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.946980\n",
      "The training accuracy is 0.6681\n",
      "The validation loss is 0.6665\n",
      "The valudation accuracy is 0.7648\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.932176\n",
      "The training accuracy is 0.6683\n",
      "The validation loss is 0.6639\n",
      "The valudation accuracy is 0.7675\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.938349\n",
      "The training accuracy is 0.6685\n",
      "The validation loss is 0.6652\n",
      "The valudation accuracy is 0.7672\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.924196\n",
      "The training accuracy is 0.6689\n",
      "The validation loss is 0.6644\n",
      "The valudation accuracy is 0.7672\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.940260\n",
      "The training accuracy is 0.6690\n",
      "The validation loss is 0.6652\n",
      "The valudation accuracy is 0.7661\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.933829\n",
      "The training accuracy is 0.6693\n",
      "The validation loss is 0.6666\n",
      "The valudation accuracy is 0.7666\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.942037\n",
      "The training accuracy is 0.6693\n",
      "The validation loss is 0.6631\n",
      "The valudation accuracy is 0.7653\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.928405\n",
      "The training accuracy is 0.6695\n",
      "The validation loss is 0.6657\n",
      "The valudation accuracy is 0.7654\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.927420\n",
      "The training accuracy is 0.6698\n",
      "The validation loss is 0.6598\n",
      "The valudation accuracy is 0.7666\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.907347\n",
      "The training accuracy is 0.6702\n",
      "The validation loss is 0.6621\n",
      "The valudation accuracy is 0.7696\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.935073\n",
      "The training accuracy is 0.6702\n",
      "The validation loss is 0.6644\n",
      "The valudation accuracy is 0.7679\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.941557\n",
      "The training accuracy is 0.6702\n",
      "The validation loss is 0.6626\n",
      "The valudation accuracy is 0.7686\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.922804\n",
      "The training accuracy is 0.6705\n",
      "The validation loss is 0.6584\n",
      "The valudation accuracy is 0.7681\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.929413\n",
      "The training accuracy is 0.6706\n",
      "The validation loss is 0.6611\n",
      "The valudation accuracy is 0.7672\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.914004\n",
      "The training accuracy is 0.6711\n",
      "The validation loss is 0.6574\n",
      "The valudation accuracy is 0.7672\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.924974\n",
      "The training accuracy is 0.6713\n",
      "The validation loss is 0.6597\n",
      "The valudation accuracy is 0.7678\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.919907\n",
      "The training accuracy is 0.6714\n",
      "The validation loss is 0.6574\n",
      "The valudation accuracy is 0.7691\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.930021\n",
      "The training accuracy is 0.6714\n",
      "The validation loss is 0.6573\n",
      "The valudation accuracy is 0.7695\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.920597\n",
      "The training accuracy is 0.6715\n",
      "The validation loss is 0.6611\n",
      "The valudation accuracy is 0.7692\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.933993\n",
      "The training accuracy is 0.6716\n",
      "The validation loss is 0.6558\n",
      "The valudation accuracy is 0.7694\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.916838\n",
      "The training accuracy is 0.6717\n",
      "The validation loss is 0.6538\n",
      "The valudation accuracy is 0.7687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base1.parameters(),lr=5e-7)\n",
    "train(myCNN_base1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6e378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e299961",
   "metadata": {},
   "source": [
    "## Base-model - Batchnorm #2 - train 71%/0.80 - val 83%/0.53\n",
    "Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfca091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# add batchnorm after each conv layer for every conv layer\n",
    "class CNN_base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_base,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fda5f86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_base(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_base2 = CNN_base()\n",
    "myCNN_base2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a787441",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63478d8b7b72495480bba04b4a199135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.750458\n",
      "The training accuracy is 0.3695\n",
      "The validation loss is 1.5327\n",
      "The valudation accuracy is 0.4552\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.651133\n",
      "The training accuracy is 0.3900\n",
      "The validation loss is 1.4146\n",
      "The valudation accuracy is 0.5069\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.549947\n",
      "The training accuracy is 0.4091\n",
      "The validation loss is 1.3310\n",
      "The valudation accuracy is 0.5360\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.495199\n",
      "The training accuracy is 0.4234\n",
      "The validation loss is 1.2953\n",
      "The valudation accuracy is 0.5460\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.447194\n",
      "The training accuracy is 0.4369\n",
      "The validation loss is 1.2475\n",
      "The valudation accuracy is 0.5579\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.420691\n",
      "The training accuracy is 0.4471\n",
      "The validation loss is 1.1947\n",
      "The valudation accuracy is 0.5759\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.380977\n",
      "The training accuracy is 0.4565\n",
      "The validation loss is 1.1618\n",
      "The valudation accuracy is 0.5909\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.364944\n",
      "The training accuracy is 0.4635\n",
      "The validation loss is 1.1443\n",
      "The valudation accuracy is 0.6039\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.353859\n",
      "The training accuracy is 0.4706\n",
      "The validation loss is 1.0940\n",
      "The valudation accuracy is 0.6269\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.301366\n",
      "The training accuracy is 0.4779\n",
      "The validation loss is 1.0418\n",
      "The valudation accuracy is 0.6376\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.300869\n",
      "The training accuracy is 0.4840\n",
      "The validation loss is 1.0348\n",
      "The valudation accuracy is 0.6418\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.261047\n",
      "The training accuracy is 0.4899\n",
      "The validation loss is 1.0242\n",
      "The valudation accuracy is 0.6449\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.235903\n",
      "The training accuracy is 0.4957\n",
      "The validation loss is 0.9624\n",
      "The valudation accuracy is 0.6579\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.200157\n",
      "The training accuracy is 0.5015\n",
      "The validation loss is 0.9713\n",
      "The valudation accuracy is 0.6632\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.185027\n",
      "The training accuracy is 0.5070\n",
      "The validation loss is 0.9589\n",
      "The valudation accuracy is 0.6629\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.171593\n",
      "The training accuracy is 0.5118\n",
      "The validation loss is 0.9013\n",
      "The valudation accuracy is 0.6772\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.135346\n",
      "The training accuracy is 0.5169\n",
      "The validation loss is 1.0114\n",
      "The valudation accuracy is 0.6595\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.131669\n",
      "The training accuracy is 0.5220\n",
      "The validation loss is 0.9020\n",
      "The valudation accuracy is 0.6777\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.094425\n",
      "The training accuracy is 0.5269\n",
      "The validation loss is 0.8046\n",
      "The valudation accuracy is 0.7279\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.095286\n",
      "The training accuracy is 0.5313\n",
      "The validation loss is 0.7942\n",
      "The valudation accuracy is 0.7242\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.071669\n",
      "The training accuracy is 0.5357\n",
      "The validation loss is 0.7893\n",
      "The valudation accuracy is 0.7268\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.046369\n",
      "The training accuracy is 0.5401\n",
      "The validation loss is 0.8781\n",
      "The valudation accuracy is 0.6936\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.029402\n",
      "The training accuracy is 0.5443\n",
      "The validation loss is 0.7469\n",
      "The valudation accuracy is 0.7401\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.022943\n",
      "The training accuracy is 0.5482\n",
      "The validation loss is 0.7009\n",
      "The valudation accuracy is 0.7561\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.993366\n",
      "The training accuracy is 0.5523\n",
      "The validation loss is 0.7407\n",
      "The valudation accuracy is 0.7464\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.996242\n",
      "The training accuracy is 0.5561\n",
      "The validation loss is 0.7113\n",
      "The valudation accuracy is 0.7530\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.937987\n",
      "The training accuracy is 0.5604\n",
      "The validation loss is 0.7403\n",
      "The valudation accuracy is 0.7384\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.952323\n",
      "The training accuracy is 0.5643\n",
      "The validation loss is 0.6473\n",
      "The valudation accuracy is 0.7745\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.930784\n",
      "The training accuracy is 0.5680\n",
      "The validation loss is 0.6493\n",
      "The valudation accuracy is 0.7798\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.949538\n",
      "The training accuracy is 0.5714\n",
      "The validation loss is 0.6319\n",
      "The valudation accuracy is 0.7812\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.905759\n",
      "The training accuracy is 0.5751\n",
      "The validation loss is 0.6489\n",
      "The valudation accuracy is 0.7784\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.899343\n",
      "The training accuracy is 0.5786\n",
      "The validation loss is 0.6260\n",
      "The valudation accuracy is 0.7789\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.883559\n",
      "The training accuracy is 0.5820\n",
      "The validation loss is 0.5839\n",
      "The valudation accuracy is 0.7975\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.878583\n",
      "The training accuracy is 0.5853\n",
      "The validation loss is 0.5822\n",
      "The valudation accuracy is 0.7997\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.854778\n",
      "The training accuracy is 0.5887\n",
      "The validation loss is 0.6203\n",
      "The valudation accuracy is 0.7852\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.830205\n",
      "The training accuracy is 0.5920\n",
      "The validation loss is 0.5496\n",
      "The valudation accuracy is 0.8124\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.849873\n",
      "The training accuracy is 0.5951\n",
      "The validation loss is 0.5607\n",
      "The valudation accuracy is 0.8049\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.814282\n",
      "The training accuracy is 0.5983\n",
      "The validation loss is 0.5723\n",
      "The valudation accuracy is 0.7979\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.820303\n",
      "The training accuracy is 0.6013\n",
      "The validation loss is 0.5636\n",
      "The valudation accuracy is 0.8112\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.810539\n",
      "The training accuracy is 0.6041\n",
      "The validation loss is 0.5115\n",
      "The valudation accuracy is 0.8261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base2.parameters(),lr=5e-5)\n",
    "train(myCNN_base2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48b4fb52",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf1e954dceb44e9a274ee3a090645ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.071938\n",
      "The training accuracy is 0.6302\n",
      "The validation loss is 0.7111\n",
      "The valudation accuracy is 0.7616\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.969116\n",
      "The training accuracy is 0.6501\n",
      "The validation loss is 0.6611\n",
      "The valudation accuracy is 0.7864\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.918611\n",
      "The training accuracy is 0.6633\n",
      "The validation loss is 0.6476\n",
      "The valudation accuracy is 0.7922\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.890066\n",
      "The training accuracy is 0.6712\n",
      "The validation loss is 0.6331\n",
      "The valudation accuracy is 0.7937\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.894646\n",
      "The training accuracy is 0.6769\n",
      "The validation loss is 0.6186\n",
      "The valudation accuracy is 0.8038\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.887226\n",
      "The training accuracy is 0.6803\n",
      "The validation loss is 0.6072\n",
      "The valudation accuracy is 0.8047\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.866359\n",
      "The training accuracy is 0.6849\n",
      "The validation loss is 0.5981\n",
      "The valudation accuracy is 0.8078\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.865972\n",
      "The training accuracy is 0.6874\n",
      "The validation loss is 0.5883\n",
      "The valudation accuracy is 0.8114\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.871456\n",
      "The training accuracy is 0.6892\n",
      "The validation loss is 0.5931\n",
      "The valudation accuracy is 0.8123\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.858495\n",
      "The training accuracy is 0.6909\n",
      "The validation loss is 0.5872\n",
      "The valudation accuracy is 0.8121\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.849924\n",
      "The training accuracy is 0.6928\n",
      "The validation loss is 0.5766\n",
      "The valudation accuracy is 0.8150\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.843941\n",
      "The training accuracy is 0.6947\n",
      "The validation loss is 0.5736\n",
      "The valudation accuracy is 0.8139\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.838115\n",
      "The training accuracy is 0.6965\n",
      "The validation loss is 0.5728\n",
      "The valudation accuracy is 0.8158\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.840001\n",
      "The training accuracy is 0.6974\n",
      "The validation loss is 0.5668\n",
      "The valudation accuracy is 0.8179\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.827069\n",
      "The training accuracy is 0.6988\n",
      "The validation loss is 0.5591\n",
      "The valudation accuracy is 0.8210\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.826471\n",
      "The training accuracy is 0.6999\n",
      "The validation loss is 0.5616\n",
      "The valudation accuracy is 0.8192\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.826228\n",
      "The training accuracy is 0.7010\n",
      "The validation loss is 0.5565\n",
      "The valudation accuracy is 0.8219\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.813396\n",
      "The training accuracy is 0.7023\n",
      "The validation loss is 0.5464\n",
      "The valudation accuracy is 0.8211\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.808272\n",
      "The training accuracy is 0.7035\n",
      "The validation loss is 0.5437\n",
      "The valudation accuracy is 0.8234\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.814945\n",
      "The training accuracy is 0.7043\n",
      "The validation loss is 0.5476\n",
      "The valudation accuracy is 0.8233\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.826298\n",
      "The training accuracy is 0.7050\n",
      "The validation loss is 0.5431\n",
      "The valudation accuracy is 0.8253\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.816033\n",
      "The training accuracy is 0.7058\n",
      "The validation loss is 0.5407\n",
      "The valudation accuracy is 0.8252\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.809427\n",
      "The training accuracy is 0.7066\n",
      "The validation loss is 0.5438\n",
      "The valudation accuracy is 0.8243\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.810239\n",
      "The training accuracy is 0.7073\n",
      "The validation loss is 0.5369\n",
      "The valudation accuracy is 0.8277\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.806833\n",
      "The training accuracy is 0.7080\n",
      "The validation loss is 0.5357\n",
      "The valudation accuracy is 0.8285\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.811807\n",
      "The training accuracy is 0.7084\n",
      "The validation loss is 0.5328\n",
      "The valudation accuracy is 0.8278\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.789666\n",
      "The training accuracy is 0.7091\n",
      "The validation loss is 0.5281\n",
      "The valudation accuracy is 0.8294\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.796229\n",
      "The training accuracy is 0.7097\n",
      "The validation loss is 0.5334\n",
      "The valudation accuracy is 0.8311\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.806509\n",
      "The training accuracy is 0.7100\n",
      "The validation loss is 0.5256\n",
      "The valudation accuracy is 0.8281\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.802228\n",
      "The training accuracy is 0.7105\n",
      "The validation loss is 0.5232\n",
      "The valudation accuracy is 0.8274\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.779728\n",
      "The training accuracy is 0.7111\n",
      "The validation loss is 0.5246\n",
      "The valudation accuracy is 0.8305\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.795021\n",
      "The training accuracy is 0.7117\n",
      "The validation loss is 0.5213\n",
      "The valudation accuracy is 0.8309\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.784055\n",
      "The training accuracy is 0.7123\n",
      "The validation loss is 0.5183\n",
      "The valudation accuracy is 0.8316\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.798038\n",
      "The training accuracy is 0.7128\n",
      "The validation loss is 0.5165\n",
      "The valudation accuracy is 0.8325\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.773802\n",
      "The training accuracy is 0.7135\n",
      "The validation loss is 0.5196\n",
      "The valudation accuracy is 0.8324\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.784694\n",
      "The training accuracy is 0.7139\n",
      "The validation loss is 0.5124\n",
      "The valudation accuracy is 0.8326\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.788892\n",
      "The training accuracy is 0.7143\n",
      "The validation loss is 0.5148\n",
      "The valudation accuracy is 0.8316\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.785523\n",
      "The training accuracy is 0.7147\n",
      "The validation loss is 0.5147\n",
      "The valudation accuracy is 0.8319\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.774968\n",
      "The training accuracy is 0.7151\n",
      "The validation loss is 0.5177\n",
      "The valudation accuracy is 0.8336\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.776456\n",
      "The training accuracy is 0.7156\n",
      "The validation loss is 0.5117\n",
      "The valudation accuracy is 0.8347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base2.parameters(),lr=1e-6)\n",
    "train(myCNN_base2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44bc4c02",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7972fd624f4008afabcd97f014d9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/6 Loss : 0.867552\n",
      "The training accuracy is 0.7029\n",
      "The validation loss is 0.5715\n",
      "The valudation accuracy is 0.8151\n",
      "\n",
      "EPOCHS : 1/6 Loss : 0.833696\n",
      "The training accuracy is 0.7098\n",
      "The validation loss is 0.5624\n",
      "The valudation accuracy is 0.8211\n",
      "\n",
      "EPOCHS : 1/6 Loss : 0.836051\n",
      "The training accuracy is 0.7127\n",
      "The validation loss is 0.5576\n",
      "The valudation accuracy is 0.8225\n",
      "\n",
      "EPOCHS : 2/6 Loss : 0.831194\n",
      "The training accuracy is 0.7142\n",
      "The validation loss is 0.5603\n",
      "The valudation accuracy is 0.8231\n",
      "\n",
      "EPOCHS : 2/6 Loss : 0.824647\n",
      "The training accuracy is 0.7150\n",
      "The validation loss is 0.5553\n",
      "The valudation accuracy is 0.8250\n",
      "\n",
      "EPOCHS : 2/6 Loss : 0.842765\n",
      "The training accuracy is 0.7150\n",
      "The validation loss is 0.5553\n",
      "The valudation accuracy is 0.8253\n",
      "\n",
      "EPOCHS : 3/6 Loss : 0.835690\n",
      "The training accuracy is 0.7161\n",
      "The validation loss is 0.5518\n",
      "The valudation accuracy is 0.8262\n",
      "\n",
      "EPOCHS : 3/6 Loss : 0.830139\n",
      "The training accuracy is 0.7165\n",
      "The validation loss is 0.5529\n",
      "The valudation accuracy is 0.8261\n",
      "\n",
      "EPOCHS : 3/6 Loss : 0.805989\n",
      "The training accuracy is 0.7179\n",
      "The validation loss is 0.5534\n",
      "The valudation accuracy is 0.8272\n",
      "\n",
      "EPOCHS : 3/6 Loss : 0.811240\n",
      "The training accuracy is 0.7192\n",
      "The validation loss is 0.5529\n",
      "The valudation accuracy is 0.8262\n",
      "\n",
      "EPOCHS : 4/6 Loss : 0.810503\n",
      "The training accuracy is 0.7199\n",
      "The validation loss is 0.5502\n",
      "The valudation accuracy is 0.8272\n",
      "\n",
      "EPOCHS : 4/6 Loss : 0.813147\n",
      "The training accuracy is 0.7205\n",
      "The validation loss is 0.5478\n",
      "The valudation accuracy is 0.8268\n",
      "\n",
      "EPOCHS : 4/6 Loss : 0.817701\n",
      "The training accuracy is 0.7206\n",
      "The validation loss is 0.5457\n",
      "The valudation accuracy is 0.8267\n",
      "\n",
      "EPOCHS : 5/6 Loss : 0.825940\n",
      "The training accuracy is 0.7204\n",
      "The validation loss is 0.5462\n",
      "The valudation accuracy is 0.8277\n",
      "\n",
      "EPOCHS : 5/6 Loss : 0.812310\n",
      "The training accuracy is 0.7208\n",
      "The validation loss is 0.5476\n",
      "The valudation accuracy is 0.8272\n",
      "\n",
      "EPOCHS : 5/6 Loss : 0.802498\n",
      "The training accuracy is 0.7212\n",
      "The validation loss is 0.5491\n",
      "The valudation accuracy is 0.8272\n",
      "\n",
      "EPOCHS : 6/6 Loss : 0.834990\n",
      "The training accuracy is 0.7210\n",
      "The validation loss is 0.5465\n",
      "The valudation accuracy is 0.8270\n",
      "\n",
      "EPOCHS : 6/6 Loss : 0.809596\n",
      "The training accuracy is 0.7212\n",
      "The validation loss is 0.5469\n",
      "The valudation accuracy is 0.8269\n",
      "\n",
      "EPOCHS : 6/6 Loss : 0.824129\n",
      "The training accuracy is 0.7210\n",
      "The validation loss is 0.5419\n",
      "The valudation accuracy is 0.8275\n",
      "\n",
      "EPOCHS : 6/6 Loss : 0.816664\n",
      "The training accuracy is 0.7211\n",
      "The validation loss is 0.5386\n",
      "The valudation accuracy is 0.8272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_base2.parameters(),lr=1e-7)\n",
    "train(myCNN_base2,train_loader,6,20 ,criterion,optimizer,'cuda',\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bfd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b1292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1211665",
   "metadata": {},
   "source": [
    "# model-dense1 - train 57%/1.17 - val 65%/0.96\n",
    "worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f29c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 3 dense (256+64)\n",
    "class CNN_dense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_dense,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,256,True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256,64,True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79b03673",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_dense(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_dense1 = CNN_dense()\n",
    "myCNN_dense1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db5e79bc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f234984679492f9a9bf07741523d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.275163\n",
      "The training accuracy is 0.1250\n",
      "The validation loss is 2.1680\n",
      "The valudation accuracy is 0.1954\n",
      "\n",
      "EPOCHS : 1/12 Loss : 2.110836\n",
      "The training accuracy is 0.1712\n",
      "The validation loss is 2.0152\n",
      "The valudation accuracy is 0.2525\n",
      "\n",
      "EPOCHS : 1/12 Loss : 2.050636\n",
      "The training accuracy is 0.1921\n",
      "The validation loss is 1.9242\n",
      "The valudation accuracy is 0.2807\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.894051\n",
      "The training accuracy is 0.2192\n",
      "The validation loss is 1.7606\n",
      "The valudation accuracy is 0.3508\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.817038\n",
      "The training accuracy is 0.2412\n",
      "The validation loss is 1.7154\n",
      "The valudation accuracy is 0.3886\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.767343\n",
      "The training accuracy is 0.2600\n",
      "The validation loss is 1.6679\n",
      "The valudation accuracy is 0.3993\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.722849\n",
      "The training accuracy is 0.2770\n",
      "The validation loss is 1.5760\n",
      "The valudation accuracy is 0.4395\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.705834\n",
      "The training accuracy is 0.2907\n",
      "The validation loss is 1.6170\n",
      "The valudation accuracy is 0.4165\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.670724\n",
      "The training accuracy is 0.3032\n",
      "The validation loss is 1.5196\n",
      "The valudation accuracy is 0.4625\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.635277\n",
      "The training accuracy is 0.3141\n",
      "The validation loss is 1.4597\n",
      "The valudation accuracy is 0.4768\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.616393\n",
      "The training accuracy is 0.3234\n",
      "The validation loss is 1.5018\n",
      "The valudation accuracy is 0.4654\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.592218\n",
      "The training accuracy is 0.3321\n",
      "The validation loss is 1.5130\n",
      "The valudation accuracy is 0.4681\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.580651\n",
      "The training accuracy is 0.3397\n",
      "The validation loss is 1.4284\n",
      "The valudation accuracy is 0.4966\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.554870\n",
      "The training accuracy is 0.3475\n",
      "The validation loss is 1.3755\n",
      "The valudation accuracy is 0.5117\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.544336\n",
      "The training accuracy is 0.3544\n",
      "The validation loss is 1.3497\n",
      "The valudation accuracy is 0.5234\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.511750\n",
      "The training accuracy is 0.3613\n",
      "The validation loss is 1.3599\n",
      "The valudation accuracy is 0.5184\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.514675\n",
      "The training accuracy is 0.3671\n",
      "The validation loss is 1.3762\n",
      "The valudation accuracy is 0.5193\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.492543\n",
      "The training accuracy is 0.3727\n",
      "The validation loss is 1.3665\n",
      "The valudation accuracy is 0.5149\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.496511\n",
      "The training accuracy is 0.3777\n",
      "The validation loss is 1.3220\n",
      "The valudation accuracy is 0.5349\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.473036\n",
      "The training accuracy is 0.3827\n",
      "The validation loss is 1.2916\n",
      "The valudation accuracy is 0.5407\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.473378\n",
      "The training accuracy is 0.3871\n",
      "The validation loss is 1.3266\n",
      "The valudation accuracy is 0.5278\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.446238\n",
      "The training accuracy is 0.3916\n",
      "The validation loss is 1.2589\n",
      "The valudation accuracy is 0.5508\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.408843\n",
      "The training accuracy is 0.3961\n",
      "The validation loss is 1.2421\n",
      "The valudation accuracy is 0.5567\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.433183\n",
      "The training accuracy is 0.4001\n",
      "The validation loss is 1.2361\n",
      "The valudation accuracy is 0.5605\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.401503\n",
      "The training accuracy is 0.4040\n",
      "The validation loss is 1.1789\n",
      "The valudation accuracy is 0.5832\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.404938\n",
      "The training accuracy is 0.4079\n",
      "The validation loss is 1.2316\n",
      "The valudation accuracy is 0.5473\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.367015\n",
      "The training accuracy is 0.4119\n",
      "The validation loss is 1.1919\n",
      "The valudation accuracy is 0.5667\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.367751\n",
      "The training accuracy is 0.4154\n",
      "The validation loss is 1.1630\n",
      "The valudation accuracy is 0.5871\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.367828\n",
      "The training accuracy is 0.4187\n",
      "The validation loss is 1.1649\n",
      "The valudation accuracy is 0.5936\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.355292\n",
      "The training accuracy is 0.4220\n",
      "The validation loss is 1.2384\n",
      "The valudation accuracy is 0.5637\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.347514\n",
      "The training accuracy is 0.4252\n",
      "The validation loss is 1.1226\n",
      "The valudation accuracy is 0.6002\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.345334\n",
      "The training accuracy is 0.4283\n",
      "The validation loss is 1.1536\n",
      "The valudation accuracy is 0.5853\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.312030\n",
      "The training accuracy is 0.4314\n",
      "The validation loss is 1.1104\n",
      "The valudation accuracy is 0.6067\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.331336\n",
      "The training accuracy is 0.4341\n",
      "The validation loss is 1.1341\n",
      "The valudation accuracy is 0.5949\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.324332\n",
      "The training accuracy is 0.4369\n",
      "The validation loss is 1.0828\n",
      "The valudation accuracy is 0.6132\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.288939\n",
      "The training accuracy is 0.4400\n",
      "The validation loss is 1.1492\n",
      "The valudation accuracy is 0.5951\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.291659\n",
      "The training accuracy is 0.4427\n",
      "The validation loss is 1.0946\n",
      "The valudation accuracy is 0.6182\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.279688\n",
      "The training accuracy is 0.4453\n",
      "The validation loss is 1.0596\n",
      "The valudation accuracy is 0.6253\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.263424\n",
      "The training accuracy is 0.4481\n",
      "The validation loss is 1.0700\n",
      "The valudation accuracy is 0.6163\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.264152\n",
      "The training accuracy is 0.4507\n",
      "The validation loss is 1.0390\n",
      "The valudation accuracy is 0.6288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_dense1.parameters(),lr=5e-5)\n",
    "train(myCNN_dense1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7bb753d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810d6481b014850b04e7fcdead4a848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.548257\n",
      "The training accuracy is 0.2760\n",
      "The validation loss is 1.1704\n",
      "The valudation accuracy is 0.6080\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.275107\n",
      "The training accuracy is 0.4192\n",
      "The validation loss is 1.0749\n",
      "The valudation accuracy is 0.6359\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.231439\n",
      "The training accuracy is 0.4707\n",
      "The validation loss is 1.0399\n",
      "The valudation accuracy is 0.6402\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.225650\n",
      "The training accuracy is 0.4947\n",
      "The validation loss is 1.0238\n",
      "The valudation accuracy is 0.6399\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.204922\n",
      "The training accuracy is 0.5099\n",
      "The validation loss is 1.0109\n",
      "The valudation accuracy is 0.6436\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.204318\n",
      "The training accuracy is 0.5210\n",
      "The validation loss is 1.0046\n",
      "The valudation accuracy is 0.6451\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.195601\n",
      "The training accuracy is 0.5290\n",
      "The validation loss is 1.0005\n",
      "The valudation accuracy is 0.6455\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.189348\n",
      "The training accuracy is 0.5352\n",
      "The validation loss is 0.9942\n",
      "The valudation accuracy is 0.6463\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.193909\n",
      "The training accuracy is 0.5400\n",
      "The validation loss is 0.9926\n",
      "The valudation accuracy is 0.6490\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.200023\n",
      "The training accuracy is 0.5440\n",
      "The validation loss is 0.9921\n",
      "The valudation accuracy is 0.6477\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.205238\n",
      "The training accuracy is 0.5469\n",
      "The validation loss is 0.9899\n",
      "The valudation accuracy is 0.6478\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.204288\n",
      "The training accuracy is 0.5489\n",
      "The validation loss is 0.9824\n",
      "The valudation accuracy is 0.6489\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.181160\n",
      "The training accuracy is 0.5515\n",
      "The validation loss is 0.9817\n",
      "The valudation accuracy is 0.6495\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.185964\n",
      "The training accuracy is 0.5532\n",
      "The validation loss is 0.9817\n",
      "The valudation accuracy is 0.6486\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.196701\n",
      "The training accuracy is 0.5546\n",
      "The validation loss is 0.9809\n",
      "The valudation accuracy is 0.6462\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.173517\n",
      "The training accuracy is 0.5564\n",
      "The validation loss is 0.9766\n",
      "The valudation accuracy is 0.6501\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.192679\n",
      "The training accuracy is 0.5577\n",
      "The validation loss is 0.9791\n",
      "The valudation accuracy is 0.6502\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.183652\n",
      "The training accuracy is 0.5591\n",
      "The validation loss is 0.9744\n",
      "The valudation accuracy is 0.6491\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.185220\n",
      "The training accuracy is 0.5603\n",
      "The validation loss is 0.9751\n",
      "The valudation accuracy is 0.6469\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.188534\n",
      "The training accuracy is 0.5613\n",
      "The validation loss is 0.9773\n",
      "The valudation accuracy is 0.6520\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.193120\n",
      "The training accuracy is 0.5621\n",
      "The validation loss is 0.9737\n",
      "The valudation accuracy is 0.6497\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.193101\n",
      "The training accuracy is 0.5629\n",
      "The validation loss is 0.9732\n",
      "The valudation accuracy is 0.6506\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.185191\n",
      "The training accuracy is 0.5637\n",
      "The validation loss is 0.9715\n",
      "The valudation accuracy is 0.6513\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.189301\n",
      "The training accuracy is 0.5643\n",
      "The validation loss is 0.9695\n",
      "The valudation accuracy is 0.6532\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.177409\n",
      "The training accuracy is 0.5651\n",
      "The validation loss is 0.9688\n",
      "The valudation accuracy is 0.6528\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.175636\n",
      "The training accuracy is 0.5659\n",
      "The validation loss is 0.9751\n",
      "The valudation accuracy is 0.6522\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.184364\n",
      "The training accuracy is 0.5664\n",
      "The validation loss is 0.9669\n",
      "The valudation accuracy is 0.6511\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.205465\n",
      "The training accuracy is 0.5666\n",
      "The validation loss is 0.9773\n",
      "The valudation accuracy is 0.6500\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.181525\n",
      "The training accuracy is 0.5672\n",
      "The validation loss is 0.9644\n",
      "The valudation accuracy is 0.6538\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.168048\n",
      "The training accuracy is 0.5677\n",
      "The validation loss is 0.9686\n",
      "The valudation accuracy is 0.6528\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.175791\n",
      "The training accuracy is 0.5682\n",
      "The validation loss is 0.9679\n",
      "The valudation accuracy is 0.6543\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.172098\n",
      "The training accuracy is 0.5686\n",
      "The validation loss is 0.9653\n",
      "The valudation accuracy is 0.6527\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.186937\n",
      "The training accuracy is 0.5688\n",
      "The validation loss is 0.9759\n",
      "The valudation accuracy is 0.6514\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.161316\n",
      "The training accuracy is 0.5693\n",
      "The validation loss is 0.9669\n",
      "The valudation accuracy is 0.6532\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.185593\n",
      "The training accuracy is 0.5696\n",
      "The validation loss is 0.9682\n",
      "The valudation accuracy is 0.6535\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.159072\n",
      "The training accuracy is 0.5701\n",
      "The validation loss is 0.9691\n",
      "The valudation accuracy is 0.6530\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.190472\n",
      "The training accuracy is 0.5704\n",
      "The validation loss is 0.9651\n",
      "The valudation accuracy is 0.6550\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.181647\n",
      "The training accuracy is 0.5707\n",
      "The validation loss is 0.9651\n",
      "The valudation accuracy is 0.6546\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.179770\n",
      "The training accuracy is 0.5710\n",
      "The validation loss is 0.9698\n",
      "The valudation accuracy is 0.6525\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.173741\n",
      "The training accuracy is 0.5712\n",
      "The validation loss is 0.9633\n",
      "The valudation accuracy is 0.6547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_dense1.parameters(),lr=1e-6)\n",
    "train(myCNN_dense1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37577223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d1609b",
   "metadata": {},
   "source": [
    "# model-less_conv#1 - train 56%/1.23 - val 65%/1.02\n",
    "Worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adc01ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpler model: conv/pool + conv//pool + conv//pool + conv//pool + 1 dense\n",
    "class CNN_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_conv,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "           # nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "           # nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "           # nn.ReLU(inplace=True),\n",
    "           # nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2a7db1b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_conv(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_less_conv1 = CNN_conv()\n",
    "myCNN_less_conv1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "516ff63c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacdfd8cad23468fa769f3454156bd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.117759\n",
      "The training accuracy is 0.2283\n",
      "The validation loss is 1.9257\n",
      "The valudation accuracy is 0.3257\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.917548\n",
      "The training accuracy is 0.2741\n",
      "The validation loss is 1.7629\n",
      "The valudation accuracy is 0.3934\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.808903\n",
      "The training accuracy is 0.3022\n",
      "The validation loss is 1.6677\n",
      "The valudation accuracy is 0.4242\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.733405\n",
      "The training accuracy is 0.3232\n",
      "The validation loss is 1.5946\n",
      "The valudation accuracy is 0.4406\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.689607\n",
      "The training accuracy is 0.3375\n",
      "The validation loss is 1.5437\n",
      "The valudation accuracy is 0.4499\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.665154\n",
      "The training accuracy is 0.3495\n",
      "The validation loss is 1.5223\n",
      "The valudation accuracy is 0.4546\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.624586\n",
      "The training accuracy is 0.3587\n",
      "The validation loss is 1.4876\n",
      "The valudation accuracy is 0.4744\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.614559\n",
      "The training accuracy is 0.3676\n",
      "The validation loss is 1.4350\n",
      "The valudation accuracy is 0.4952\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.578766\n",
      "The training accuracy is 0.3747\n",
      "The validation loss is 1.4643\n",
      "The valudation accuracy is 0.4821\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.571066\n",
      "The training accuracy is 0.3812\n",
      "The validation loss is 1.3919\n",
      "The valudation accuracy is 0.5188\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.565745\n",
      "The training accuracy is 0.3874\n",
      "The validation loss is 1.4264\n",
      "The valudation accuracy is 0.4974\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.549171\n",
      "The training accuracy is 0.3931\n",
      "The validation loss is 1.4016\n",
      "The valudation accuracy is 0.5140\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.538863\n",
      "The training accuracy is 0.3984\n",
      "The validation loss is 1.3526\n",
      "The valudation accuracy is 0.5340\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.531329\n",
      "The training accuracy is 0.4026\n",
      "The validation loss is 1.3802\n",
      "The valudation accuracy is 0.5246\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.521322\n",
      "The training accuracy is 0.4070\n",
      "The validation loss is 1.3778\n",
      "The valudation accuracy is 0.5206\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.500109\n",
      "The training accuracy is 0.4115\n",
      "The validation loss is 1.3133\n",
      "The valudation accuracy is 0.5528\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.469270\n",
      "The training accuracy is 0.4158\n",
      "The validation loss is 1.3036\n",
      "The valudation accuracy is 0.5510\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.476142\n",
      "The training accuracy is 0.4195\n",
      "The validation loss is 1.2609\n",
      "The valudation accuracy is 0.5666\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.453093\n",
      "The training accuracy is 0.4231\n",
      "The validation loss is 1.2639\n",
      "The valudation accuracy is 0.5638\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.462896\n",
      "The training accuracy is 0.4262\n",
      "The validation loss is 1.2722\n",
      "The valudation accuracy is 0.5667\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.460458\n",
      "The training accuracy is 0.4292\n",
      "The validation loss is 1.2453\n",
      "The valudation accuracy is 0.5752\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.444282\n",
      "The training accuracy is 0.4323\n",
      "The validation loss is 1.2644\n",
      "The valudation accuracy is 0.5593\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.431968\n",
      "The training accuracy is 0.4353\n",
      "The validation loss is 1.2670\n",
      "The valudation accuracy is 0.5612\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.433412\n",
      "The training accuracy is 0.4379\n",
      "The validation loss is 1.2715\n",
      "The valudation accuracy is 0.5702\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.422096\n",
      "The training accuracy is 0.4405\n",
      "The validation loss is 1.2053\n",
      "The valudation accuracy is 0.5825\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.410804\n",
      "The training accuracy is 0.4430\n",
      "The validation loss is 1.2150\n",
      "The valudation accuracy is 0.5839\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.411299\n",
      "The training accuracy is 0.4454\n",
      "The validation loss is 1.2391\n",
      "The valudation accuracy is 0.5712\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.402607\n",
      "The training accuracy is 0.4478\n",
      "The validation loss is 1.1842\n",
      "The valudation accuracy is 0.5852\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.388320\n",
      "The training accuracy is 0.4503\n",
      "The validation loss is 1.2111\n",
      "The valudation accuracy is 0.5865\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.372184\n",
      "The training accuracy is 0.4526\n",
      "The validation loss is 1.1353\n",
      "The valudation accuracy is 0.6141\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.368663\n",
      "The training accuracy is 0.4547\n",
      "The validation loss is 1.1675\n",
      "The valudation accuracy is 0.5977\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.361424\n",
      "The training accuracy is 0.4569\n",
      "The validation loss is 1.1500\n",
      "The valudation accuracy is 0.6055\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.347987\n",
      "The training accuracy is 0.4593\n",
      "The validation loss is 1.1208\n",
      "The valudation accuracy is 0.6091\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.344708\n",
      "The training accuracy is 0.4613\n",
      "The validation loss is 1.1509\n",
      "The valudation accuracy is 0.5983\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.349263\n",
      "The training accuracy is 0.4634\n",
      "The validation loss is 1.0991\n",
      "The valudation accuracy is 0.6199\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.332022\n",
      "The training accuracy is 0.4654\n",
      "The validation loss is 1.1050\n",
      "The valudation accuracy is 0.6270\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.334033\n",
      "The training accuracy is 0.4673\n",
      "The validation loss is 1.1004\n",
      "The valudation accuracy is 0.6200\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.304745\n",
      "The training accuracy is 0.4694\n",
      "The validation loss is 1.0900\n",
      "The valudation accuracy is 0.6263\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.316098\n",
      "The training accuracy is 0.4712\n",
      "The validation loss is 1.0787\n",
      "The valudation accuracy is 0.6271\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.300337\n",
      "The training accuracy is 0.4731\n",
      "The validation loss is 1.0665\n",
      "The valudation accuracy is 0.6367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_less_conv1.parameters(),lr=5e-5)\n",
    "train(myCNN_less_conv1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8302f39b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7f6612de144dfb15a286fae51a76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.270607\n",
      "The training accuracy is 0.5547\n",
      "The validation loss is 1.0463\n",
      "The valudation accuracy is 0.6438\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.264083\n",
      "The training accuracy is 0.5573\n",
      "The validation loss is 1.0457\n",
      "The valudation accuracy is 0.6435\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.259397\n",
      "The training accuracy is 0.5606\n",
      "The validation loss is 1.0437\n",
      "The valudation accuracy is 0.6466\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.259492\n",
      "The training accuracy is 0.5608\n",
      "The validation loss is 1.0431\n",
      "The valudation accuracy is 0.6452\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.247872\n",
      "The training accuracy is 0.5630\n",
      "The validation loss is 1.0368\n",
      "The valudation accuracy is 0.6491\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.252274\n",
      "The training accuracy is 0.5640\n",
      "The validation loss is 1.0408\n",
      "The valudation accuracy is 0.6481\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.267981\n",
      "The training accuracy is 0.5632\n",
      "The validation loss is 1.0395\n",
      "The valudation accuracy is 0.6506\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.243046\n",
      "The training accuracy is 0.5638\n",
      "The validation loss is 1.0368\n",
      "The valudation accuracy is 0.6495\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.265481\n",
      "The training accuracy is 0.5640\n",
      "The validation loss is 1.0421\n",
      "The valudation accuracy is 0.6483\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.263012\n",
      "The training accuracy is 0.5637\n",
      "The validation loss is 1.0361\n",
      "The valudation accuracy is 0.6512\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.274791\n",
      "The training accuracy is 0.5632\n",
      "The validation loss is 1.0344\n",
      "The valudation accuracy is 0.6525\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.252927\n",
      "The training accuracy is 0.5638\n",
      "The validation loss is 1.0333\n",
      "The valudation accuracy is 0.6519\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.256378\n",
      "The training accuracy is 0.5641\n",
      "The validation loss is 1.0335\n",
      "The valudation accuracy is 0.6503\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.253218\n",
      "The training accuracy is 0.5641\n",
      "The validation loss is 1.0329\n",
      "The valudation accuracy is 0.6511\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.269313\n",
      "The training accuracy is 0.5637\n",
      "The validation loss is 1.0353\n",
      "The valudation accuracy is 0.6533\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.246728\n",
      "The training accuracy is 0.5643\n",
      "The validation loss is 1.0283\n",
      "The valudation accuracy is 0.6537\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.246977\n",
      "The training accuracy is 0.5645\n",
      "The validation loss is 1.0341\n",
      "The valudation accuracy is 0.6538\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.244838\n",
      "The training accuracy is 0.5651\n",
      "The validation loss is 1.0385\n",
      "The valudation accuracy is 0.6537\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.248970\n",
      "The training accuracy is 0.5656\n",
      "The validation loss is 1.0291\n",
      "The valudation accuracy is 0.6543\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.255964\n",
      "The training accuracy is 0.5657\n",
      "The validation loss is 1.0285\n",
      "The valudation accuracy is 0.6535\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.240756\n",
      "The training accuracy is 0.5660\n",
      "The validation loss is 1.0279\n",
      "The valudation accuracy is 0.6539\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.240112\n",
      "The training accuracy is 0.5663\n",
      "The validation loss is 1.0288\n",
      "The valudation accuracy is 0.6519\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.256923\n",
      "The training accuracy is 0.5664\n",
      "The validation loss is 1.0283\n",
      "The valudation accuracy is 0.6547\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.256353\n",
      "The training accuracy is 0.5665\n",
      "The validation loss is 1.0244\n",
      "The valudation accuracy is 0.6543\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.261283\n",
      "The training accuracy is 0.5663\n",
      "The validation loss is 1.0258\n",
      "The valudation accuracy is 0.6546\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.234378\n",
      "The training accuracy is 0.5666\n",
      "The validation loss is 1.0256\n",
      "The valudation accuracy is 0.6536\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.242428\n",
      "The training accuracy is 0.5670\n",
      "The validation loss is 1.0297\n",
      "The valudation accuracy is 0.6541\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.253136\n",
      "The training accuracy is 0.5669\n",
      "The validation loss is 1.0228\n",
      "The valudation accuracy is 0.6544\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.259424\n",
      "The training accuracy is 0.5669\n",
      "The validation loss is 1.0279\n",
      "The valudation accuracy is 0.6556\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.245359\n",
      "The training accuracy is 0.5672\n",
      "The validation loss is 1.0248\n",
      "The valudation accuracy is 0.6558\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.260208\n",
      "The training accuracy is 0.5670\n",
      "The validation loss is 1.0247\n",
      "The valudation accuracy is 0.6567\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.240383\n",
      "The training accuracy is 0.5672\n",
      "The validation loss is 1.0253\n",
      "The valudation accuracy is 0.6557\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.248580\n",
      "The training accuracy is 0.5672\n",
      "The validation loss is 1.0240\n",
      "The valudation accuracy is 0.6550\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.242345\n",
      "The training accuracy is 0.5675\n",
      "The validation loss is 1.0229\n",
      "The valudation accuracy is 0.6554\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.259221\n",
      "The training accuracy is 0.5674\n",
      "The validation loss is 1.0249\n",
      "The valudation accuracy is 0.6555\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.233341\n",
      "The training accuracy is 0.5678\n",
      "The validation loss is 1.0213\n",
      "The valudation accuracy is 0.6560\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.248004\n",
      "The training accuracy is 0.5678\n",
      "The validation loss is 1.0188\n",
      "The valudation accuracy is 0.6542\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.250596\n",
      "The training accuracy is 0.5679\n",
      "The validation loss is 1.0253\n",
      "The valudation accuracy is 0.6562\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.237040\n",
      "The training accuracy is 0.5680\n",
      "The validation loss is 1.0197\n",
      "The valudation accuracy is 0.6562\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.235390\n",
      "The training accuracy is 0.5682\n",
      "The validation loss is 1.0198\n",
      "The valudation accuracy is 0.6548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_less_conv1.parameters(),lr=1e-6)\n",
    "train(myCNN_less_conv1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c250497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28afa48",
   "metadata": {},
   "source": [
    "# model_more_filter#1 - train 64%/1.0 - val 73%/0.76\n",
    "slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce388596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# # of filters of first three conv layers doubled\n",
    "class CNN_filter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_filter,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "593de58a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_filter(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_more_filter1 = CNN_filter()\n",
    "myCNN_more_filter1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "588ec6bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517f54e01d994f26b09baadede02cb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.104293\n",
      "The training accuracy is 0.2166\n",
      "The validation loss is 1.9536\n",
      "The valudation accuracy is 0.2825\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.927154\n",
      "The training accuracy is 0.2604\n",
      "The validation loss is 1.7715\n",
      "The valudation accuracy is 0.3840\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.805959\n",
      "The training accuracy is 0.2913\n",
      "The validation loss is 1.6522\n",
      "The valudation accuracy is 0.4134\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.739862\n",
      "The training accuracy is 0.3121\n",
      "The validation loss is 1.6652\n",
      "The valudation accuracy is 0.4137\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.694448\n",
      "The training accuracy is 0.3289\n",
      "The validation loss is 1.5181\n",
      "The valudation accuracy is 0.4673\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.638451\n",
      "The training accuracy is 0.3441\n",
      "The validation loss is 1.5069\n",
      "The valudation accuracy is 0.4672\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.604688\n",
      "The training accuracy is 0.3557\n",
      "The validation loss is 1.4463\n",
      "The valudation accuracy is 0.4924\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.579719\n",
      "The training accuracy is 0.3660\n",
      "The validation loss is 1.4872\n",
      "The valudation accuracy is 0.4766\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.570793\n",
      "The training accuracy is 0.3743\n",
      "The validation loss is 1.4117\n",
      "The valudation accuracy is 0.5011\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.515983\n",
      "The training accuracy is 0.3826\n",
      "The validation loss is 1.3256\n",
      "The valudation accuracy is 0.5409\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.537586\n",
      "The training accuracy is 0.3891\n",
      "The validation loss is 1.3291\n",
      "The valudation accuracy is 0.5388\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.481041\n",
      "The training accuracy is 0.3960\n",
      "The validation loss is 1.2908\n",
      "The valudation accuracy is 0.5557\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.476968\n",
      "The training accuracy is 0.4023\n",
      "The validation loss is 1.2853\n",
      "The valudation accuracy is 0.5427\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.474312\n",
      "The training accuracy is 0.4078\n",
      "The validation loss is 1.2785\n",
      "The valudation accuracy is 0.5470\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.447396\n",
      "The training accuracy is 0.4131\n",
      "The validation loss is 1.2576\n",
      "The valudation accuracy is 0.5608\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.413099\n",
      "The training accuracy is 0.4189\n",
      "The validation loss is 1.2032\n",
      "The valudation accuracy is 0.5750\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.421195\n",
      "The training accuracy is 0.4236\n",
      "The validation loss is 1.2239\n",
      "The valudation accuracy is 0.5719\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.400109\n",
      "The training accuracy is 0.4283\n",
      "The validation loss is 1.1788\n",
      "The valudation accuracy is 0.5833\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.389459\n",
      "The training accuracy is 0.4327\n",
      "The validation loss is 1.1943\n",
      "The valudation accuracy is 0.5776\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.393594\n",
      "The training accuracy is 0.4368\n",
      "The validation loss is 1.1593\n",
      "The valudation accuracy is 0.5971\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.353502\n",
      "The training accuracy is 0.4410\n",
      "The validation loss is 1.2131\n",
      "The valudation accuracy is 0.5718\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.359106\n",
      "The training accuracy is 0.4447\n",
      "The validation loss is 1.1151\n",
      "The valudation accuracy is 0.6136\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.320104\n",
      "The training accuracy is 0.4487\n",
      "The validation loss is 1.1318\n",
      "The valudation accuracy is 0.6034\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.324016\n",
      "The training accuracy is 0.4523\n",
      "The validation loss is 1.0815\n",
      "The valudation accuracy is 0.6179\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.323468\n",
      "The training accuracy is 0.4559\n",
      "The validation loss is 1.0772\n",
      "The valudation accuracy is 0.6262\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.316988\n",
      "The training accuracy is 0.4590\n",
      "The validation loss is 1.0958\n",
      "The valudation accuracy is 0.6117\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.277349\n",
      "The training accuracy is 0.4626\n",
      "The validation loss is 1.0495\n",
      "The valudation accuracy is 0.6346\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.284637\n",
      "The training accuracy is 0.4656\n",
      "The validation loss is 1.0697\n",
      "The valudation accuracy is 0.6303\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.258409\n",
      "The training accuracy is 0.4689\n",
      "The validation loss is 1.0674\n",
      "The valudation accuracy is 0.6320\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.253926\n",
      "The training accuracy is 0.4721\n",
      "The validation loss is 0.9961\n",
      "The valudation accuracy is 0.6544\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.235694\n",
      "The training accuracy is 0.4750\n",
      "The validation loss is 0.9921\n",
      "The valudation accuracy is 0.6566\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.208087\n",
      "The training accuracy is 0.4781\n",
      "The validation loss is 0.9830\n",
      "The valudation accuracy is 0.6615\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.224992\n",
      "The training accuracy is 0.4809\n",
      "The validation loss is 0.9631\n",
      "The valudation accuracy is 0.6659\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.213725\n",
      "The training accuracy is 0.4836\n",
      "The validation loss is 0.9467\n",
      "The valudation accuracy is 0.6690\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.201433\n",
      "The training accuracy is 0.4864\n",
      "The validation loss is 0.9515\n",
      "The valudation accuracy is 0.6671\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.169621\n",
      "The training accuracy is 0.4894\n",
      "The validation loss is 0.9807\n",
      "The valudation accuracy is 0.6585\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.165619\n",
      "The training accuracy is 0.4921\n",
      "The validation loss is 0.9292\n",
      "The valudation accuracy is 0.6736\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.134418\n",
      "The training accuracy is 0.4950\n",
      "The validation loss is 0.8819\n",
      "The valudation accuracy is 0.6924\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.133416\n",
      "The training accuracy is 0.4979\n",
      "The validation loss is 0.9557\n",
      "The valudation accuracy is 0.6596\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.129846\n",
      "The training accuracy is 0.5005\n",
      "The validation loss is 0.8291\n",
      "The valudation accuracy is 0.7088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_more_filter1.parameters(),lr=5e-5)\n",
    "train(myCNN_more_filter1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "948e670b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e92c063a7240d9be29964cb568b24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.072912\n",
      "The training accuracy is 0.6258\n",
      "The validation loss is 0.8119\n",
      "The valudation accuracy is 0.7223\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.052176\n",
      "The training accuracy is 0.6311\n",
      "The validation loss is 0.7987\n",
      "The valudation accuracy is 0.7240\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.058794\n",
      "The training accuracy is 0.6317\n",
      "The validation loss is 0.7941\n",
      "The valudation accuracy is 0.7259\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.048181\n",
      "The training accuracy is 0.6333\n",
      "The validation loss is 0.7915\n",
      "The valudation accuracy is 0.7281\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.022270\n",
      "The training accuracy is 0.6354\n",
      "The validation loss is 0.7854\n",
      "The valudation accuracy is 0.7289\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.024732\n",
      "The training accuracy is 0.6365\n",
      "The validation loss is 0.7791\n",
      "The valudation accuracy is 0.7296\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.026536\n",
      "The training accuracy is 0.6372\n",
      "The validation loss is 0.7853\n",
      "The valudation accuracy is 0.7285\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.013485\n",
      "The training accuracy is 0.6380\n",
      "The validation loss is 0.7771\n",
      "The valudation accuracy is 0.7299\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.028113\n",
      "The training accuracy is 0.6381\n",
      "The validation loss is 0.7828\n",
      "The valudation accuracy is 0.7294\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.023953\n",
      "The training accuracy is 0.6386\n",
      "The validation loss is 0.7809\n",
      "The valudation accuracy is 0.7308\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.036380\n",
      "The training accuracy is 0.6383\n",
      "The validation loss is 0.7790\n",
      "The valudation accuracy is 0.7292\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.015719\n",
      "The training accuracy is 0.6389\n",
      "The validation loss is 0.7749\n",
      "The valudation accuracy is 0.7305\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.013471\n",
      "The training accuracy is 0.6394\n",
      "The validation loss is 0.7745\n",
      "The valudation accuracy is 0.7305\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.011532\n",
      "The training accuracy is 0.6400\n",
      "The validation loss is 0.7720\n",
      "The valudation accuracy is 0.7295\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.002387\n",
      "The training accuracy is 0.6408\n",
      "The validation loss is 0.7706\n",
      "The valudation accuracy is 0.7330\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.025847\n",
      "The training accuracy is 0.6409\n",
      "The validation loss is 0.7725\n",
      "The valudation accuracy is 0.7327\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.016858\n",
      "The training accuracy is 0.6411\n",
      "The validation loss is 0.7701\n",
      "The valudation accuracy is 0.7298\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.004977\n",
      "The training accuracy is 0.6416\n",
      "The validation loss is 0.7716\n",
      "The valudation accuracy is 0.7311\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.009703\n",
      "The training accuracy is 0.6418\n",
      "The validation loss is 0.7679\n",
      "The valudation accuracy is 0.7320\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.007011\n",
      "The training accuracy is 0.6419\n",
      "The validation loss is 0.7672\n",
      "The valudation accuracy is 0.7318\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.017874\n",
      "The training accuracy is 0.6422\n",
      "The validation loss is 0.7696\n",
      "The valudation accuracy is 0.7348\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.007577\n",
      "The training accuracy is 0.6424\n",
      "The validation loss is 0.7665\n",
      "The valudation accuracy is 0.7329\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.020688\n",
      "The training accuracy is 0.6422\n",
      "The validation loss is 0.7646\n",
      "The valudation accuracy is 0.7330\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.020538\n",
      "The training accuracy is 0.6421\n",
      "The validation loss is 0.7669\n",
      "The valudation accuracy is 0.7349\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.007471\n",
      "The training accuracy is 0.6423\n",
      "The validation loss is 0.7615\n",
      "The valudation accuracy is 0.7333\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.023197\n",
      "The training accuracy is 0.6425\n",
      "The validation loss is 0.7597\n",
      "The valudation accuracy is 0.7343\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.016522\n",
      "The training accuracy is 0.6426\n",
      "The validation loss is 0.7623\n",
      "The valudation accuracy is 0.7355\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.003188\n",
      "The training accuracy is 0.6427\n",
      "The validation loss is 0.7586\n",
      "The valudation accuracy is 0.7342\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.011932\n",
      "The training accuracy is 0.6430\n",
      "The validation loss is 0.7593\n",
      "The valudation accuracy is 0.7350\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.006868\n",
      "The training accuracy is 0.6432\n",
      "The validation loss is 0.7635\n",
      "The valudation accuracy is 0.7352\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.997090\n",
      "The training accuracy is 0.6433\n",
      "The validation loss is 0.7659\n",
      "The valudation accuracy is 0.7360\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.992728\n",
      "The training accuracy is 0.6437\n",
      "The validation loss is 0.7612\n",
      "The valudation accuracy is 0.7352\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.978893\n",
      "The training accuracy is 0.6442\n",
      "The validation loss is 0.7564\n",
      "The valudation accuracy is 0.7360\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.011752\n",
      "The training accuracy is 0.6442\n",
      "The validation loss is 0.7538\n",
      "The valudation accuracy is 0.7365\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.007051\n",
      "The training accuracy is 0.6443\n",
      "The validation loss is 0.7559\n",
      "The valudation accuracy is 0.7366\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.002293\n",
      "The training accuracy is 0.6444\n",
      "The validation loss is 0.7573\n",
      "The valudation accuracy is 0.7364\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.000006\n",
      "The training accuracy is 0.6446\n",
      "The validation loss is 0.7572\n",
      "The valudation accuracy is 0.7363\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.007301\n",
      "The training accuracy is 0.6446\n",
      "The validation loss is 0.7642\n",
      "The valudation accuracy is 0.7361\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.004921\n",
      "The training accuracy is 0.6446\n",
      "The validation loss is 0.7589\n",
      "The valudation accuracy is 0.7378\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.996839\n",
      "The training accuracy is 0.6447\n",
      "The validation loss is 0.7529\n",
      "The valudation accuracy is 0.7382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_more_filter1.parameters(),lr=1e-6)\n",
    "train(myCNN_more_filter1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac8ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df356242",
   "metadata": {},
   "source": [
    "# model_more_filter#2 - train 73%/0.74 - val 82%/0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9b832d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# # of filters of first all conv layers doubled\n",
    "class CNN_filter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_filter,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(512,1024,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(16384,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db378d68",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_filter(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_more_filter2 = CNN_filter()\n",
    "myCNN_more_filter2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c9c4eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bead27b6baf45918dd2afe82f7b616f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.130799\n",
      "The training accuracy is 0.2009\n",
      "The validation loss is 1.9515\n",
      "The valudation accuracy is 0.2892\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.854765\n",
      "The training accuracy is 0.2641\n",
      "The validation loss is 1.6922\n",
      "The valudation accuracy is 0.3941\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.747994\n",
      "The training accuracy is 0.2994\n",
      "The validation loss is 1.7273\n",
      "The valudation accuracy is 0.3673\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.689537\n",
      "The training accuracy is 0.3224\n",
      "The validation loss is 1.5161\n",
      "The valudation accuracy is 0.4644\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.653937\n",
      "The training accuracy is 0.3395\n",
      "The validation loss is 1.5405\n",
      "The valudation accuracy is 0.4561\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.605088\n",
      "The training accuracy is 0.3545\n",
      "The validation loss is 1.4770\n",
      "The valudation accuracy is 0.4655\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.554902\n",
      "The training accuracy is 0.3668\n",
      "The validation loss is 1.4061\n",
      "The valudation accuracy is 0.5085\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.536558\n",
      "The training accuracy is 0.3773\n",
      "The validation loss is 1.3328\n",
      "The valudation accuracy is 0.5254\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.489994\n",
      "The training accuracy is 0.3880\n",
      "The validation loss is 1.3050\n",
      "The valudation accuracy is 0.5450\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.449603\n",
      "The training accuracy is 0.3972\n",
      "The validation loss is 1.2321\n",
      "The valudation accuracy is 0.5708\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.426200\n",
      "The training accuracy is 0.4060\n",
      "The validation loss is 1.1939\n",
      "The valudation accuracy is 0.5802\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.391672\n",
      "The training accuracy is 0.4141\n",
      "The validation loss is 1.2435\n",
      "The valudation accuracy is 0.5605\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.374783\n",
      "The training accuracy is 0.4222\n",
      "The validation loss is 1.1461\n",
      "The valudation accuracy is 0.5933\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.356085\n",
      "The training accuracy is 0.4287\n",
      "The validation loss is 1.1776\n",
      "The valudation accuracy is 0.5931\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.316174\n",
      "The training accuracy is 0.4358\n",
      "The validation loss is 1.0997\n",
      "The valudation accuracy is 0.6102\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.295338\n",
      "The training accuracy is 0.4424\n",
      "The validation loss is 1.0608\n",
      "The valudation accuracy is 0.6263\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.262087\n",
      "The training accuracy is 0.4490\n",
      "The validation loss is 1.0724\n",
      "The valudation accuracy is 0.6224\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.233439\n",
      "The training accuracy is 0.4556\n",
      "The validation loss is 0.9831\n",
      "The valudation accuracy is 0.6525\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.227892\n",
      "The training accuracy is 0.4613\n",
      "The validation loss is 1.0083\n",
      "The valudation accuracy is 0.6407\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.199795\n",
      "The training accuracy is 0.4671\n",
      "The validation loss is 0.9255\n",
      "The valudation accuracy is 0.6797\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.162190\n",
      "The training accuracy is 0.4729\n",
      "The validation loss is 0.9229\n",
      "The valudation accuracy is 0.6746\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.142663\n",
      "The training accuracy is 0.4787\n",
      "The validation loss is 0.9249\n",
      "The valudation accuracy is 0.6747\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.130234\n",
      "The training accuracy is 0.4840\n",
      "The validation loss is 0.8852\n",
      "The valudation accuracy is 0.6895\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.114307\n",
      "The training accuracy is 0.4891\n",
      "The validation loss is 0.9408\n",
      "The valudation accuracy is 0.6748\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.077694\n",
      "The training accuracy is 0.4946\n",
      "The validation loss is 0.8554\n",
      "The valudation accuracy is 0.7011\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.068701\n",
      "The training accuracy is 0.4996\n",
      "The validation loss is 0.8525\n",
      "The valudation accuracy is 0.7054\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.082083\n",
      "The training accuracy is 0.5041\n",
      "The validation loss is 0.8283\n",
      "The valudation accuracy is 0.7077\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.040988\n",
      "The training accuracy is 0.5091\n",
      "The validation loss is 0.7694\n",
      "The valudation accuracy is 0.7288\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.005359\n",
      "The training accuracy is 0.5139\n",
      "The validation loss is 0.7304\n",
      "The valudation accuracy is 0.7376\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.012654\n",
      "The training accuracy is 0.5181\n",
      "The validation loss is 0.7617\n",
      "The valudation accuracy is 0.7333\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.993534\n",
      "The training accuracy is 0.5224\n",
      "The validation loss is 0.7618\n",
      "The valudation accuracy is 0.7365\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.988126\n",
      "The training accuracy is 0.5265\n",
      "The validation loss is 0.7025\n",
      "The valudation accuracy is 0.7466\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.946713\n",
      "The training accuracy is 0.5307\n",
      "The validation loss is 0.6768\n",
      "The valudation accuracy is 0.7631\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.957855\n",
      "The training accuracy is 0.5346\n",
      "The validation loss is 0.6796\n",
      "The valudation accuracy is 0.7586\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.945984\n",
      "The training accuracy is 0.5386\n",
      "The validation loss is 0.6525\n",
      "The valudation accuracy is 0.7730\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.920318\n",
      "The training accuracy is 0.5423\n",
      "The validation loss is 0.6674\n",
      "The valudation accuracy is 0.7737\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.913945\n",
      "The training accuracy is 0.5461\n",
      "The validation loss is 0.6200\n",
      "The valudation accuracy is 0.7823\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.905618\n",
      "The training accuracy is 0.5496\n",
      "The validation loss is 0.6320\n",
      "The valudation accuracy is 0.7796\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.899671\n",
      "The training accuracy is 0.5531\n",
      "The validation loss is 0.6601\n",
      "The valudation accuracy is 0.7688\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.883382\n",
      "The training accuracy is 0.5566\n",
      "The validation loss is 0.6370\n",
      "The valudation accuracy is 0.7770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_more_filter2.parameters(),lr=5e-5)\n",
    "train(myCNN_more_filter2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b12cbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27677f5b23c4dd1b83b2648fbde371b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 0.809455\n",
      "The training accuracy is 0.7119\n",
      "The validation loss is 0.5493\n",
      "The valudation accuracy is 0.8087\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.807250\n",
      "The training accuracy is 0.7159\n",
      "The validation loss is 0.5407\n",
      "The valudation accuracy is 0.8128\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.779494\n",
      "The training accuracy is 0.7191\n",
      "The validation loss is 0.5359\n",
      "The valudation accuracy is 0.8122\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.797574\n",
      "The training accuracy is 0.7180\n",
      "The validation loss is 0.5314\n",
      "The valudation accuracy is 0.8136\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.781807\n",
      "The training accuracy is 0.7204\n",
      "The validation loss is 0.5284\n",
      "The valudation accuracy is 0.8150\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.778856\n",
      "The training accuracy is 0.7217\n",
      "The validation loss is 0.5247\n",
      "The valudation accuracy is 0.8142\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.778422\n",
      "The training accuracy is 0.7226\n",
      "The validation loss is 0.5214\n",
      "The valudation accuracy is 0.8130\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.774667\n",
      "The training accuracy is 0.7229\n",
      "The validation loss is 0.5193\n",
      "The valudation accuracy is 0.8166\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.783382\n",
      "The training accuracy is 0.7234\n",
      "The validation loss is 0.5261\n",
      "The valudation accuracy is 0.8166\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.771059\n",
      "The training accuracy is 0.7240\n",
      "The validation loss is 0.5209\n",
      "The valudation accuracy is 0.8157\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.780862\n",
      "The training accuracy is 0.7239\n",
      "The validation loss is 0.5232\n",
      "The valudation accuracy is 0.8154\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.785390\n",
      "The training accuracy is 0.7240\n",
      "The validation loss is 0.5193\n",
      "The valudation accuracy is 0.8170\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.761391\n",
      "The training accuracy is 0.7246\n",
      "The validation loss is 0.5121\n",
      "The valudation accuracy is 0.8177\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.764766\n",
      "The training accuracy is 0.7252\n",
      "The validation loss is 0.5150\n",
      "The valudation accuracy is 0.8180\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.768603\n",
      "The training accuracy is 0.7254\n",
      "The validation loss is 0.5158\n",
      "The valudation accuracy is 0.8174\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.765205\n",
      "The training accuracy is 0.7257\n",
      "The validation loss is 0.5147\n",
      "The valudation accuracy is 0.8183\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.765854\n",
      "The training accuracy is 0.7260\n",
      "The validation loss is 0.5127\n",
      "The valudation accuracy is 0.8185\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.779185\n",
      "The training accuracy is 0.7261\n",
      "The validation loss is 0.5108\n",
      "The valudation accuracy is 0.8202\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.751331\n",
      "The training accuracy is 0.7267\n",
      "The validation loss is 0.5099\n",
      "The valudation accuracy is 0.8205\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.759572\n",
      "The training accuracy is 0.7271\n",
      "The validation loss is 0.5083\n",
      "The valudation accuracy is 0.8207\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.757341\n",
      "The training accuracy is 0.7274\n",
      "The validation loss is 0.5076\n",
      "The valudation accuracy is 0.8219\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.770327\n",
      "The training accuracy is 0.7276\n",
      "The validation loss is 0.5059\n",
      "The valudation accuracy is 0.8193\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.759633\n",
      "The training accuracy is 0.7279\n",
      "The validation loss is 0.5094\n",
      "The valudation accuracy is 0.8205\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.754575\n",
      "The training accuracy is 0.7282\n",
      "The validation loss is 0.5079\n",
      "The valudation accuracy is 0.8218\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.767045\n",
      "The training accuracy is 0.7283\n",
      "The validation loss is 0.5020\n",
      "The valudation accuracy is 0.8210\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.748300\n",
      "The training accuracy is 0.7286\n",
      "The validation loss is 0.5059\n",
      "The valudation accuracy is 0.8201\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.762681\n",
      "The training accuracy is 0.7289\n",
      "The validation loss is 0.5000\n",
      "The valudation accuracy is 0.8211\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.748354\n",
      "The training accuracy is 0.7291\n",
      "The validation loss is 0.5040\n",
      "The valudation accuracy is 0.8199\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.757748\n",
      "The training accuracy is 0.7294\n",
      "The validation loss is 0.5041\n",
      "The valudation accuracy is 0.8204\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.751447\n",
      "The training accuracy is 0.7297\n",
      "The validation loss is 0.5050\n",
      "The valudation accuracy is 0.8206\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.750779\n",
      "The training accuracy is 0.7300\n",
      "The validation loss is 0.5022\n",
      "The valudation accuracy is 0.8229\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.758061\n",
      "The training accuracy is 0.7302\n",
      "The validation loss is 0.4990\n",
      "The valudation accuracy is 0.8227\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.755074\n",
      "The training accuracy is 0.7303\n",
      "The validation loss is 0.5014\n",
      "The valudation accuracy is 0.8227\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.750235\n",
      "The training accuracy is 0.7305\n",
      "The validation loss is 0.5024\n",
      "The valudation accuracy is 0.8215\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.753629\n",
      "The training accuracy is 0.7307\n",
      "The validation loss is 0.4997\n",
      "The valudation accuracy is 0.8234\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.755775\n",
      "The training accuracy is 0.7308\n",
      "The validation loss is 0.4983\n",
      "The valudation accuracy is 0.8218\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.750006\n",
      "The training accuracy is 0.7310\n",
      "The validation loss is 0.4972\n",
      "The valudation accuracy is 0.8216\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.745877\n",
      "The training accuracy is 0.7312\n",
      "The validation loss is 0.4969\n",
      "The valudation accuracy is 0.8225\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.741142\n",
      "The training accuracy is 0.7315\n",
      "The validation loss is 0.4978\n",
      "The valudation accuracy is 0.8228\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.745985\n",
      "The training accuracy is 0.7316\n",
      "The validation loss is 0.4969\n",
      "The valudation accuracy is 0.8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_more_filter2.parameters(),lr=1e-6)\n",
    "train(myCNN_more_filter2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da80b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e563a2ad",
   "metadata": {},
   "source": [
    "# model_complex#1 - train 58%/1.17 - val 66.8%/0.93\n",
    "Worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c38b7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex model: conv/conv/pool + conv/conv//conv/pool + conv/conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# duplicate conv layers for the second of each block of conv layers except for the last block\n",
    "class CNN_complex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_complex,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(8192,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aaeeae31",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_complex(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_complex1 = CNN_complex()\n",
    "myCNN_complex1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4087c929",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fa2e22c184485fa037afba8b4671e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.214786\n",
      "The training accuracy is 0.1548\n",
      "The validation loss is 2.0171\n",
      "The valudation accuracy is 0.2625\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.949343\n",
      "The training accuracy is 0.2186\n",
      "The validation loss is 1.8069\n",
      "The valudation accuracy is 0.3531\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.852791\n",
      "The training accuracy is 0.2551\n",
      "The validation loss is 1.7516\n",
      "The valudation accuracy is 0.3964\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.810089\n",
      "The training accuracy is 0.2778\n",
      "The validation loss is 1.7910\n",
      "The valudation accuracy is 0.3632\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.761293\n",
      "The training accuracy is 0.2962\n",
      "The validation loss is 1.7090\n",
      "The valudation accuracy is 0.4123\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.712550\n",
      "The training accuracy is 0.3116\n",
      "The validation loss is 1.5559\n",
      "The valudation accuracy is 0.4447\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.708691\n",
      "The training accuracy is 0.3224\n",
      "The validation loss is 1.5647\n",
      "The valudation accuracy is 0.4590\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.642507\n",
      "The training accuracy is 0.3335\n",
      "The validation loss is 1.5030\n",
      "The valudation accuracy is 0.4755\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.623438\n",
      "The training accuracy is 0.3434\n",
      "The validation loss is 1.5620\n",
      "The valudation accuracy is 0.4659\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.608105\n",
      "The training accuracy is 0.3516\n",
      "The validation loss is 1.4592\n",
      "The valudation accuracy is 0.4984\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.586690\n",
      "The training accuracy is 0.3591\n",
      "The validation loss is 1.5258\n",
      "The valudation accuracy is 0.4639\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.572451\n",
      "The training accuracy is 0.3662\n",
      "The validation loss is 1.3824\n",
      "The valudation accuracy is 0.5198\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.552646\n",
      "The training accuracy is 0.3725\n",
      "The validation loss is 1.3669\n",
      "The valudation accuracy is 0.5233\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.546454\n",
      "The training accuracy is 0.3780\n",
      "The validation loss is 1.3981\n",
      "The valudation accuracy is 0.5189\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.511461\n",
      "The training accuracy is 0.3839\n",
      "The validation loss is 1.3781\n",
      "The valudation accuracy is 0.5185\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.503822\n",
      "The training accuracy is 0.3894\n",
      "The validation loss is 1.3510\n",
      "The valudation accuracy is 0.5307\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.503658\n",
      "The training accuracy is 0.3941\n",
      "The validation loss is 1.3215\n",
      "The valudation accuracy is 0.5441\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.491594\n",
      "The training accuracy is 0.3987\n",
      "The validation loss is 1.3136\n",
      "The valudation accuracy is 0.5446\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.451024\n",
      "The training accuracy is 0.4033\n",
      "The validation loss is 1.2736\n",
      "The valudation accuracy is 0.5604\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.449300\n",
      "The training accuracy is 0.4077\n",
      "The validation loss is 1.2826\n",
      "The valudation accuracy is 0.5523\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.429961\n",
      "The training accuracy is 0.4118\n",
      "The validation loss is 1.2668\n",
      "The valudation accuracy is 0.5575\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.440183\n",
      "The training accuracy is 0.4156\n",
      "The validation loss is 1.2360\n",
      "The valudation accuracy is 0.5667\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.418962\n",
      "The training accuracy is 0.4193\n",
      "The validation loss is 1.2505\n",
      "The valudation accuracy is 0.5614\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.398362\n",
      "The training accuracy is 0.4229\n",
      "The validation loss is 1.2334\n",
      "The valudation accuracy is 0.5649\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.420847\n",
      "The training accuracy is 0.4259\n",
      "The validation loss is 1.2204\n",
      "The valudation accuracy is 0.5640\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.371065\n",
      "The training accuracy is 0.4293\n",
      "The validation loss is 1.1798\n",
      "The valudation accuracy is 0.5931\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.372792\n",
      "The training accuracy is 0.4326\n",
      "The validation loss is 1.2039\n",
      "The valudation accuracy is 0.5767\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.361834\n",
      "The training accuracy is 0.4356\n",
      "The validation loss is 1.1360\n",
      "The valudation accuracy is 0.6108\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.362553\n",
      "The training accuracy is 0.4385\n",
      "The validation loss is 1.1681\n",
      "The valudation accuracy is 0.5974\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.357229\n",
      "The training accuracy is 0.4412\n",
      "The validation loss is 1.2446\n",
      "The valudation accuracy is 0.5585\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.338061\n",
      "The training accuracy is 0.4441\n",
      "The validation loss is 1.1039\n",
      "The valudation accuracy is 0.6106\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.318053\n",
      "The training accuracy is 0.4470\n",
      "The validation loss is 1.1023\n",
      "The valudation accuracy is 0.6151\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.317229\n",
      "The training accuracy is 0.4496\n",
      "The validation loss is 1.1507\n",
      "The valudation accuracy is 0.6003\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.325816\n",
      "The training accuracy is 0.4522\n",
      "The validation loss is 1.1763\n",
      "The valudation accuracy is 0.5848\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.306885\n",
      "The training accuracy is 0.4548\n",
      "The validation loss is 1.1046\n",
      "The valudation accuracy is 0.6126\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.285240\n",
      "The training accuracy is 0.4574\n",
      "The validation loss is 1.0743\n",
      "The valudation accuracy is 0.6120\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.289437\n",
      "The training accuracy is 0.4598\n",
      "The validation loss is 1.0556\n",
      "The valudation accuracy is 0.6315\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.265489\n",
      "The training accuracy is 0.4624\n",
      "The validation loss is 1.0393\n",
      "The valudation accuracy is 0.6361\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.258758\n",
      "The training accuracy is 0.4649\n",
      "The validation loss is 1.0338\n",
      "The valudation accuracy is 0.6319\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.280705\n",
      "The training accuracy is 0.4670\n",
      "The validation loss is 1.0532\n",
      "The valudation accuracy is 0.6297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_complex1.parameters(),lr=5e-5)\n",
    "train(myCNN_complex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d979c67e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68500cc13b964e4d9e4f49d692fcec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.210104\n",
      "The training accuracy is 0.5778\n",
      "The validation loss is 0.9827\n",
      "The valudation accuracy is 0.6566\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.201532\n",
      "The training accuracy is 0.5750\n",
      "The validation loss is 0.9732\n",
      "The valudation accuracy is 0.6600\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.191466\n",
      "The training accuracy is 0.5769\n",
      "The validation loss is 0.9681\n",
      "The valudation accuracy is 0.6618\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.213356\n",
      "The training accuracy is 0.5758\n",
      "The validation loss is 0.9694\n",
      "The valudation accuracy is 0.6611\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.193245\n",
      "The training accuracy is 0.5761\n",
      "The validation loss is 0.9606\n",
      "The valudation accuracy is 0.6634\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.185975\n",
      "The training accuracy is 0.5782\n",
      "The validation loss is 0.9650\n",
      "The valudation accuracy is 0.6600\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.187006\n",
      "The training accuracy is 0.5787\n",
      "The validation loss is 0.9608\n",
      "The valudation accuracy is 0.6620\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.195282\n",
      "The training accuracy is 0.5784\n",
      "The validation loss is 0.9596\n",
      "The valudation accuracy is 0.6621\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.185594\n",
      "The training accuracy is 0.5791\n",
      "The validation loss is 0.9552\n",
      "The valudation accuracy is 0.6653\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.189146\n",
      "The training accuracy is 0.5796\n",
      "The validation loss is 0.9527\n",
      "The valudation accuracy is 0.6658\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.173887\n",
      "The training accuracy is 0.5811\n",
      "The validation loss is 0.9528\n",
      "The valudation accuracy is 0.6636\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.201490\n",
      "The training accuracy is 0.5814\n",
      "The validation loss is 0.9560\n",
      "The valudation accuracy is 0.6654\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.186276\n",
      "The training accuracy is 0.5813\n",
      "The validation loss is 0.9500\n",
      "The valudation accuracy is 0.6645\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.187424\n",
      "The training accuracy is 0.5815\n",
      "The validation loss is 0.9501\n",
      "The valudation accuracy is 0.6657\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.174063\n",
      "The training accuracy is 0.5818\n",
      "The validation loss is 0.9521\n",
      "The valudation accuracy is 0.6662\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.174026\n",
      "The training accuracy is 0.5821\n",
      "The validation loss is 0.9491\n",
      "The valudation accuracy is 0.6648\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.177552\n",
      "The training accuracy is 0.5821\n",
      "The validation loss is 0.9465\n",
      "The valudation accuracy is 0.6682\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.186631\n",
      "The training accuracy is 0.5820\n",
      "The validation loss is 0.9558\n",
      "The valudation accuracy is 0.6659\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.166345\n",
      "The training accuracy is 0.5824\n",
      "The validation loss is 0.9493\n",
      "The valudation accuracy is 0.6667\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.171535\n",
      "The training accuracy is 0.5825\n",
      "The validation loss is 0.9541\n",
      "The valudation accuracy is 0.6681\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.172460\n",
      "The training accuracy is 0.5826\n",
      "The validation loss is 0.9493\n",
      "The valudation accuracy is 0.6657\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.172790\n",
      "The training accuracy is 0.5828\n",
      "The validation loss is 0.9468\n",
      "The valudation accuracy is 0.6673\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.183258\n",
      "The training accuracy is 0.5827\n",
      "The validation loss is 0.9517\n",
      "The valudation accuracy is 0.6667\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.182983\n",
      "The training accuracy is 0.5828\n",
      "The validation loss is 0.9442\n",
      "The valudation accuracy is 0.6691\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.186657\n",
      "The training accuracy is 0.5829\n",
      "The validation loss is 0.9473\n",
      "The valudation accuracy is 0.6691\n",
      "\n",
      "EPOCHS : 8/12 Loss : 1.190144\n",
      "The training accuracy is 0.5829\n",
      "The validation loss is 0.9475\n",
      "The valudation accuracy is 0.6684\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.182439\n",
      "The training accuracy is 0.5831\n",
      "The validation loss is 0.9443\n",
      "The valudation accuracy is 0.6686\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.176951\n",
      "The training accuracy is 0.5831\n",
      "The validation loss is 0.9463\n",
      "The valudation accuracy is 0.6695\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.175956\n",
      "The training accuracy is 0.5831\n",
      "The validation loss is 0.9417\n",
      "The valudation accuracy is 0.6705\n",
      "\n",
      "EPOCHS : 9/12 Loss : 1.163352\n",
      "The training accuracy is 0.5835\n",
      "The validation loss is 0.9475\n",
      "The valudation accuracy is 0.6700\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.170808\n",
      "The training accuracy is 0.5836\n",
      "The validation loss is 0.9443\n",
      "The valudation accuracy is 0.6687\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.154636\n",
      "The training accuracy is 0.5841\n",
      "The validation loss is 0.9444\n",
      "The valudation accuracy is 0.6681\n",
      "\n",
      "EPOCHS : 10/12 Loss : 1.165523\n",
      "The training accuracy is 0.5844\n",
      "The validation loss is 0.9461\n",
      "The valudation accuracy is 0.6705\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.184244\n",
      "The training accuracy is 0.5845\n",
      "The validation loss is 0.9384\n",
      "The valudation accuracy is 0.6705\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.153809\n",
      "The training accuracy is 0.5848\n",
      "The validation loss is 0.9417\n",
      "The valudation accuracy is 0.6711\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.164739\n",
      "The training accuracy is 0.5850\n",
      "The validation loss is 0.9357\n",
      "The valudation accuracy is 0.6722\n",
      "\n",
      "EPOCHS : 11/12 Loss : 1.166846\n",
      "The training accuracy is 0.5851\n",
      "The validation loss is 0.9381\n",
      "The valudation accuracy is 0.6711\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.165618\n",
      "The training accuracy is 0.5851\n",
      "The validation loss is 0.9329\n",
      "The valudation accuracy is 0.6708\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.180257\n",
      "The training accuracy is 0.5852\n",
      "The validation loss is 0.9383\n",
      "The valudation accuracy is 0.6716\n",
      "\n",
      "EPOCHS : 12/12 Loss : 1.152201\n",
      "The training accuracy is 0.5855\n",
      "The validation loss is 0.9349\n",
      "The valudation accuracy is 0.6712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_complex1.parameters(),lr=1e-6)\n",
    "train(myCNN_complex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15f771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826a1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5c4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357feb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a94f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230186d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb929b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f990027d",
   "metadata": {},
   "source": [
    "# experiment 1 - batchnorm#2 with more filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fac78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# add batchnorm after each conv layer for every conv layer\n",
    "# double the filters \n",
    "class CNN_ex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ex,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.1),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(512,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            #nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(16384,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30cec40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_ex(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_ex1 = CNN_ex()\n",
    "myCNN_ex1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c43c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e597f702112046b48fbfe63d3014a265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.773883\n",
      "The training accuracy is 0.3743\n",
      "The validation loss is 1.4604\n",
      "The valudation accuracy is 0.4886\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.648645\n",
      "The training accuracy is 0.3934\n",
      "The validation loss is 1.3866\n",
      "The valudation accuracy is 0.5227\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.548299\n",
      "The training accuracy is 0.4112\n",
      "The validation loss is 1.3864\n",
      "The valudation accuracy is 0.5119\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.463543\n",
      "The training accuracy is 0.4280\n",
      "The validation loss is 1.1921\n",
      "The valudation accuracy is 0.5881\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.432971\n",
      "The training accuracy is 0.4414\n",
      "The validation loss is 1.2291\n",
      "The valudation accuracy is 0.5669\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.385400\n",
      "The training accuracy is 0.4532\n",
      "The validation loss is 1.1438\n",
      "The valudation accuracy is 0.5926\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.318790\n",
      "The training accuracy is 0.4650\n",
      "The validation loss is 1.0786\n",
      "The valudation accuracy is 0.6077\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.295671\n",
      "The training accuracy is 0.4745\n",
      "The validation loss is 1.0950\n",
      "The valudation accuracy is 0.5996\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.247802\n",
      "The training accuracy is 0.4844\n",
      "The validation loss is 1.0438\n",
      "The valudation accuracy is 0.6288\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.225558\n",
      "The training accuracy is 0.4931\n",
      "The validation loss is 0.8853\n",
      "The valudation accuracy is 0.6938\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.171092\n",
      "The training accuracy is 0.5020\n",
      "The validation loss is 0.8588\n",
      "The valudation accuracy is 0.6961\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.155659\n",
      "The training accuracy is 0.5098\n",
      "The validation loss is 0.9258\n",
      "The valudation accuracy is 0.6623\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.125656\n",
      "The training accuracy is 0.5171\n",
      "The validation loss is 0.8881\n",
      "The valudation accuracy is 0.7045\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.095329\n",
      "The training accuracy is 0.5240\n",
      "The validation loss is 0.8396\n",
      "The valudation accuracy is 0.7059\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.051071\n",
      "The training accuracy is 0.5313\n",
      "The validation loss is 0.7959\n",
      "The valudation accuracy is 0.7257\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.060837\n",
      "The training accuracy is 0.5374\n",
      "The validation loss is 0.8413\n",
      "The valudation accuracy is 0.7042\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.017603\n",
      "The training accuracy is 0.5438\n",
      "The validation loss is 0.7301\n",
      "The valudation accuracy is 0.7514\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.980110\n",
      "The training accuracy is 0.5501\n",
      "The validation loss is 0.7127\n",
      "The valudation accuracy is 0.7515\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.950017\n",
      "The training accuracy is 0.5562\n",
      "The validation loss is 0.6655\n",
      "The valudation accuracy is 0.7666\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.944494\n",
      "The training accuracy is 0.5622\n",
      "The validation loss is 0.6873\n",
      "The valudation accuracy is 0.7647\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.899859\n",
      "The training accuracy is 0.5682\n",
      "The validation loss is 0.5805\n",
      "The valudation accuracy is 0.8030\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.886364\n",
      "The training accuracy is 0.5738\n",
      "The validation loss is 0.5753\n",
      "The valudation accuracy is 0.8019\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.873097\n",
      "The training accuracy is 0.5790\n",
      "The validation loss is 0.6146\n",
      "The valudation accuracy is 0.7873\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.850616\n",
      "The training accuracy is 0.5839\n",
      "The validation loss is 0.5785\n",
      "The valudation accuracy is 0.7962\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.815812\n",
      "The training accuracy is 0.5892\n",
      "The validation loss is 0.5062\n",
      "The valudation accuracy is 0.8301\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.833565\n",
      "The training accuracy is 0.5938\n",
      "The validation loss is 0.5095\n",
      "The valudation accuracy is 0.8236\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.785246\n",
      "The training accuracy is 0.5985\n",
      "The validation loss is 0.5603\n",
      "The valudation accuracy is 0.8091\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.766499\n",
      "The training accuracy is 0.6032\n",
      "The validation loss is 0.5036\n",
      "The valudation accuracy is 0.8257\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.742569\n",
      "The training accuracy is 0.6081\n",
      "The validation loss is 0.4545\n",
      "The valudation accuracy is 0.8424\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.768277\n",
      "The training accuracy is 0.6122\n",
      "The validation loss is 0.4590\n",
      "The valudation accuracy is 0.8423\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.732101\n",
      "The training accuracy is 0.6165\n",
      "The validation loss is 0.4271\n",
      "The valudation accuracy is 0.8567\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.710046\n",
      "The training accuracy is 0.6209\n",
      "The validation loss is 0.4478\n",
      "The valudation accuracy is 0.8462\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.716042\n",
      "The training accuracy is 0.6247\n",
      "The validation loss is 0.3842\n",
      "The valudation accuracy is 0.8695\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.693287\n",
      "The training accuracy is 0.6287\n",
      "The validation loss is 0.4147\n",
      "The valudation accuracy is 0.8549\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.671951\n",
      "The training accuracy is 0.6327\n",
      "The validation loss is 0.3963\n",
      "The valudation accuracy is 0.8649\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.650045\n",
      "The training accuracy is 0.6367\n",
      "The validation loss is 0.4367\n",
      "The valudation accuracy is 0.8467\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.662350\n",
      "The training accuracy is 0.6402\n",
      "The validation loss is 0.4046\n",
      "The valudation accuracy is 0.8610\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.643232\n",
      "The training accuracy is 0.6437\n",
      "The validation loss is 0.3699\n",
      "The valudation accuracy is 0.8768\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.622491\n",
      "The training accuracy is 0.6473\n",
      "The validation loss is 0.3577\n",
      "The valudation accuracy is 0.8794\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.625980\n",
      "The training accuracy is 0.6507\n",
      "The validation loss is 0.4225\n",
      "The valudation accuracy is 0.8632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_ex1.parameters(),lr=5e-5)\n",
    "train(myCNN_ex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbcee6b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b24e0eaf7934963ac248fe38eb0d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.206427\n",
      "The training accuracy is 0.6105\n",
      "The validation loss is 0.7397\n",
      "The valudation accuracy is 0.7482\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.928349\n",
      "The training accuracy is 0.6458\n",
      "The validation loss is 0.5932\n",
      "The valudation accuracy is 0.7945\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.868345\n",
      "The training accuracy is 0.6626\n",
      "The validation loss is 0.5610\n",
      "The valudation accuracy is 0.8040\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.837573\n",
      "The training accuracy is 0.6752\n",
      "The validation loss is 0.5412\n",
      "The valudation accuracy is 0.8128\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.827167\n",
      "The training accuracy is 0.6824\n",
      "The validation loss is 0.5193\n",
      "The valudation accuracy is 0.8237\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.789505\n",
      "The training accuracy is 0.6909\n",
      "The validation loss is 0.5043\n",
      "The valudation accuracy is 0.8268\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.791786\n",
      "The training accuracy is 0.6966\n",
      "The validation loss is 0.4929\n",
      "The valudation accuracy is 0.8303\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.777576\n",
      "The training accuracy is 0.7011\n",
      "The validation loss is 0.4824\n",
      "The valudation accuracy is 0.8358\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.766417\n",
      "The training accuracy is 0.7051\n",
      "The validation loss is 0.4830\n",
      "The valudation accuracy is 0.8362\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.750374\n",
      "The training accuracy is 0.7090\n",
      "The validation loss is 0.4688\n",
      "The valudation accuracy is 0.8375\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.759533\n",
      "The training accuracy is 0.7114\n",
      "The validation loss is 0.4577\n",
      "The valudation accuracy is 0.8446\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.735841\n",
      "The training accuracy is 0.7145\n",
      "The validation loss is 0.4554\n",
      "The valudation accuracy is 0.8466\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.736656\n",
      "The training accuracy is 0.7169\n",
      "The validation loss is 0.4497\n",
      "The valudation accuracy is 0.8469\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.718883\n",
      "The training accuracy is 0.7194\n",
      "The validation loss is 0.4436\n",
      "The valudation accuracy is 0.8497\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.727108\n",
      "The training accuracy is 0.7217\n",
      "The validation loss is 0.4378\n",
      "The valudation accuracy is 0.8496\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.719732\n",
      "The training accuracy is 0.7235\n",
      "The validation loss is 0.4338\n",
      "The valudation accuracy is 0.8535\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.728059\n",
      "The training accuracy is 0.7251\n",
      "The validation loss is 0.4257\n",
      "The valudation accuracy is 0.8551\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.703057\n",
      "The training accuracy is 0.7269\n",
      "The validation loss is 0.4219\n",
      "The valudation accuracy is 0.8551\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.702910\n",
      "The training accuracy is 0.7285\n",
      "The validation loss is 0.4219\n",
      "The valudation accuracy is 0.8584\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.711057\n",
      "The training accuracy is 0.7299\n",
      "The validation loss is 0.4180\n",
      "The valudation accuracy is 0.8587\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.719129\n",
      "The training accuracy is 0.7309\n",
      "The validation loss is 0.4151\n",
      "The valudation accuracy is 0.8601\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.689847\n",
      "The training accuracy is 0.7324\n",
      "The validation loss is 0.4087\n",
      "The valudation accuracy is 0.8613\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.684098\n",
      "The training accuracy is 0.7339\n",
      "The validation loss is 0.4099\n",
      "The valudation accuracy is 0.8647\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.701060\n",
      "The training accuracy is 0.7349\n",
      "The validation loss is 0.4106\n",
      "The valudation accuracy is 0.8635\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.687254\n",
      "The training accuracy is 0.7360\n",
      "The validation loss is 0.4078\n",
      "The valudation accuracy is 0.8623\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.681341\n",
      "The training accuracy is 0.7370\n",
      "The validation loss is 0.3991\n",
      "The valudation accuracy is 0.8645\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.690527\n",
      "The training accuracy is 0.7380\n",
      "The validation loss is 0.4000\n",
      "The valudation accuracy is 0.8653\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.678867\n",
      "The training accuracy is 0.7390\n",
      "The validation loss is 0.4023\n",
      "The valudation accuracy is 0.8645\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.684652\n",
      "The training accuracy is 0.7400\n",
      "The validation loss is 0.4023\n",
      "The valudation accuracy is 0.8675\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.675826\n",
      "The training accuracy is 0.7410\n",
      "The validation loss is 0.3903\n",
      "The valudation accuracy is 0.8692\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.659290\n",
      "The training accuracy is 0.7420\n",
      "The validation loss is 0.3965\n",
      "The valudation accuracy is 0.8703\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.669802\n",
      "The training accuracy is 0.7430\n",
      "The validation loss is 0.3903\n",
      "The valudation accuracy is 0.8702\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.666128\n",
      "The training accuracy is 0.7438\n",
      "The validation loss is 0.3838\n",
      "The valudation accuracy is 0.8693\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.671832\n",
      "The training accuracy is 0.7446\n",
      "The validation loss is 0.3864\n",
      "The valudation accuracy is 0.8717\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.650927\n",
      "The training accuracy is 0.7455\n",
      "The validation loss is 0.3828\n",
      "The valudation accuracy is 0.8704\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.661499\n",
      "The training accuracy is 0.7463\n",
      "The validation loss is 0.3835\n",
      "The valudation accuracy is 0.8718\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.662116\n",
      "The training accuracy is 0.7469\n",
      "The validation loss is 0.3810\n",
      "The valudation accuracy is 0.8731\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.647222\n",
      "The training accuracy is 0.7477\n",
      "The validation loss is 0.3778\n",
      "The valudation accuracy is 0.8736\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/2000451365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/3142515270.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, epochs, print_every, criterion, optimizer, device, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# maybe accumulate loss for steps?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# accuracy 80%\n",
    "optimizer = optim.AdamW(myCNN_ex1.parameters(),lr=1e-6)\n",
    "train(myCNN_ex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b36cb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529f1473c4bb4e168309754f82694396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 0.779802\n",
      "The training accuracy is 0.7299\n",
      "The validation loss is 0.4567\n",
      "The valudation accuracy is 0.8406\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.741424\n",
      "The training accuracy is 0.7364\n",
      "The validation loss is 0.4381\n",
      "The valudation accuracy is 0.8485\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.714671\n",
      "The training accuracy is 0.7423\n",
      "The validation loss is 0.4339\n",
      "The valudation accuracy is 0.8501\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.709604\n",
      "The training accuracy is 0.7449\n",
      "The validation loss is 0.4248\n",
      "The valudation accuracy is 0.8514\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.712366\n",
      "The training accuracy is 0.7464\n",
      "The validation loss is 0.4237\n",
      "The valudation accuracy is 0.8521\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.722462\n",
      "The training accuracy is 0.7465\n",
      "The validation loss is 0.4260\n",
      "The valudation accuracy is 0.8532\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.708034\n",
      "The training accuracy is 0.7480\n",
      "The validation loss is 0.4217\n",
      "The valudation accuracy is 0.8538\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.697910\n",
      "The training accuracy is 0.7495\n",
      "The validation loss is 0.4196\n",
      "The valudation accuracy is 0.8554\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.694493\n",
      "The training accuracy is 0.7501\n",
      "The validation loss is 0.4148\n",
      "The valudation accuracy is 0.8556\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.698795\n",
      "The training accuracy is 0.7510\n",
      "The validation loss is 0.4139\n",
      "The valudation accuracy is 0.8565\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.698989\n",
      "The training accuracy is 0.7518\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/3833796446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/3142515270.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, epochs, print_every, criterion, optimizer, device, name)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The training accuracy is {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mrunning_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0maccuracy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[1;31m#print(\"training accuracy: \\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m#accuracy_test(model,trainloader)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/3142515270.py\u001b[0m in \u001b[0;36maccuracy_test\u001b[1;34m(model, dataloader, epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46644/3652907856.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \"\"\"\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    417\u001b[0m             )\n\u001b[0;32m    418\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_long\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_short\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2006\u001b[0m                 )\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_ex1.parameters(),lr=5e-8)\n",
    "train(myCNN_ex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b71b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd912c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024672fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_ex1.load_state_dict(torch.load(\"Weights/myCNN_experiment1_1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db39cdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23375a3910a541ccb17f32214599bb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.104228\n",
      "The training accuracy is 0.6386\n",
      "The validation loss is 0.6638\n",
      "The valudation accuracy is 0.7783\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.856919\n",
      "The training accuracy is 0.6704\n",
      "The validation loss is 0.5274\n",
      "The valudation accuracy is 0.8205\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.817035\n",
      "The training accuracy is 0.6850\n",
      "The validation loss is 0.5149\n",
      "The valudation accuracy is 0.8265\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.781390\n",
      "The training accuracy is 0.6960\n",
      "The validation loss is 0.4758\n",
      "The valudation accuracy is 0.8374\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.748342\n",
      "The training accuracy is 0.7052\n",
      "The validation loss is 0.4655\n",
      "The valudation accuracy is 0.8430\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.755997\n",
      "The training accuracy is 0.7107\n",
      "The validation loss is 0.4541\n",
      "The valudation accuracy is 0.8467\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.731971\n",
      "The training accuracy is 0.7159\n",
      "The validation loss is 0.4382\n",
      "The valudation accuracy is 0.8524\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.718945\n",
      "The training accuracy is 0.7207\n",
      "The validation loss is 0.4369\n",
      "The valudation accuracy is 0.8538\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.710777\n",
      "The training accuracy is 0.7247\n",
      "The validation loss is 0.4241\n",
      "The valudation accuracy is 0.8554\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.709072\n",
      "The training accuracy is 0.7276\n",
      "The validation loss is 0.4207\n",
      "The valudation accuracy is 0.8558\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.702528\n",
      "The training accuracy is 0.7302\n",
      "The validation loss is 0.4082\n",
      "The valudation accuracy is 0.8624\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.690244\n",
      "The training accuracy is 0.7331\n",
      "The validation loss is 0.4106\n",
      "The valudation accuracy is 0.8622\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.694601\n",
      "The training accuracy is 0.7351\n",
      "The validation loss is 0.4055\n",
      "The valudation accuracy is 0.8630\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.688869\n",
      "The training accuracy is 0.7369\n",
      "The validation loss is 0.4012\n",
      "The valudation accuracy is 0.8676\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.666909\n",
      "The training accuracy is 0.7391\n",
      "The validation loss is 0.3919\n",
      "The valudation accuracy is 0.8671\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.671940\n",
      "The training accuracy is 0.7407\n",
      "The validation loss is 0.3915\n",
      "The valudation accuracy is 0.8644\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.656363\n",
      "The training accuracy is 0.7427\n",
      "The validation loss is 0.3855\n",
      "The valudation accuracy is 0.8689\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.661185\n",
      "The training accuracy is 0.7444\n",
      "The validation loss is 0.3822\n",
      "The valudation accuracy is 0.8702\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.663763\n",
      "The training accuracy is 0.7460\n",
      "The validation loss is 0.3856\n",
      "The valudation accuracy is 0.8719\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.653791\n",
      "The training accuracy is 0.7473\n",
      "The validation loss is 0.3764\n",
      "The valudation accuracy is 0.8742\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.633337\n",
      "The training accuracy is 0.7489\n",
      "The validation loss is 0.3749\n",
      "The valudation accuracy is 0.8739\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.658514\n",
      "The training accuracy is 0.7499\n",
      "The validation loss is 0.3735\n",
      "The valudation accuracy is 0.8747\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.645118\n",
      "The training accuracy is 0.7511\n",
      "The validation loss is 0.3730\n",
      "The valudation accuracy is 0.8754\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.636419\n",
      "The training accuracy is 0.7525\n",
      "The validation loss is 0.3692\n",
      "The valudation accuracy is 0.8765\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.627946\n",
      "The training accuracy is 0.7539\n",
      "The validation loss is 0.3647\n",
      "The valudation accuracy is 0.8785\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.633301\n",
      "The training accuracy is 0.7550\n",
      "The validation loss is 0.3594\n",
      "The valudation accuracy is 0.8803\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.620544\n",
      "The training accuracy is 0.7562\n",
      "The validation loss is 0.3653\n",
      "The valudation accuracy is 0.8809\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.629147\n",
      "The training accuracy is 0.7572\n",
      "The validation loss is 0.3649\n",
      "The valudation accuracy is 0.8791\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.624888\n",
      "The training accuracy is 0.7581\n",
      "The validation loss is 0.3524\n",
      "The valudation accuracy is 0.8817\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.626943\n",
      "The training accuracy is 0.7591\n",
      "The validation loss is 0.3539\n",
      "The valudation accuracy is 0.8812\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.615389\n",
      "The training accuracy is 0.7601\n",
      "The validation loss is 0.3527\n",
      "The valudation accuracy is 0.8789\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.610366\n",
      "The training accuracy is 0.7611\n",
      "The validation loss is 0.3527\n",
      "The valudation accuracy is 0.8813\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.633314\n",
      "The training accuracy is 0.7616\n",
      "The validation loss is 0.3518\n",
      "The valudation accuracy is 0.8814\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.605527\n",
      "The training accuracy is 0.7625\n",
      "The validation loss is 0.3457\n",
      "The valudation accuracy is 0.8823\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.613115\n",
      "The training accuracy is 0.7633\n",
      "The validation loss is 0.3381\n",
      "The valudation accuracy is 0.8851\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.626197\n",
      "The training accuracy is 0.7639\n",
      "The validation loss is 0.3456\n",
      "The valudation accuracy is 0.8845\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.600451\n",
      "The training accuracy is 0.7647\n",
      "The validation loss is 0.3458\n",
      "The valudation accuracy is 0.8850\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.616995\n",
      "The training accuracy is 0.7654\n",
      "The validation loss is 0.3377\n",
      "The valudation accuracy is 0.8853\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.593099\n",
      "The training accuracy is 0.7661\n",
      "The validation loss is 0.3391\n",
      "The valudation accuracy is 0.8860\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.598015\n",
      "The training accuracy is 0.7669\n",
      "The validation loss is 0.3445\n",
      "The valudation accuracy is 0.8817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_ex1.parameters(),lr=2e-6)\n",
    "train(myCNN_ex1,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4098d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ec9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0662bf2",
   "metadata": {},
   "source": [
    "# experiment #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf7afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental model: conv/pool + conv/conv/pool + conv/conv/pool + conv/conv/conv/pool + 1 dense\n",
    "# add batchnorm after each conv layer for every conv layer\n",
    "# double the filters \n",
    "# add dropouts\n",
    "class CNN_ex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ex,self).__init__()\n",
    "        self.convlayers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(512,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "        )\n",
    "        #self.finalconv = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
    "        self.finaldense = nn.Sequential(\n",
    "            nn.Linear(16384,10,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "           # nn.Linear(2048,1024,True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(1024,10,True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convlayers(x)\n",
    "        #x = self.finalconv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.finaldense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43824136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_ex(\n",
       "  (convlayers): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout2d(p=0.3, inplace=False)\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Dropout2d(p=0.3, inplace=False)\n",
       "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Dropout2d(p=0.3, inplace=False)\n",
       "    (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (31): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (finaldense): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN_ex2 = CNN_ex()\n",
    "myCNN_ex2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac5d0929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbaeb9bde624bd29295b5c472d013a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 2.078925\n",
      "The training accuracy is 0.2665\n",
      "The validation loss is 1.7636\n",
      "The valudation accuracy is 0.3595\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.729875\n",
      "The training accuracy is 0.3229\n",
      "The validation loss is 1.5061\n",
      "The valudation accuracy is 0.4710\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.634707\n",
      "The training accuracy is 0.3538\n",
      "The validation loss is 1.4076\n",
      "The valudation accuracy is 0.5090\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.584316\n",
      "The training accuracy is 0.3753\n",
      "The validation loss is 1.3529\n",
      "The valudation accuracy is 0.5217\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.517932\n",
      "The training accuracy is 0.3937\n",
      "The validation loss is 1.2861\n",
      "The valudation accuracy is 0.5424\n",
      "\n",
      "EPOCHS : 2/12 Loss : 1.480323\n",
      "The training accuracy is 0.4077\n",
      "The validation loss is 1.2729\n",
      "The valudation accuracy is 0.5516\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.429741\n",
      "The training accuracy is 0.4196\n",
      "The validation loss is 1.1624\n",
      "The valudation accuracy is 0.6023\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.387591\n",
      "The training accuracy is 0.4310\n",
      "The validation loss is 1.1758\n",
      "The valudation accuracy is 0.5863\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.366433\n",
      "The training accuracy is 0.4407\n",
      "The validation loss is 1.1292\n",
      "The valudation accuracy is 0.5994\n",
      "\n",
      "EPOCHS : 3/12 Loss : 1.339576\n",
      "The training accuracy is 0.4498\n",
      "The validation loss is 1.0505\n",
      "The valudation accuracy is 0.6378\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.309931\n",
      "The training accuracy is 0.4581\n",
      "The validation loss is 1.0153\n",
      "The valudation accuracy is 0.6584\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.267263\n",
      "The training accuracy is 0.4665\n",
      "The validation loss is 1.0047\n",
      "The valudation accuracy is 0.6570\n",
      "\n",
      "EPOCHS : 4/12 Loss : 1.229395\n",
      "The training accuracy is 0.4745\n",
      "The validation loss is 0.9753\n",
      "The valudation accuracy is 0.6592\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.191562\n",
      "The training accuracy is 0.4820\n",
      "The validation loss is 0.8911\n",
      "The valudation accuracy is 0.6939\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.183473\n",
      "The training accuracy is 0.4889\n",
      "The validation loss is 0.8537\n",
      "The valudation accuracy is 0.7023\n",
      "\n",
      "EPOCHS : 5/12 Loss : 1.129735\n",
      "The training accuracy is 0.4960\n",
      "The validation loss is 0.9072\n",
      "The valudation accuracy is 0.6880\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.138188\n",
      "The training accuracy is 0.5022\n",
      "The validation loss is 0.8306\n",
      "The valudation accuracy is 0.7155\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.085446\n",
      "The training accuracy is 0.5088\n",
      "The validation loss is 0.7781\n",
      "The valudation accuracy is 0.7337\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.054091\n",
      "The training accuracy is 0.5154\n",
      "The validation loss is 0.7520\n",
      "The valudation accuracy is 0.7391\n",
      "\n",
      "EPOCHS : 6/12 Loss : 1.022055\n",
      "The training accuracy is 0.5217\n",
      "The validation loss is 0.6939\n",
      "The valudation accuracy is 0.7566\n",
      "\n",
      "EPOCHS : 7/12 Loss : 1.009157\n",
      "The training accuracy is 0.5277\n",
      "The validation loss is 0.7571\n",
      "The valudation accuracy is 0.7445\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.990065\n",
      "The training accuracy is 0.5334\n",
      "The validation loss is 0.6873\n",
      "The valudation accuracy is 0.7653\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.955076\n",
      "The training accuracy is 0.5393\n",
      "The validation loss is 0.6809\n",
      "The valudation accuracy is 0.7644\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.955103\n",
      "The training accuracy is 0.5446\n",
      "The validation loss is 0.6889\n",
      "The valudation accuracy is 0.7679\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.911002\n",
      "The training accuracy is 0.5500\n",
      "The validation loss is 0.6508\n",
      "The valudation accuracy is 0.7692\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.880887\n",
      "The training accuracy is 0.5555\n",
      "The validation loss is 0.6449\n",
      "The valudation accuracy is 0.7721\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.884090\n",
      "The training accuracy is 0.5605\n",
      "The validation loss is 0.6007\n",
      "The valudation accuracy is 0.7963\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.846380\n",
      "The training accuracy is 0.5657\n",
      "The validation loss is 0.5512\n",
      "The valudation accuracy is 0.8106\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.825260\n",
      "The training accuracy is 0.5706\n",
      "The validation loss is 0.5310\n",
      "The valudation accuracy is 0.8186\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.818260\n",
      "The training accuracy is 0.5754\n",
      "The validation loss is 0.5408\n",
      "The valudation accuracy is 0.8143\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.782076\n",
      "The training accuracy is 0.5803\n",
      "The validation loss is 0.5192\n",
      "The valudation accuracy is 0.8206\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.782548\n",
      "The training accuracy is 0.5850\n",
      "The validation loss is 0.4584\n",
      "The valudation accuracy is 0.8413\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.767189\n",
      "The training accuracy is 0.5895\n",
      "The validation loss is 0.4680\n",
      "The valudation accuracy is 0.8363\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.767685\n",
      "The training accuracy is 0.5936\n",
      "The validation loss is 0.4326\n",
      "The valudation accuracy is 0.8494\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.743801\n",
      "The training accuracy is 0.5978\n",
      "The validation loss is 0.4460\n",
      "The valudation accuracy is 0.8473\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.719747\n",
      "The training accuracy is 0.6019\n",
      "The validation loss is 0.4379\n",
      "The valudation accuracy is 0.8483\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.711956\n",
      "The training accuracy is 0.6060\n",
      "The validation loss is 0.4313\n",
      "The valudation accuracy is 0.8475\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.719765\n",
      "The training accuracy is 0.6098\n",
      "The validation loss is 0.4020\n",
      "The valudation accuracy is 0.8638\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.693014\n",
      "The training accuracy is 0.6135\n",
      "The validation loss is 0.4608\n",
      "The valudation accuracy is 0.8332\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.663314\n",
      "The training accuracy is 0.6174\n",
      "The validation loss is 0.4058\n",
      "The valudation accuracy is 0.8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_ex2.parameters(),lr=5e-5)\n",
    "train(myCNN_ex2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13769c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e45f662bdd4d92ad75c54545ee3ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.900985\n",
      "The training accuracy is 0.4714\n",
      "The validation loss is 1.1822\n",
      "The valudation accuracy is 0.6336\n",
      "\n",
      "EPOCHS : 1/12 Loss : 1.081805\n",
      "The training accuracy is 0.5588\n",
      "The validation loss is 0.6656\n",
      "The valudation accuracy is 0.7759\n",
      "\n",
      "EPOCHS : 1/12 Loss : 0.910941\n",
      "The training accuracy is 0.6018\n",
      "The validation loss is 0.5963\n",
      "The valudation accuracy is 0.8023\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.866691\n",
      "The training accuracy is 0.6276\n",
      "The validation loss is 0.5613\n",
      "The valudation accuracy is 0.8148\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.846135\n",
      "The training accuracy is 0.6433\n",
      "The validation loss is 0.5402\n",
      "The valudation accuracy is 0.8218\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.815574\n",
      "The training accuracy is 0.6562\n",
      "The validation loss is 0.5209\n",
      "The valudation accuracy is 0.8282\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.804127\n",
      "The training accuracy is 0.6659\n",
      "The validation loss is 0.5037\n",
      "The valudation accuracy is 0.8334\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.799591\n",
      "The training accuracy is 0.6735\n",
      "The validation loss is 0.4948\n",
      "The valudation accuracy is 0.8351\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.778306\n",
      "The training accuracy is 0.6802\n",
      "The validation loss is 0.4850\n",
      "The valudation accuracy is 0.8382\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.779534\n",
      "The training accuracy is 0.6852\n",
      "The validation loss is 0.4857\n",
      "The valudation accuracy is 0.8396\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.786226\n",
      "The training accuracy is 0.6896\n",
      "The validation loss is 0.4783\n",
      "The valudation accuracy is 0.8406\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.773330\n",
      "The training accuracy is 0.6934\n",
      "The validation loss is 0.4685\n",
      "The valudation accuracy is 0.8447\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.752913\n",
      "The training accuracy is 0.6972\n",
      "The validation loss is 0.4590\n",
      "The valudation accuracy is 0.8465\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.754742\n",
      "The training accuracy is 0.7001\n",
      "The validation loss is 0.4579\n",
      "The valudation accuracy is 0.8496\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.752109\n",
      "The training accuracy is 0.7027\n",
      "The validation loss is 0.4558\n",
      "The valudation accuracy is 0.8496\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.732638\n",
      "The training accuracy is 0.7058\n",
      "The validation loss is 0.4510\n",
      "The valudation accuracy is 0.8505\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.719870\n",
      "The training accuracy is 0.7087\n",
      "The validation loss is 0.4460\n",
      "The valudation accuracy is 0.8502\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.722331\n",
      "The training accuracy is 0.7111\n",
      "The validation loss is 0.4414\n",
      "The valudation accuracy is 0.8527\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.729171\n",
      "The training accuracy is 0.7132\n",
      "The validation loss is 0.4437\n",
      "The valudation accuracy is 0.8533\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.721007\n",
      "The training accuracy is 0.7152\n",
      "The validation loss is 0.4392\n",
      "The valudation accuracy is 0.8556\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.716122\n",
      "The training accuracy is 0.7171\n",
      "The validation loss is 0.4320\n",
      "The valudation accuracy is 0.8555\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.701995\n",
      "The training accuracy is 0.7192\n",
      "The validation loss is 0.4310\n",
      "The valudation accuracy is 0.8577\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.709673\n",
      "The training accuracy is 0.7208\n",
      "The validation loss is 0.4303\n",
      "The valudation accuracy is 0.8581\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.707047\n",
      "The training accuracy is 0.7223\n",
      "The validation loss is 0.4261\n",
      "The valudation accuracy is 0.8599\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.703104\n",
      "The training accuracy is 0.7239\n",
      "The validation loss is 0.4200\n",
      "The valudation accuracy is 0.8585\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.700730\n",
      "The training accuracy is 0.7253\n",
      "The validation loss is 0.4237\n",
      "The valudation accuracy is 0.8604\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.701590\n",
      "The training accuracy is 0.7267\n",
      "The validation loss is 0.4172\n",
      "The valudation accuracy is 0.8608\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.701520\n",
      "The training accuracy is 0.7279\n",
      "The validation loss is 0.4154\n",
      "The valudation accuracy is 0.8630\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.692578\n",
      "The training accuracy is 0.7289\n",
      "The validation loss is 0.4226\n",
      "The valudation accuracy is 0.8622\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.692496\n",
      "The training accuracy is 0.7300\n",
      "The validation loss is 0.4129\n",
      "The valudation accuracy is 0.8645\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.679609\n",
      "The training accuracy is 0.7313\n",
      "The validation loss is 0.4105\n",
      "The valudation accuracy is 0.8642\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.696895\n",
      "The training accuracy is 0.7322\n",
      "The validation loss is 0.4085\n",
      "The valudation accuracy is 0.8632\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.694112\n",
      "The training accuracy is 0.7332\n",
      "The validation loss is 0.4054\n",
      "The valudation accuracy is 0.8649\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.693731\n",
      "The training accuracy is 0.7341\n",
      "The validation loss is 0.4023\n",
      "The valudation accuracy is 0.8650\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.672769\n",
      "The training accuracy is 0.7351\n",
      "The validation loss is 0.4017\n",
      "The valudation accuracy is 0.8657\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.670319\n",
      "The training accuracy is 0.7360\n",
      "The validation loss is 0.3994\n",
      "The valudation accuracy is 0.8661\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.672543\n",
      "The training accuracy is 0.7369\n",
      "The validation loss is 0.4007\n",
      "The valudation accuracy is 0.8660\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.668445\n",
      "The training accuracy is 0.7379\n",
      "The validation loss is 0.3935\n",
      "The valudation accuracy is 0.8674\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.674240\n",
      "The training accuracy is 0.7387\n",
      "The validation loss is 0.3963\n",
      "The valudation accuracy is 0.8671\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.671082\n",
      "The training accuracy is 0.7395\n",
      "The validation loss is 0.3996\n",
      "The valudation accuracy is 0.8670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy 78.8%\n",
    "optimizer = optim.AdamW(myCNN_ex2.parameters(),lr=1e-6)\n",
    "train(myCNN_ex2,train_loader, 12,40 ,criterion,optimizer,'cuda',\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be25e906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e133e556a5dd457f910de96f02082139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.505633\n",
      "The training accuracy is 0.5377\n",
      "The validation loss is 0.7293\n",
      "The valudation accuracy is 0.7572\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.776649\n",
      "The training accuracy is 0.6358\n",
      "The validation loss is 0.4409\n",
      "The valudation accuracy is 0.8535\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.721136\n",
      "The training accuracy is 0.6745\n",
      "The validation loss is 0.4236\n",
      "The valudation accuracy is 0.8595\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.703796\n",
      "The training accuracy is 0.6958\n",
      "The validation loss is 0.4160\n",
      "The valudation accuracy is 0.8624\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.700845\n",
      "The training accuracy is 0.7086\n",
      "The validation loss is 0.4096\n",
      "The valudation accuracy is 0.8632\n",
      "\n",
      "EPOCHS : 4/12 Loss : 0.695472\n",
      "The training accuracy is 0.7175\n",
      "The validation loss is 0.4099\n",
      "The valudation accuracy is 0.8617\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.677517\n",
      "The training accuracy is 0.7248\n",
      "The validation loss is 0.4051\n",
      "The valudation accuracy is 0.8657\n",
      "\n",
      "EPOCHS : 5/12 Loss : 0.674734\n",
      "The training accuracy is 0.7303\n",
      "The validation loss is 0.3992\n",
      "The valudation accuracy is 0.8670\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.683325\n",
      "The training accuracy is 0.7344\n",
      "The validation loss is 0.3983\n",
      "The valudation accuracy is 0.8674\n",
      "\n",
      "EPOCHS : 6/12 Loss : 0.683245\n",
      "The training accuracy is 0.7375\n",
      "The validation loss is 0.3992\n",
      "The valudation accuracy is 0.8692\n",
      "\n",
      "EPOCHS : 7/12 Loss : 0.661174\n",
      "The training accuracy is 0.7411\n",
      "The validation loss is 0.3934\n",
      "The valudation accuracy is 0.8698\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.676893\n",
      "The training accuracy is 0.7433\n",
      "The validation loss is 0.3965\n",
      "The valudation accuracy is 0.8694\n",
      "\n",
      "EPOCHS : 8/12 Loss : 0.658183\n",
      "The training accuracy is 0.7458\n",
      "The validation loss is 0.3898\n",
      "The valudation accuracy is 0.8694\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.658911\n",
      "The training accuracy is 0.7479\n",
      "The validation loss is 0.3891\n",
      "The valudation accuracy is 0.8711\n",
      "\n",
      "EPOCHS : 9/12 Loss : 0.667164\n",
      "The training accuracy is 0.7494\n",
      "The validation loss is 0.3878\n",
      "The valudation accuracy is 0.8702\n",
      "\n",
      "EPOCHS : 10/12 Loss : 0.665327\n",
      "The training accuracy is 0.7508\n",
      "The validation loss is 0.3858\n",
      "The valudation accuracy is 0.8726\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.664267\n",
      "The training accuracy is 0.7519\n",
      "The validation loss is 0.3841\n",
      "The valudation accuracy is 0.8730\n",
      "\n",
      "EPOCHS : 11/12 Loss : 0.651829\n",
      "The training accuracy is 0.7534\n",
      "The validation loss is 0.3790\n",
      "The valudation accuracy is 0.8718\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.656281\n",
      "The training accuracy is 0.7547\n",
      "The validation loss is 0.3808\n",
      "The valudation accuracy is 0.8731\n",
      "\n",
      "EPOCHS : 12/12 Loss : 0.656384\n",
      "The training accuracy is 0.7556\n",
      "The validation loss is 0.3771\n",
      "The valudation accuracy is 0.8729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 79%\n",
    "optimizer = optim.AdamW(myCNN_ex2.parameters(),lr=5e-7)\n",
    "train(myCNN_ex2,train_loader,12,20 ,criterion,optimizer,'cuda',\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9649aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b932f286bbd64e74aaa1807faa177122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 1/12 Loss : 1.548194\n",
      "The training accuracy is 0.5214\n",
      "The validation loss is 0.6360\n",
      "The valudation accuracy is 0.7868\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.872709\n",
      "The training accuracy is 0.6109\n",
      "The validation loss is 0.4552\n",
      "The valudation accuracy is 0.8430\n",
      "\n",
      "EPOCHS : 2/12 Loss : 0.758733\n",
      "The training accuracy is 0.6529\n",
      "The validation loss is 0.4353\n",
      "The valudation accuracy is 0.8509\n",
      "\n",
      "EPOCHS : 3/12 Loss : 0.744330\n",
      "The training accuracy is 0.6759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45580/2793507604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyCNN_ex2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45580/67191372.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, epochs, print_every, criterion, optimizer, device, name)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The training accuracy is {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mrunning_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0maccuracy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[1;31m#print(\"training accuracy: \\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m#accuracy_test(model,trainloader)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45580/67191372.py\u001b[0m in \u001b[0;36maccuracy_test\u001b[1;34m(model, dataloader, epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(myCNN_ex2.parameters(),lr=5e-8)\n",
    "train(myCNN_ex2,train_loader,12,20 ,criterion,optimizer,'cuda',\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae46e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b45d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068024f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671b69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4543ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e5b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248e16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f81ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116f035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f468ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96349dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a7672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc11f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d509101b",
   "metadata": {},
   "source": [
    "# generate test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6353762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_result(model,dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.cuda() \n",
    "    model.eval()\n",
    "    result = []\n",
    "    with torch.no_grad(): \n",
    "        for data in dataloader:\n",
    "           \n",
    "            images,labels = data\n",
    "            images,labels = images.to('cuda'),labels.to('cuda')\n",
    "            \n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            predicted = predicted.to(\"cpu\").flatten().tolist()\n",
    "            result+=predicted\n",
    "            \n",
    "            # total += labels.size(0)\n",
    "            \n",
    "            # correct += (predicted == labels).sum().item()\n",
    "      \n",
    "    ids = list(range(len(result)))\n",
    "\n",
    "    df = pd.DataFrame(data={\"id\":ids,\"label\":result})\n",
    "    return df\n",
    "\n",
    "test_data = pd.read_csv(\"sample_submission.csv\")\n",
    "test_data = CustomDataset(test_data,\"./test/\",transform=data_transformers[\"val\"])\n",
    "test_loader = DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8733fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = gen_test_result(myCNN_ex1,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b52f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission8.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f266c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc5562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
