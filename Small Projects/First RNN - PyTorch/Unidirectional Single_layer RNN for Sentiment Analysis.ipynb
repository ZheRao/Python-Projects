{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76e5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cf054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20d6b435c70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device(\"cuda\")\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b13bf4",
   "metadata": {},
   "source": [
    "# getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb557a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 6661.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 6567.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:  25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read sentiments and reviews data from the text files\n",
    "review_list = []\n",
    "label_list = []\n",
    "for label in [\"pos\",\"neg\"]:\n",
    "    for fname in tqdm(os.listdir(f\"W://Study Material/Jupyter Notebook/Datasets/aclImdb_v1/aclImdb/train/{label}/\")):\n",
    "        if \"txt\" not in fname:\n",
    "            continue\n",
    "        with open(os.path.join(f\"W://Study Material/Jupyter Notebook/Datasets/aclImdb_v1/aclImdb/train/{label}/\",\n",
    "                              fname), encoding=\"utf8\") as f:\n",
    "            review_list += [f.read()]\n",
    "            label_list += [label]\n",
    "print(\"Number of reviews: \", len(review_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e797bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21d48a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd30dc2",
   "metadata": {},
   "source": [
    "# pre-processing review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c2c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all to lower cases\n",
    "review_list = [review.lower() for review in review_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c30566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy. it ran at the same time as some other programs about school life, such as \"teachers\". my 35 years in the teaching profession lead me to believe that bromwell high\\'s satire is much closer to reality than is \"teachers\". the scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools i knew and their students. when i saw the episode in which a student repeatedly tried to burn down the school, i immediately recalled ......... at .......... high. a classic line: inspector: i\\'m here to sack one of your teachers. student: welcome to bromwell high. i expect that many adults of my age think that bromwell high is far fetched. what a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4397386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 25000/25000 [00:01<00:00, 12559.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuations\n",
    "review_list = [\"\".join([letter for letter in review if letter not in punctuation]) \n",
    "              for review in tqdm(review_list)]\n",
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1fecacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 762/762 [00:00<00:00, 761510.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for review in tqdm(review_list[0]):\n",
    "    #print(review)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f969b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31824241\n",
      "bromwell high is a c\n"
     ]
    }
   ],
   "source": [
    "# accumulate all review texts together\n",
    "reviews_blob = \" \".join(review_list)\n",
    "print(len(reviews_blob))\n",
    "print(reviews_blob[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253f8fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate list of all words of all reviews\n",
    "review_words = reviews_blob.split()\n",
    "review_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e26b6ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5821814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774d9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1903 106855\n"
     ]
    }
   ],
   "source": [
    "# get the word counts in a dictionary object called count_words\n",
    "count_words = Counter(review_words)\n",
    "print(count_words[\"high\"],count_words[\"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b242dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
     ]
    }
   ],
   "source": [
    "# sort words as per counts (decreasing order)\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "print(sorted_review_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c5804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28dd8e95",
   "metadata": {},
   "source": [
    "# convert words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3eeaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
     ]
    }
   ],
   "source": [
    "# create word to integer (token) distionary in order to encode text as numbers\n",
    "vocab_to_token = {word:idx+1 for idx, (word,count) in enumerate(sorted_review_words)}\n",
    "print(list(vocab_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb6cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "388326dd",
   "metadata": {},
   "source": [
    "# translate dataset into a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3c322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22572, 321, 6, 3, 1077, 219, 8, 2082, 30, 1, 166, 61, 14, 46, 80, 5581, 42, 399, 118, 135, 14, 4883, 55, 4980, 147, 7, 1, 4941, 6023, 479, 69, 5, 255, 11, 22572, 17217, 1970, 6, 72, 2356, 5, 638, 70, 6, 4883, 1, 26241, 5, 2031, 10833, 1, 5884, 1421, 36, 68, 67, 204, 140, 64, 1215, 4883, 21183, 1, 43770, 4, 1, 218, 902, 31, 2922, 69, 4, 1, 4706, 9, 671, 2, 64, 1421, 50, 9, 207, 1, 382, 7, 59, 3, 1473, 3614, 774, 5, 3561, 186, 1, 399, 9, 1191, 14623, 30, 321, 3, 349, 362, 2960, 141, 131, 5, 9055, 28, 4, 122, 4883, 1473, 2410, 5, 22572, 321, 9, 515, 11, 105, 1462, 4, 55, 580, 102, 11, 22572, 321, 6, 233, 8881, 48, 3, 2285, 11, 8, 206]\n"
     ]
    }
   ],
   "source": [
    "reviews_tokenized = []\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token)\n",
    "print(reviews_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc43dbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']\n",
      "22572\n",
      "321\n",
      "6\n",
      "3\n",
      "1077\n",
      "219\n",
      "8\n",
      "2082\n",
      "30\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "string = review_list[0].split()[:10]\n",
    "print(string)\n",
    "\n",
    "for i in np.arange(10):\n",
    "    print(vocab_to_token[string[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e9007f",
   "metadata": {},
   "source": [
    "# encode targets as pos - 1 and neg - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "950f6dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "# get reviews length\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "print(len(reviews_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc5b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform encoding\n",
    "encoded_label_list = [1 if label == \"pos\" else 0 for label in label_list]\n",
    "\n",
    "# get rid of empty reviews\n",
    "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l>0]\n",
    "encoded_label_list = np.array([encoded_label_list[i] for i,l in enumerate(reviews_len) if l > 0],\n",
    "                             dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b51920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "# check number of reviews\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "print(len(reviews_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c40e1c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2469\n"
     ]
    }
   ],
   "source": [
    "print(max(reviews_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b54af",
   "metadata": {},
   "source": [
    "# normalize the length of reviews to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78dcf546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.7708e+04, 5.3030e+03, 1.3860e+03, 5.3200e+02, 5.6000e+01,\n",
       "        8.0000e+00, 4.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([  10. ,  255.9,  501.8,  747.7,  993.6, 1239.5, 1485.4, 1731.3,\n",
       "        1977.2, 2223.1, 2469. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(reviews_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de64daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the length to 512 if it's short, truncate length to 512 if it's long\n",
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized),sequence_length),dtype=int)\n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        if review_len <= sequence_length:\n",
    "            # if the length is too small, add 0's in the beginning of the review vector\n",
    "            #  to make the size 512\n",
    "            zeros = list(np.zeros(sequence_length-review_len))\n",
    "            new_sequence = zeros+review\n",
    "        else:\n",
    "            new_sequence = review[0:sequence_length]\n",
    "        padded_reviews[idx,:] = np.array(new_sequence)\n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length=512\n",
    "padded_reviews = pad_sequence(reviews_tokenized,sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c030ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ecb00a",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d7332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "#  modify the code so that it takes the first 0.125 and last 0.125 as validation\n",
    "#  so that the validation set is not all 0 labeled\n",
    "idx1 = 0.125\n",
    "idx2 = 0.875\n",
    "train_X = padded_reviews[int(idx1*len(padded_reviews)):int(idx2*len(padded_reviews))]\n",
    "train_y = encoded_label_list[int(idx1*len(padded_reviews)):int(idx2*len(padded_reviews))]\n",
    "validation_X = np.concatenate([padded_reviews[:int(idx1*len(padded_reviews))], padded_reviews[int(idx2*len(padded_reviews)):]])\n",
    "validation_y = np.concatenate([encoded_label_list[:int(idx1*len(padded_reviews))], encoded_label_list[int(idx2*len(padded_reviews)):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a86794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0ae558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before modification\n",
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d9b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after modification\n",
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b688d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18750, 512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7622d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6250, 512)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d85e21",
   "metadata": {},
   "source": [
    "# generate dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb16a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate datasets\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device),\n",
    "                             torch.from_numpy(train_y).to(device))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device),\n",
    "                                  torch.from_numpy(validation_y).to(device))\n",
    "batch_size=32\n",
    "\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "135af3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input size:  torch.Size([32, 512])\n",
      "Example Input:\n",
      " tensor([[    9,  1031,  2171,  ...,   464,    76,    87],\n",
      "        [    0,     0,     0,  ...,     4,    55,  1933],\n",
      "        [    0,     0,     0,  ...,    31,  2207,   472],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    14,  7885, 90440],\n",
      "        [    0,     0,     0,  ...,   483,  5594,    12],\n",
      "        [   10,  7154,    19,  ...,  2685,   379,     1]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\n",
      "Example Output size:  torch.Size([32])\n",
      "Example Output:\n",
      " tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# print some data\n",
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = train_data_iter.next()\n",
    "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
    "print('Example Input:\\n', X_example)\n",
    "print()\n",
    "print('Example Output size: ', y_example.size()) # batch_size\n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c3c88b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    9,     0,     0,  ...,     0,     0,    10],\n",
       "        [ 1031,     0,     0,  ...,     0,     0,  7154],\n",
       "        [ 2171,     0,     0,  ...,     0,     0,    19],\n",
       "        ...,\n",
       "        [  464,     4,    31,  ...,    14,   483,  2685],\n",
       "        [   76,    55,  2207,  ...,  7885,  5594,   379],\n",
       "        [   87,  1933,   472,  ..., 90440,    12,     1]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_example.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8434467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    9,  1031,  2171,  ...,   464,    76,    87],\n",
       "        [    0,     0,     0,  ...,     4,    55,  1933],\n",
       "        [    0,     0,     0,  ...,    31,  2207,   472],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,    14,  7885, 90440],\n",
       "        [    0,     0,     0,  ...,   483,  5594,    12],\n",
       "        [   10,  7154,    19,  ...,  2685,   379,     1]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae14771a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_example[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caff1a",
   "metadata": {},
   "source": [
    "# define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd268200",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer=nn.Embedding(input_dimension,embedding_dimension)\n",
    "        self.rnn_layer=nn.RNN(embedding_dimension,hidden_dimension,num_layers=1)\n",
    "        self.fc_layer=nn.Linear(hidden_dimension,output_dimension)\n",
    "    \n",
    "    def forward(self,sequence):\n",
    "        # sequence shape (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence) # embedding shape \n",
    "                                                    # (sequence_length, batch_size, embedding_dimension)\n",
    "        output, hidden_state = self.rnn_layer(embedding) # output shape (sequence_length, batch_size,hidden_dimension)\n",
    "                                                    # hidden_state shape (1, batch_size, hidden_dimension)\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))\n",
    "        return final_output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4cec471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the RNN model:\n",
    "input_dimension = len(vocab_to_token)+1 # +1 to account for padding\n",
    "embedding_dimension = 100\n",
    "hidden_dimension = 32\n",
    "output_dimension = 1\n",
    "\n",
    "rnn = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "optim = optim.Adam(rnn.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss() #this module provides a numerically stable computation of\n",
    "                                    # sigmoid before binary cross-entropy function\n",
    "rnn = rnn.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4eec3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121365"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_to_token)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dffa393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a accuracy metric to measures performance\n",
    "def accuracy_metric(predictions, y):\n",
    "    round_pred = torch.round(torch.sigmoid(predictions))\n",
    "    success = (round_pred == y).float() # convert into float for division\n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ef920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22f2b83",
   "metadata": {},
   "source": [
    "# training and validation routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "837c2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training routine\n",
    "def train(model, dataloader, optim, loss_func):\n",
    "    total_loss = 0\n",
    "    overall_accuracy = 0\n",
    "    model.train()\n",
    "    for sequence, sentiment in dataloader:\n",
    "        optim.zero_grad()\n",
    "        preds = model(sequence.T).squeeze()\n",
    "        loss = loss_func(preds, sentiment)\n",
    "        accuracy = accuracy_metric(preds, sentiment)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "        overall_accuracy += accuracy.item()\n",
    "    return total_loss/len(dataloader), overall_accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faae8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation routine\n",
    "def validate(model, dataloader, loss_func):\n",
    "    total_loss = 0\n",
    "    overall_accuracy = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sequence, sentiment in dataloader:\n",
    "            pred = model(sequence.T).squeeze()\n",
    "            loss = loss_func(pred, sentiment)\n",
    "            accuracy = accuracy_metric(pred,sentiment)\n",
    "            total_loss += loss.item()\n",
    "            overall_accuracy += accuracy.item()\n",
    "    return total_loss/len(dataloader), overall_accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13053845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b78b4726",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "767cdb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time spent: 11.766915798187256s\n",
      "training loss: 0.676 | training accuracy: 56.31%\n",
      "validation loss: 0.646 | val_accuracy: 61.83%\n",
      "\n",
      "epoch number: 2 | time spent: 10.64987063407898s\n",
      "training loss: 0.594 | training accuracy: 68.41%\n",
      "validation loss: 0.599 | val_accuracy: 68.93%\n",
      "\n",
      "epoch number: 3 | time spent: 10.678669214248657s\n",
      "training loss: 0.555 | training accuracy: 71.29%\n",
      "validation loss: 0.606 | val_accuracy: 66.29%\n",
      "\n",
      "epoch number: 4 | time spent: 10.657835483551025s\n",
      "training loss: 0.461 | training accuracy: 78.86%\n",
      "validation loss: 0.675 | val_accuracy: 70.84%\n",
      "\n",
      "epoch number: 5 | time spent: 10.668766260147095s\n",
      "training loss: 0.477 | training accuracy: 78.05%\n",
      "validation loss: 0.589 | val_accuracy: 71.14%\n",
      "\n",
      "epoch number: 6 | time spent: 10.687759637832642s\n",
      "training loss: 0.383 | training accuracy: 83.59%\n",
      "validation loss: 0.580 | val_accuracy: 74.35%\n",
      "\n",
      "epoch number: 7 | time spent: 10.822776079177856s\n",
      "training loss: 0.325 | training accuracy: 86.65%\n",
      "validation loss: 0.600 | val_accuracy: 73.84%\n",
      "\n",
      "epoch number: 8 | time spent: 10.671734809875488s\n",
      "training loss: 0.281 | training accuracy: 88.79%\n",
      "validation loss: 0.705 | val_accuracy: 65.12%\n",
      "\n",
      "epoch number: 9 | time spent: 11.106525182723999s\n",
      "training loss: 0.331 | training accuracy: 85.54%\n",
      "validation loss: 0.675 | val_accuracy: 72.07%\n",
      "\n",
      "epoch number: 10 | time spent: 10.748155117034912s\n",
      "training loss: 0.208 | training accuracy: 92.40%\n",
      "validation loss: 0.687 | val_accuracy: 74.34%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "best_val_loss =float(\"inf\") # set it to infinity\n",
    "for e in range(epochs):\n",
    "    time_start = time.time()\n",
    "    training_loss, train_accuracy = train(rnn,train_dataloader, optim, loss_func)\n",
    "    val_loss, val_accuracy = validate(rnn, validation_dataloader,loss_func)\n",
    "    time_end = time.time()\n",
    "    dtime = time_end - time_start\n",
    "    #if val_loss < best_val_loss:\n",
    "        #best_val_loss = val_loss\n",
    "        #torch.save(rnn.state_dict(),\"Weights/rnn-Val_loss-{}.pkl\".format(np.round(best_val_loss,4)))\n",
    "    print(f\"epoch number: {e+1} | time spent: {dtime}s\")\n",
    "    print(f\"training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%\")\n",
    "    print(f\"validation loss: {val_loss:.3f} | val_accuracy: {val_accuracy*100:.2f}%\\n\")\n",
    "torch.save(rnn.state_dict(),\"Weights/rnn-Val_loss-{}.pkl\".format(np.round(best_val_loss,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabd1d6",
   "metadata": {},
   "source": [
    "# make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b9dd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    sentence = sentence.lower()\n",
    "    sentence = \"\".join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token,0) for token in sentence.split()]\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized),0),\"constant\")\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    #print(\"Shape: \", model_input.shape)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    #print(\"Shape: \", model_input.shape)\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    print(\"predicted probability: %.4f%%\" % (pred*100))\n",
    "    output = \"pos\" if pred >= 0.5 else \"neg\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "750670bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S t r i n g'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Strin,g\"\n",
    "\" \".join([c for c in a if c not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77964fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 6, 49]\n",
      "10 6 49\n"
     ]
    }
   ],
   "source": [
    "# recall the vocab_to_token is the word to int dictionary\n",
    "a = \"this is good\"\n",
    "b = [vocab_to_token.get(token, 0) for token in a.split()]\n",
    "print(b)\n",
    "print(vocab_to_token[\"this\"],vocab_to_token[\"is\"],vocab_to_token[\"good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e08c457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e1b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d9f75a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([512])\n",
      "Shape:  torch.Size([512, 1])\n",
      "predicted probability: 31.4191%\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn,\"This file is horrible\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c016271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([512])\n",
      "Shape:  torch.Size([512, 1])\n",
      "predicted probability: 88.0094%\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn,\"Director tried too hard but this film is too bad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13b673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
